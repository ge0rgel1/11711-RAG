David Mortensen
Paper count: 75
- Nathaniel R. Robinson, Perez Ogayo, David R. Mortensen, Graham Neubig. 2023. ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages. Abstract: Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs’ MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world’s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language’s resource level is the most important feature in determining ChatGPT’s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.
- Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R. Mortensen, Noah A. Smith, Yulia Tsvetkov. 2023. Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models. Abstract: Language models have graduated from being research prototypes to commercialized products offered as web APIs, and recent works have highlighted the multilingual capabilities of these products. The API vendors charge their users based on usage, more specifically on the number of ``tokens'' processed or generated by the underlying language models. What constitutes a token, however, is training data and model dependent with a large variance in the number of tokens required to convey the same information in different languages. In this work, we analyze the effect of this non-uniformity on the fairness of an API's pricing policy across languages. We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with. Through these analyses, we aim to increase transparency around language model APIs' pricing policies and encourage the vendors to make them more equitable.
- David R. Mortensen. 2023. African Substrates Rather Than European Lexifiers to Augment African-diaspora Creole Translation. Abstract: Machine translation (MT) model training is difficult for low-resource languages. This is especially true for African-diaspora Creole languages because of data scarcity. Cross-lingual data augmentation methods with knowledge transfer from related high-resource languages are a common technique to overcome this disadvantage. For instance, practitioners may transfer knowledge from a language in the same language family as the low-resource language of interest. Africandiaspora Creole languages are low-resource and simultaneously have relationships with multiple language groups. These languages, such as Haitian Creole and Jamaican Patois, are typically lexified by colonial European languages, but they are structurally similar to African languages. We explore the advantages of transferring knowledge from the European lexifier language versus the phylogenetic and typological relatives of the African substrate languages. We analysed Haitian and Jamaican MT: both controlling tightly for data properties across compared transfer languages and later allowing use of all data we collected. Our inquiry demonstrates a significant advantage in using African transfer languages in some settings.
- Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin. 2023. SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing. Abstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.
- Leonie Weissweiler, Taiqi He, Naoki Otani, David R. Mortensen, L. Levin, Hinrich Schütze. 2023. Construction Grammar Provides Unique Insight into Neural Language Models. Abstract: Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.
- David R. Mortensen, Ela Gulsen, Taiqi He, Nathaniel R. Robinson, Jonathan D. Amith, Lindia Tjuatja, L. Levin. 2023. Generalized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation. Abstract: Interlinear glossing provides a vital type of morphosyntactic annotation, both for linguists and language revitalists, and numerous conventions exist for representing it formally and computationally. Some of these formats are human readable; others are machine readable. Some are easy to edit with general-purpose tools. Few represent non-concatentative processes like infixation, reduplication, mutation, truncation, and tonal overwriting in a consistent and formally rigorous way (on par with affixation). We propose an annotation conventionâ€”Generalized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.
- Young Min Kim, Kalvin Chang, Chenxuan Cui, David R. Mortensen. 2023. Transformed Protoform Reconstruction. Abstract: Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023.
- Vilém Zouhar, Kalvin Chang, Chenxuan Cui, Nathaniel Carlson, Nathaniel R. Robinson, Mrinmaya Sachan, David R. Mortensen. 2023. PWESuite: Phonetic Word Embeddings and Tasks They Facilitate. Abstract: Mapping words into a fixed-dimensional vector space is the backbone of modern NLP. While most word embedding methods successfully encode semantic information, they overlook phonetic information that is crucial for many tasks. We develop three methods that use articulatory features to build phonetically informed word embeddings. To address the inconsistent evaluation of existing phonetic word embedding methods, we also contribute a task suite to fairly evaluate past, current, and future methods. We evaluate both (1) intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and (2) extrinsic performance on tasks such as rhyme and cognate detection and sound analogies. We hope our task suite will promote reproducibility and inspire future phonetic embedding research.
- Xinjian Li, Florian Metze, David R. Mortensen, A. Black, Shinji Watanabe. 2022. Phone Inventories and Recognition for Every Language. Abstract: Identifying phone inventories is a crucial component in language documentation and the preservation of endangered languages. However, even the largest collection of phone inventory only covers about 2000 languages, which is only 1/4 of the total number of languages in the world. A majority of the remaining languages are endangered. In this work, we attempt to solve this problem by estimating the phone inventory for any language listed in Glottolog, which contains phylogenetic information regarding 8000 languages. In particular, we propose one probabilistic model and one non-probabilistic model, both using phylogenetic trees (“language family trees”) to measure the distance between languages. We show that our best model outperforms baseline models by 6.5 F1. Furthermore, we demonstrate that, with the proposed inventories, the phone recognition model can be customized for every language in the set, which improved the PER (phone error rate) in phone recognition by 25%.
- Nathaniel R. Robinson, Perez Ogayo, Swetha Gangu, David R. Mortensen, Shinji Watanabe. 2022. When Is TTS Augmentation Through a Pivot Language Useful?. Abstract: Developing Automatic Speech Recognition (ASR) for low-resource languages is a challenge due to the small amount of transcribed audio data. For many such languages, audio and text are available separately, but not audio with transcriptions. Using text, speech can be synthetically produced via text-to-speech (TTS) systems. However, many low-resource languages do not have quality TTS systems either. We propose an alter-native: produce synthetic audio by running text from the target language through a trained TTS system for a higher-resource pivot language. We investigate when and how this technique is most effective in low-resource settings. In our experiments, using several thousand synthetic TTS text-speech pairs and duplicating authentic data to balance yields optimal results. Our findings suggest that searching over a set of candidate pivot languages can lead to marginal improvements and that, surpris-ingly, ASR performance can by harmed by increases in measured TTS quality. Application of these findings improves ASR by 64.5% and 45.0% character error reduction rate (CERR) re-spectively for two low-resource languages: Guaran´ı and Suba.
- David R. Mortensen, Xinyu Zhang, Chenxuan Cui, Katherine J. Zhang. 2022. A Hmong Corpus with Elaborate Expression Annotations. Abstract: This paper describes the first publicly available corpus of Hmong, a minority language of China, Vietnam, Laos, Thailand, and various countries in Europe and the Americas. The corpus has been scraped from a long-running Usenet newsgroup called soc.culture.hmong and consists of approximately 12 million tokens. This corpus (called SCH) is also the first substantial corpus to be annotated for elaborate expressions, a kind of four-part coordinate construction that is common and important in the languages of mainland Southeast Asia. We show that word embeddings trained on SCH can benefit tasks in Hmong (solving analogies) and that a model trained on it can label previously unseen elaborate expressions, in context, with an F1 of 90.79 (precision: 87.36, recall: 94.52). [ISO 639-3: mww, hmj]
- Xinjian Li, Florian Metze, David R. Mortensen, A. Black, Shinji Watanabe. 2022. ASR2K: Speech Recognition for Around 2000 Languages without Audio. Abstract: Most recent speech recognition models rely on large supervised datasets, which are unavailable for many low-resource languages. In this work, we present a speech recognition pipeline that does not require any audio for the target language. The only assumption is that we have access to raw text datasets or a set of n-gram statistics. Our speech pipeline consists of three components: acoustic, pronunciation, and language models. Unlike the standard pipeline, our acoustic and pronunciation models use multilingual models without any supervision. The language model is built using n-gram statistics or the raw text dataset. We build speech recognition for 1909 languages by combining it with Crubadan: a large endangered languages n-gram database. Furthermore, we test our approach on 129 languages across two datasets: Common Voice and CMU Wilderness dataset. We achieve 50% CER and 74% WER on the Wilderness dataset with Crubadan statistics only and improve them to 45% CER and 69% WER when using 10000 raw text utterances.
- Nathaniel R. Robinson, Nathaniel Carlson, David R. Mortensen, Elizabeth Vargas, Thomas Fackrell, Nancy Fulda. 2022. Task-dependent Optimal Weight Combinations for Static Embeddings. Abstract: A variety of NLP applications use word2vec skip-gram, GloVe, and fastText word embeddings. These models learn two sets of embedding vectors, but most practitioners use only one of them, or alternately an unweighted sum of both. This is the first study to systematically explore a range of linear combinations between the first and second embedding sets. We evaluate these combinations on a set of six NLP benchmarks including IR, POS-tagging, and sentence similarity. We show that the default embedding combinations are often suboptimal and demonstrate 1.0-8.0% improvements. Notably, GloVes default unweighted sum is its least effective combination across tasks. We provide a theoretical basis for weighting one set of embeddings more than the other according to the algorithm and task. We apply our findings to improve accuracy in applications of cross-lingual alignment and navigational knowledge by up to 15.2%.
- Nathaniel R. Robinson, Cameron J. Hogan, Nancy Fulda, David R. Mortensen. 2022. Data-adaptive Transfer Learning for Translation: A Case Study in Haitian and Jamaican. Abstract: Multilingual transfer techniques often improve low-resource machine translation (MT). Many of these techniques are applied without considering data characteristics. We show in the context of Haitian-to-English translation that transfer effectiveness is correlated with amount of training data and relationships between knowledge-sharing languages. Our experiments suggest that for some languages beyond a threshold of authentic data, back-translation augmentation methods are counterproductive, while cross-lingual transfer from a sufficiently related language is preferred. We complement this finding by contributing a rule-based French-Haitian orthographic and syntactic engine and a novel method for phonological embedding. When used with multilingual techniques, orthographic transformation makes statistically significant improvements over conventional methods. And in very low-resource Jamaican MT, code-switching with a transfer language for orthographic resemblance yields a 6.63 BLEU point advantage.
- Aditi Chaudhary, Zaid A. W. Sheikh, David R. Mortensen, Antonios Anastasopoulos, Graham Neubig. 2022. AUTOLEX: An Automatic Framework for Linguistic Exploration. Abstract: Each language has its own complex systems of word, phrase, and sentence construction, the guiding principles of which are often summarized in grammar descriptions for the consumption of linguists or language learners. However, manual creation of such descriptions is a fraught process, as creating descriptions which describe the language in"its own terms"without bias or error requires both a deep understanding of the language at hand and linguistics as a whole. We propose an automatic framework AutoLEX that aims to ease linguists' discovery and extraction of concise descriptions of linguistic phenomena. Specifically, we apply this framework to extract descriptions for three phenomena: morphological agreement, case marking, and word order, across several languages. We evaluate the descriptions with the help of language experts and propose a method for automated evaluation when human evaluation is infeasible.
- Chenxuan Cui, Katherine J. Zhang, David R. Mortensen. 2022. Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese. Abstract: Coordinate compounds (CCs) and elaborate expressions (EEs) are coordinate constructions common in languages of East and Southeast Asia. Mortensen (2006) claims that (1) the linear ordering of EEs and CCs in Hmong, Lahu, and Chinese can be predicted via phonological hierarchies and (2) that these phonological hierarchies lack a clear phonetic rationale. These claims are significant because morphosyntax has often been seen as in a feed-forward relationship with phonology, and phonological generalizations have often been assumed to be phonetically “natural”. We investigate whether the ordering of CCs and EEs can be learned empirically and whether computational models (classifiers and sequence-labeling models) learn unnatural hierarchies similar to those posited by Mortensen (2006). We find that decision trees and SVMs learn to predict the order of CCs/EEs on the basis of phonology, beating strong baselines for all three languages, with DTs learning hierarchies strikingly similar to those proposed by Mortensen. However, we also find that a neural sequence labeling model is able to learn the ordering of elaborate expressions in Hmong very effectively without using any phonological information. We argue that EE ordering can be learned through two independent routes: phonology and lexical distribution, presenting a more nuanced picture than previous work.
- Clayton Marr, David R. Mortensen. 2022. Large-scale computerized forward reconstruction yields new perspectives in French diachronic phonology. Abstract: 
Traditionally, historical phonologists have relied on tedious manual derivations to sequence the sound changes that have shaped the phonological evolution of languages. However, humans are prone to errors, and cannot track thousands of parallel derivations in any efficient manner. We demonstrate computerized forward reconstruction (CFR), deriving each etymon in parallel, as a task with metrics to optimize, and as a tool which drastically facilitates inquiry. To this end we present DiaSim, an application which simulates “cascades” of diachronic developments over a language’s lexicon and provides various diagnostics for “debugging” those cascades. We test our method on a Latin-to-French reflex prediction task, using a newly compiled, publicly available dataset FLLex consisting of 1368 paired Latin and Modern French forms. We also introduce a second dataset, FLLAPS, which maps 310 reflexes from Latin through five attested intermediate stages up to Modern French, derived from Pope’s (1934) periodic development tables. We present publicly available rule cascades: the baseline BaseCLEF and BaseCLEF* cascades, based on Pope’s (1934) widely-cited view of French development, and DiaCLEF, made from incremental corrections to BaseCLEF aided by DiaSim’s diagnostics. DiaCLEF outperforms the baselines by large margins, improving raw accuracy on FLLex from 3.2% to 84.9% of etyma, with similarly large improvements for each of FLLAPS’ periods. Changes were made to build DiaCLEF considering only the baseline and DiaSim’s diagnostics, but they often independently reproduced past work in French diachronic phonology, corroborating both our procedure and past endeavors; we discuss the implications of some of our findings in detail.
- Kalvin Chang, Chenxuan Cui, Young Min Kim, David R. Mortensen. 2022. WikiHan: A New Comparative Dataset for Chinese Languages. Abstract: Most comparative datasets of Chinese varieties are not digital; however, Wiktionary includes a wealth of transcriptions of words from these varieties. The usefulness of these data is limited by the fact that they use a wide range of variety-specific romanizations, making data difficult to compare. The current work collects this data into a single constituent (IPA, or International Phonetic Alphabet) and structured form (TSV) for use in comparative linguistics and Chinese NLP. At the time of writing, the dataset contains 67,943 entries across 8 varieties and Middle Chinese. The dataset is validated on a protoform reconstruction task using an encoder-decoder cross-attention architecture (Meloni et al 2021), achieving an accuracy of 54.11%, a PER (phoneme error rate) of 17.69%, and a FER (feature error rate) of 6.60%.
- Xinjian Li, Florian Metze, David R. Mortensen, Shinji Watanabe, A. Black. 2022. Zero-shot Learning for Grapheme to Phoneme Conversion with Language Ensemble. Abstract: Grapheme-to-Phoneme (G2P) has many applications in NLP and speech fields. Most existing work focuses heavily on languages with abundant training datasets, which limits the scope of target languages to less than 100 languages. This work attempts to apply zero-shot learning to approximate G2P models for all low-resource and endangered languages in Glottolog (about 8k languages). For any unseen target language, we first build the phylogenetic tree (i.e. language family tree) to identify top-k nearest languages for which we have training sets. Then we run models of those languages to obtain a hypothesis set, which we combine into a confusion network to propose a most likely hypothesis as an approximation to the target language. We test our approach on over 600 unseen languages and demonstrate it significantly outperforms baselines.
- Brendon Boldt, David R. Mortensen. 2022. Recommendations for Systematic Research on Emergent Language. Abstract: Emergent language is unique among ﬁelds within the discipline of machine learning for its open-endedness, not obviously presenting well-deﬁned problems to be solved. As a result, the current research in the ﬁeld has largely been exploratory: focusing on establishing new problems, techniques, and phenomena. Yet after these problems have been established, subsequent progress requires research which can measurably demonstrate how it improves on prior approaches. This type of research is what we call systematic research ; in this paper, we illustrate this mode of research speciﬁcally for emergent language. We ﬁrst identify the overarching goals of emergent language research, categoriz-ing them as either science or engineering. Using this distinction, we present core methodological elements of science and engineering, analyze their role in current emergent language research, and recommend how to apply these elements.
- Brendon Boldt, David R. Mortensen. 2022. Mathematically Modeling the Lexicon Entropy of Emergent Language. Abstract: We formulate a stochastic process, FiLex, as a mathematical model of lexicon entropy in deep learning-based emergent language systems. Defining a model mathematically allows it to generate clear predictions which can be directly and decisively tested. We empirically verify across four different environments that FiLex predicts the correct correlation between hyperparameters (training steps, lexicon size, learning rate, rollout buffer size, and Gumbel-Softmax temperature) and the emergent language's entropy in 20 out of 20 environment-hyperparameter combinations. Furthermore, our experiments reveal that different environments show diverse relationships between their hyperparameters and entropy which demonstrates the need for a model which can make well-defined predictions at a precise level of granularity.
- Brendon Boldt, David R. Mortensen. 2022. Modeling Emergent Lexicon Formation with a Self-Reinforcing Stochastic Process. Abstract: We introduce FiLex, a self-reinforcing stochastic process which models finite lexicons in emergent language experiments. The central property of FiLex is that it is a self-reinforcing process, parallel to the intuition that the more a word is used in a language, the more its use will continue. As a theoretical model, FiLex serves as a way to both explain and predict the behavior of the emergent language system. We empirically test FiLex's ability to capture the relationship between the emergent language's hyperparameters and the lexicon's Shannon entropy.
- Jimin Sun, Hwijeen Ahn, Chan Young Park, Yulia Tsvetkov, David R. Mortensen. 2021. Cross-Cultural Similarity Features for Cross-Lingual Transfer Learning of Pragmatically Motivated Tasks. Abstract: Much work in cross-lingual transfer learning explored how to select better transfer languages for multilingual tasks, primarily focusing on typological and genealogical similarities between languages. We hypothesize that these measures of linguistic proximity are not enough when working with pragmatically-motivated tasks, such as sentiment analysis. As an alternative, we introduce three linguistic features that capture cross-cultural similarities that manifest in linguistic patterns and quantify distinct aspects of language pragmatics: language context-level, figurative language, and the lexification of emotion concepts. Our analyses show that the proposed pragmatic features do capture cross-cultural similarities and align well with existing work in sociolinguistics and linguistic anthropology. We further corroborate the effectiveness of pragmatically-driven transfer in the downstream task of choosing transfer languages for cross-lingual sentiment analysis.
- Xinjian Li, David R. Mortensen, Florian Metze, A. Black. 2021. Multilingual Phonetic Dataset for Low Resource Speech Recognition. Abstract: Phone Recognition is one of the most important tasks in the field of multilingual speech recognition, especially for low-resource languages whose orthographies are not available. However, most speech recognition datasets so far only focus on high-resource languages, there are very few datasets available for low-resource languages, especially datasets with detailed phone annotation. In this work, we present a large multilingual phonetic dataset, which is preprocessed and aligned from the UCLA phonetic dataset. The dataset contains around 100 low-resource languages and 7000 utterances in total. This dataset would provide an ideal training/evaluation set for universal phone recognition.
- David R. Mortensen, J. Picone, Xinjian Li, Kathleen Siminyu. 2021. Tusom2021: A Phonetically Transcribed Speech Dataset from an Endangered Language for Universal Phone Recognition Experiments. Abstract: There is growing interest in ASR systems that can recognize phones in a language-independent fashion. There is additionally interest in building language technologies for low-resource and endangered languages. However, there is a paucity of realistic data that can be used to test such systems and technologies. This paper presents a publicly available, phonetically transcribed corpus of 2255 utterances (words and short phrases) in the endangered Tangkhulic language East Tusom (no ISO 639-3 code), a Tibeto-Burman language variety spoken mostly in India. Because the dataset is transcribed in terms of phones, rather than phonemes, it is a better match for universal phone recognition systems than many larger (phonemically transcribed) datasets. This paper describes the dataset and the methodology used to produce it. It further presents basic benchmarks of state-of-the-art universal phone recognition systems on the dataset as baselines for future experiments.
- Adithya Pratapa, Antonios Anastasopoulos, Shruti Rijhwani, Aditi Chaudhary, David R. Mortensen, Graham Neubig, Yulia Tsvetkov. 2021. Evaluating the Morphosyntactic Well-formedness of Generated Texts. Abstract: Text generation systems are ubiquitous in natural language processing applications. However, evaluation of these systems remains a challenge, especially in multilingual settings. In this paper, we propose L’AMBRE – a metric to evaluate the morphosyntactic well-formedness of text using its dependency parse and morphosyntactic rules of the language. We present a way to automatically extract various rules governing morphosyntax directly from dependency treebanks. To tackle the noisy outputs from text generation systems, we propose a simple methodology to train robust parsers. We show the effectiveness of our metric on the task of machine translation through a diachronic study of systems translating into morphologically-rich languages.
- Brian Yan, Siddharth Dalmia, David R. Mortensen, Florian Metze, Shinji Watanabe. 2021. Differentiable Allophone Graphs for Language-Universal Speech Recognition. Abstract: Building language-universal speech recognition systems entails producing phonological units of spoken sound that can be shared across languages. While speech annotations at the language-specific phoneme or surface levels are readily available, annotations at a universal phone level are relatively rare and difficult to produce. In this work, we present a general framework to derive phone-level supervision from only phonemic transcriptions and phone-to-phoneme mappings with learnable weights represented using weighted finite-state transducers, which we call differentiable allophone graphs. By training multilingually, we build a universal phone-based speech recognition model with interpretable probabilistic phone-to-phoneme mappings for each language. These phone-based systems with learned allophone graphs can be used by linguists to document new languages, build phone-based lexicons that capture rich pronunciation variations, and re-evaluate the allophone mappings of seen language. We demonstrate the aforementioned benefits of our proposed framework with a system trained on 7 diverse languages.
- Da Francis, Ella Rabinovich, Farhan Samir, David R. Mortensen, S. Stevenson. 2021. Quantifying Cognitive Factors in Lexical Decline. Abstract: Abstract We adopt an evolutionary view on language change in which cognitive factors (in addition to social ones) affect the fitness of words and their success in the linguistic ecosystem. Specifically, we propose a variety of psycholinguistic factors—semantic, distributional, and phonological—that we hypothesize are predictive of lexical decline, in which words greatly decrease in frequency over time. Using historical data across three languages (English, French, and German), we find that most of our proposed factors show a significant difference in the expected direction between each curated set of declining words and their matched stable words. Moreover, logistic regression analyses show that semantic and distributional factors are significant in predicting declining words. Further diachronic analysis reveals that declining words tend to decrease in the diversity of their lexical contexts over time, gradually narrowing their ‘ecological niches’.
- Kathleen Siminyu, Xinjian Li, Antonios Anastasopoulos, David R. Mortensen, M. Marlo, Graham Neubig. 2021. Phoneme Recognition through Fine Tuning of Phonetic Representations: a Case Study on Luhya Language Varieties. Abstract: Models pre-trained on multiple languages have shown significant promise for improving speech recognition, particularly for low-resource languages. In this work, we focus on phoneme recognition using Allosaurus, a method for multilingual recognition based on phonetic annotation, which incorporates phonological knowledge through a language-dependent allophone layer that associates a universal narrow phone-set with the phonemes that appear in each language. To evaluate in a challenging real-world scenario, we curate phone recognition datasets for Bukusu and Saamia, two varieties of the Luhya language cluster of western Kenya and eastern Uganda. To our knowledge, these datasets are the first of their kind. We carry out similar experiments on the dataset of an endangered Tangkhulic language, East Tusom, a Tibeto-Burman language variety spoken mostly in India. We explore both zero-shot and few-shot recognition by fine-tuning using datasets of varying sizes (10 to 1000 utterances). We find that fine-tuning of Allosaurus, even with just 100 utterances, leads to significant improvements in phone error rates.
- David R. Mortensen, J. Picone. 2021. East Tusom. Abstract: 
East Tusom is a Tibeto-Burman language of Manipur, India, belonging to the Tangkhulic group. While it shares some innovations with the other Tangkhulic languages, it differs markedly from “Standard Tangkhul” (which is based on the speech of Ukhrul town). Past documentation is limited to a small set of hastily transcribed forms in a comparative reconstruction of Tangkhulic rhymes (Mortensen & Miller 2013; Mortensen 2012). This paper presents the first substantial sketch of an aspect of the language: its (descriptive) phonetics and phonology. The data are based on recordings of an extensive wordlist (730 items) and one short text, all from one fluent native speaker in her mid-twenties. We present the phonetic inventory of East Tusom and a phonemicization, with exhaustive examples. We also present an overview of the major phonological patterns and generalizations in the language. Of special interest are a “placeless nasal” that is realized as nasalization on the preceding vowel unless it is followed by a consonant, and numerous plosive-fricative clusters (where the fricative is roughly homorganic with the following vowel) that have developed from historical aspirated plosives. A complete wordlist, organized by gloss and semantic field, is provided as appendices.
- Jimin Sun, Hwijeen Ahn, Chan Young Park, Yulia Tsvetkov, David R. Mortensen. 2020. Ranking Transfer Languages with Pragmatically-Motivated Features for Multilingual Sentiment Analysis. Abstract: Cross-lingual transfer learning studies how datasets, annotations, and models can be transferred from resource-rich languages to improve language technologies in resource-poor settings. Recent works have shown that we can further benefit from the selection of the best transfer language. In this paper, we propose three pragmatically-motivated features that can help guide the optimal transfer language selection problem for cross-lingual transfer. Specifically, the proposed features operationalize cross-cultural similarities that manifest in various linguistic patterns: language context-level, sharing multi-word expressions, and the use of emotion concepts. Our experimental results show that these features significantly improve the prediction of optimal transfer languages over baselines in sentiment analysis, but are less useful for dependency parsing. Further analyses show that the proposed features indeed capture the intended cross-cultural similarities and align well with existing work in sociolinguistics and linguistic anthropology.
- Clayton Marr, David R. Mortensen. 2020. Computerized Forward Reconstruction for Analysis in Diachronic Phonology, and Latin to French Reflex Prediction. Abstract: Traditionally, historical phonologists have relied on tedious manual derivations to calibrate the sequences of sound changes that shaped the phonological evolution of languages. However, humans are prone to errors, and cannot track thousands of parallel word derivations in any efficient manner. We propose to instead automatically derive each lexical item in parallel, and we demonstrate forward reconstruction as both a computational task with metrics to optimize, and as an empirical tool for inquiry. For this end we present DiaSim, a user-facing application that simulates “cascades” of diachronic developments over a language’s lexicon and provides diagnostics for “debugging” those cascades. We test our methodology on a Latin-to-French reflex prediction task, using a newly compiled dataset FLLex with 1368 paired Latin/French forms. We also present, FLLAPS, which maps 310 Latin reflexes through five stages until Modern French, derived from Pope (1934)’s sound tables. Our publicly available rule cascades include the baselines BaseCLEF and BaseCLEF*, representing the received view of Latin to French development, and DiaCLEF, build by incremental corrections to BaseCLEF aided by DiaSim’s diagnostics. DiaCLEF vastly outperforms the baselines, improving final accuracy on FLLex from 3.2%to 84.9%, and similar improvements across FLLAPS’ stages.
- Xinjian Li, Siddharth Dalmia, Juncheng Billy Li, Matthew Russell Lee, Patrick Littell, Jiali Yao, Antonios Anastasopoulos, David R. Mortensen, Graham Neubig, A. Black, Florian Metze. 2020. Universal Phone Recognition with a Multilingual Allophone System. Abstract: Multilingual models can improve language processing, particularly for low resource situations, by sharing parameters across languages. Multilingual acoustic models, however, generally ignore the difference between phonemes (sounds that can support lexical contrasts in a particular language) and their corresponding phones (the sounds that are actually spoken, which are language independent). This can lead to performance degradation when combining a variety of training languages, as identically annotated phonemes can actually correspond to several different underlying phonetic realizations. In this work, we propose a joint model of both language-independent phone and language-dependent phoneme distributions. In multilingual ASR experiments over 11 languages, we find that this model improves testing performance by 2% phoneme error rate absolute in low-resource conditions. Additionally, because we are explicitly modeling language-independent phones, we can build a (nearly-)universal phone recognizer that, when combined with the PHOIBLE [1] large, manually curated database of phone inventories, can be customized into 2,000 language dependent recognizers. Experiments on two low-resourced indigenous languages, Inuktitut and Tusom, show that our recognizer achieves phone accuracy improvements of more than 17%, moving a step closer to speech recognition for all languages in the world.1
- David R. Mortensen, Xinjian Li, Patrick Littell, Alexis Michaud, Shruti Rijhwani, Antonios Anastasopoulos, A. Black, Florian Metze, Graham Neubig. 2020. AlloVera: A Multilingual Allophone Database. Abstract: We introduce a new resource, AlloVera, which provides mappings from 218 allophones to phonemes for 14 languages. Phonemes are contrastive phonological units, and allophones are their various concrete realizations, which are predictable from phonological context. While phonemic representations are language specific, phonetic representations (stated in terms of (allo)phones) are much closer to a universal (language-independent) transcription. AlloVera allows the training of speech recognition models that output phonetic transcriptions in the International Phonetic Alphabet (IPA), regardless of the input language. We show that a “universal” allophone model, Allosaurus, built with AlloVera, outperforms “universal” phonemic models and language-specific models on a speech-transcription task. We explore the implications of this technology (and related technologies) for the documentation of endangered and minority languages. We further explore other applications for which AlloVera will be suitable as it grows, including phonological typology.
- Maria Ryskina, Ella Rabinovich, Taylor Berg-Kirkpatrick, David R. Mortensen, Yulia Tsvetkov. 2020. Where New Words Are Born: Distributional Semantic Analysis of Neologisms and Their Semantic Neighborhoods. Abstract: We perform statistical analysis of the phenomenon of neology, the process by which new words emerge in a language, using large diachronic corpora of English. We investigate the importance of two factors, semantic sparsity and frequency growth rates of semantic neighbors, formalized in the distributional semantics paradigm. We show that both factors are predictive of word emergence although we find more support for the latter hypothesis. Besides presenting a new linguistic application of distributional semantics, this study tackles the linguistic question of the role of language-internal factors (in our case, sparsity) in language change motivated by language-external factors (reflected in frequency growth).
- Aditi Chaudhary, Antonios Anastasopoulos, Adithya Pratapa, David R. Mortensen, Zaid A. W. Sheikh, Yulia Tsvetkov, Graham Neubig. 2020. Automatic Extraction of Rules Governing Morphological Agreement. Abstract: Creating a descriptive grammar of a language is an indispensable step for language documentation and preservation. However, at the same time it is a tedious, time-consuming task. In this paper, we take steps towards automating this process by devising an automated framework for extracting a first-pass grammatical specification from raw text in a concise, human- and machine-readable format. We focus on extracting rules describing agreement, a morphosyntactic phenomenon at the core of the grammars of many of the world's languages. We apply our framework to all languages included in the Universal Dependencies project, with promising results. Using cross-lingual transfer, even with no expert annotations in the language of interest, our framework extracts a grammatical specification which is nearly equivalent to those created with large amounts of gold-standard annotated data. We confirm this finding with human expert evaluations of the rules that our framework produces, which have an average accuracy of 78%. We release an interface demonstrating the extracted rules at this https URL.
- Xinjian Li, Siddharth Dalmia, David R. Mortensen, Juncheng Li, A. Black, Florian Metze. 2020. Towards Zero-shot Learning for Automatic Phonemic Transcription. Abstract: Automatic phonemic transcription tools are useful for low-resource language documentation. However, due to the lack of training sets, only a tiny fraction of languages have phonemic transcription tools. Fortunately, multilingual acoustic modeling provides a solution given limited audio training data. A more challenging problem is to build phonemic transcribers for languages with zero training data. The difficulty of this task is that phoneme inventories often differ between the training languages and the target language, making it infeasible to recognize unseen phonemes. In this work, we address this problem by adopting the idea of zero-shot learning. Our model is able to recognize unseen phonemes in the target language without any training data. In our model, we decompose phonemes into corresponding articulatory attributes such as vowel and consonant. Instead of predicting phonemes directly, we first predict distributions over articulatory attributes, and then compute phoneme distributions with a customized acoustic model. We evaluate our model by training it using 13 languages and testing it using 7 unseen languages. We find that it achieves 7.7% better phoneme error rate on average over a standard multilingual model.
- Zhong Zhou, Lori S. Levin, David R. Mortensen, A. Waibel. 2019. Using Interlinear Glosses as Pivot in Low-Resource Multilingual Machine Translation.. Abstract: We demonstrate a new approach to Neural Machine Translation (NMT) for low-resource languages using a ubiquitous linguistic resource, Interlinear Glossed Text (IGT). IGT represents a non-English sentence as a sequence of English lemmas and morpheme labels. As such, it can serve as a pivot or interlingua for NMT. Our contribution is four-fold. Firstly, we pool IGT for 1,497 languages in ODIN (54,545 glosses) and 70,918 glosses in Arapaho and train a gloss-to-target NMT system from IGT to English, with a BLEU score of 25.94. We introduce a multilingual NMT model that tags all glossed text with gloss-source language tags and train a universal system with shared attention across 1,497 languages. Secondly, we use the IGT gloss-to-target translation as a key step in an English-Turkish MT system trained on only 865 lines from ODIN. Thirdly, we we present five metrics for evaluating extremely low-resource translation when BLEU is no longer sufficient and evaluate the Turkish low-resource system using BLEU and also using accuracy of matching nouns, verbs, agreement, tense, and spurious repetition, showing large improvements.
- Aditi Chaudhary, Elizabeth Salesky, G. Bhat, David R. Mortensen, J. Carbonell, Yulia Tsvetkov. 2019. CMU-01 at the SIGMORPHON 2019 Shared Task on Crosslinguality and Context in Morphology. Abstract: This paper presents the submission by the CMU-01 team to the SIGMORPHON 2019 task 2 of Morphological Analysis and Lemmatization in Context. This task requires us to produce the lemma and morpho-syntactic description of each token in a sequence, for 107 treebanks. We approach this task with a hierarchical neural conditional random field (CRF) model which predicts each coarse-grained feature (eg. POS, Case, etc.) independently. However, most treebanks are under-resourced, thus making it challenging to train deep neural models for them. Hence, we propose a multi-lingual transfer training regime where we transfer from multiple related languages that share similar typology.
- Zhong Zhou, Lori S. Levin, David R. Mortensen, A. Waibel. 2019. Low-Resource Machine Translation using Interlinear Glosses. Abstract: Neural Machine Translation (NMT) does not handle low-resource translation well because NMT is data-hungry and low-resource languages, by their nature, have limited parallel data. Many low-resource languages are morphologically rich, which complicates matters further by increasing data sparsity. However, a good linguist is capable of building a morphological analyzer in far fewer hours than it would take to collect and translate the amount of parallel data needed for conventional NMT. We combine the benefits of both NMT and linguistic information in our work. We use morphological analyzer to automatically generate interlinear glosses with dictionary or parallel data, and translate the source text to interlinear gloss as an interlingua representation, and finally translate into the target text using NMT trained on the ODIN dataset that includes a large collection of interlinear glosses and their corresponding target translations. Our result for translating from the interlinear gloss to the target text using the entire ODIN dataset achieves a BLEU score of 35.07. And our qualitative results show positive findings in a low-resource scenario of Turkish-English translation using 865 lines of training data. Our translation system yield better results than training NMT directly from the source language to the target language in a constrained-data setting, and is helpful to produce translation with sufficiently good content and fluency when data is scarce.
- Aditi Chaudhary, Siddharth Dalmia, Junjie Hu, Xinjian Li, Austin Matthews, Aldrian Obaja Muis, Naoki Otani, Shruti Rijhwani, Zaid A. W. Sheikh, Nidhi Vyas, Xinyi Wang, Jiateng Xie, Ruochen Xu, Chunting Zhou, Peter J. Jansen, Yiming Yang, Lori S. Levin, Florian Metze, T. Mitamura, David R. Mortensen, Graham Neubig, E. Hovy, A. Black, J. Carbonell, Graham Horwood, Shabnam Tafreshi, Mona T. Diab, Efsun Sarioglu Kayi, N. Farra, K. McKeown. 2019. The ARIEL-CMU Systems for LoReHLT18. Abstract: This paper describes the ARIEL-CMU submissions to the Low Resource Human Language Technologies (LoReHLT) 2018 evaluations for the tasks Machine Translation (MT), Entity Discovery and Linking (EDL), and detection of Situation Frames in Text and Speech (SF Text and Speech).
- Xinjian Li, Siddharth Dalmia, David R. Mortensen, Florian Metze, A. Black. 2018. Zero-shot Learning for Speech Recognition with Universal Phonetic Model. Abstract: There are more than 7,000 languages in the world, but due to the lack of training sets, only a small number of them have speech recognition systems. Multilingual speech recognition provides a solution if at least some audio training data is available. Often, however, phoneme inventories differ between the training languages and the target language, making this approach infeasible. In this work, we address the problem of building an acoustic model for languages with zero audio resources. Our model is able to recognize unseen phonemes in the target language, if only a small text corpus is available. We adopt the idea of zero-shot learning, and decompose phonemes into corresponding phonetic attributes such as vowel and consonant. Instead of predicting phonemes directly, we first predict distributions over phonetic attributes, and then compute phoneme distributions with a customized acoustic model. We extensively evaluate our English-trained model on 20 unseen languages, and find that on average, it achieves 9.9% better phone error rate over a traditional CTC based acoustic model trained on English.
- Patrick Littell, R. Thomas McCoy, Na-Rae Han, Shruti Rijhwani, Zaid A. W. Sheikh, David R. Mortensen, T. Mitamura, Lori S. Levin. 2018. Parser combinators for Tigrinya and Oromo morphology. Abstract: We present rule-based morphological parsers in the Tigrinya and Oromo languages, based on a parser-combinator rather than finite-state paradigm. This paradigm allows rapid development and ease of integration with other systems, although at the cost of non-optimal theoretical efficiency. These parsers produce multiple output representations simultaneously, including lemmatization, morphological segmentation, and an English word-for-word gloss, and we evaluate these representations as input for entity detection and linking and humanitarian need detection.
- David R. Mortensen, Siddharth Dalmia, Patrick Littell. 2018. Epitran: Precision G2P for Many Languages. Abstract: Epitran is a massively multilingual, multiple back-end system for G2P (grapheme-to-phoneme) transduction which is distributed with support for 61 languages. It takes word tokens in the orthography of a language and outputs a phonemic representation in either IPA or X-SAMPA. The main system is written in Python and is publicly available as open source software. Its efficacy has been demonstrated in multiple research projects relating to language transfer, polyglot models, and speech. In a particular ASR task, Epitran was shown to improve the word error rate over Babel baselines for acoustic modeling.
- Aditi Chaudhary, Chunting Zhou, Lori S. Levin, Graham Neubig, David R. Mortensen, J. Carbonell. 2018. Adapting Word Embeddings to New Languages with Morphological and Phonological Subword Representations. Abstract: Much work in Natural Language Processing (NLP) has been for resource-rich languages, making generalization to new, less-resourced languages challenging. We present two approaches for improving generalization to low-resourced languages by adapting continuous word representations using linguistically motivated subword units: phonemes, morphemes and graphemes. Our method requires neither parallel corpora nor bilingual dictionaries and provides a significant gain in performance over previous methods relying on these resources. We demonstrate the effectiveness of our approaches on Named Entity Recognition for four languages, namely Uyghur, Turkish, Bengali and Hindi, of which Uyghur and Bengali are low resource languages, and also perform experiments on Machine Translation. Exploiting subwords with transfer learning gives us a boost of +15.2 NER F1 for Uyghur and +9.7 F1 for Bengali. We also show improvements in the monolingual setting where we achieve (avg.) +3 F1 and (avg.) +1.35 BLEU.
- Lori S. Levin, Patrick Littell, David R. Mortensen, Ke Lin, Katherine Kairis, Carlisle Turner. 2017. URIEL and lang2vec: Representing languages as typological, geographical, and phylogenetic vectors. Abstract: We introduce the URIEL knowledge base for massively multilingual NLP and the lang2vec utility, which provides information-rich vector identifications of languages drawn from typological, geographical, and phylogenetic databases and normalized to have straightforward and consistent formats, naming, and semantics. The goal of URIEL and lang2vec is to enable multilingual NLP, especially on less-resourced languages and make possible types of experiments (especially but not exclusively related to NLP tasks) that are otherwise difficult or impossible due to the sparsity and incommensurability of the data sources. lang2vec vectors have been shown to reduce perplexity in multilingual language modeling, when compared to one-hot language identification vectors.
- Patrick Littell, Kartik Goyal, David R. Mortensen, Alexa Little, Chris Dyer, Lori S. Levin. 2016. Named Entity Recognition for Linguistic Rapid Response in Low-Resource Languages: Sorani Kurdish and Tajik. Abstract: This paper describes our construction of named-entity recognition (NER) systems in two Western Iranian languages, Sorani Kurdish and Tajik, as a part of a pilot study of “Linguistic Rapid Response” to potential emergency humanitarian relief situations. In the absence of large annotated corpora, parallel corpora, treebanks, bilingual lexica, etc., we found the following to be effective: exploiting distributional regularities in monolingual data, projecting information across closely related languages, and utilizing human linguist judgments. We show promising results on both a four-month exercise in Sorani and a two-day exercise in Tajik, achieved with minimal annotation costs.
- Patrick Littell, David R. Mortensen, Kartik Goyal, Chris Dyer, Lori S. Levin. 2016. Bridge-Language Capitalization Inference in Western Iranian: Sorani, Kurmanji, Zazaki, and Tajik. Abstract: In Sorani Kurdish, one of the most useful orthographic features in named-entity recognition – capitalization – is absent, as the language’s Perso-Arabic script does not make a distinction between uppercase and lowercase letters. We describe a system for deriving an inferred capitalization value from closely related languages by phonological similarity, and illustrate the system using several related Western Iranian languages.
- Yulia Tsvetkov, Sunayana Sitaram, Manaal Faruqui, Guillaume Lample, Patrick Littell, David R. Mortensen, A. Black, Lori S. Levin, Chris Dyer. 2016. Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation Learning. Abstract: We introduce polyglot language models, recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted. We apply these to the problem of modeling phone sequences---a domain in which universal symbol inventories and cross-linguistically shared feature representations are a natural fit. Intrinsic evaluation on held-out perplexity, qualitative analysis of the learned representations, and extrinsic evaluation in two downstream applications that make use of phonetic features show (i) that polyglot models better generalize to held-out data than comparable monolingual models and (ii) that polyglot phonetic feature representations are of higher quality than those learned monolingually.
- David R. Mortensen, Patrick Littell, Akash Bharadwaj, Kartik Goyal, Chris Dyer, Lori S. Levin. 2016. PanPhon: A Resource for Mapping IPA Segments to Articulatory Feature Vectors. Abstract: This paper contributes to a growing body of evidence that—when coupled with appropriate machine-learning techniques–linguistically motivated, information-rich representations can outperform one-hot encodings of linguistic data. In particular, we show that phonological features outperform character-based models. PanPhon is a database relating over 5,000 IPA segments to 21 subsegmental articulatory features. We show that this database boosts performance in various NER-related tasks. Phonologically aware, neural CRF models built on PanPhon features are able to perform better on monolingual Spanish and Turkish NER tasks that character-based models. They have also been shown to work well in transfer models (as between Uzbek and Turkish). PanPhon features also contribute measurably to Orthography-to-IPA conversion tasks.
- Akash Bharadwaj, David R. Mortensen, Chris Dyer, J. Carbonell. 2016. Phonologically Aware Neural Model for Named Entity Recognition in Low Resource Transfer Settings. Abstract: Named Entity Recognition is a well established information extraction task with many state of the art systems existing for a variety of languages. Most systems rely on language speciﬁc resources, large annotated corpora, gazetteers and feature engineering to perform well monolingually. In this paper, we introduce an attentional neural model which only uses language universal phonological character representations with word embeddings to achieve state of the art performance in a monolingual setting using super-vision and which can quickly adapt to a new language with minimal or no data. We demonstrate that phonological character representations facilitate cross-lingual transfer, out-perform orthographic representations and incorporating both attention and phonological features improves statistical efﬁciency of the model in 0-shot and low data transfer settings with no task speciﬁc feature engineering in the source or target language.
- David R. Mortensen. 2014. Hmong-Mien Languages. Abstract: in the United States, and Barbara Niederer in France. However, while some issues in Hmong-Mien historical linguistics have been settled, others remain open. The following discussion is divided into five categories: the still-unsettled question of the relationship of Hmong-Mien to other language families, the more settled but still developing question of how the languages that are classified as Hmong-Mien relate to one another (internal subclassification), the substantial literature on the reconstruction of Proto-Hmong-Mien, the history of grammatical features of Hmong-Mien languages
- Mang, David R. Mortensen. 2012. Running head : TONALLY CONDITIONED VOWEL RAISING Tonally Conditioned Vowel Raising in Shuijingping. Abstract: In the Mang (Hmongic) dialect of Shuijingping, Guizhou, China, vowels are raised in certain tonal contexts. When a syllable bearing the historical A2 tone occurs in sandhi context, it surfaces with a low tone (historical S) and a raised vowel nucleus. When a syllable bearing the C2 tone occurs out of sandhi context, it also surfaces with a raised vowel. In most other documented cases of tone-vowel quality interactions, there is some factor, such as syllable structure, metrical structure, or vowel duration that mediates between tone and vowel quality. These earlier analyses cannot be straightforwardly extended to Shuijingping Mang, since no synchronic mediating factor seems to be present. However, this paper shows that, historically, there was another mediating factor between tone and vowel quality—voice quality. It is common for tones in East and Southeast Asian languages to have characteristic phonation types. It is also common for phonation type to affect vowel quality. Comparative evidence shows that the tones that condition the vowel alternation in the present-day language historically underwent a tonally-driven breathy-modal voice alternation. Subsequently, the tonal grammar has changed; however, vowel raising remains as a synchronic alternation. TONALLY CONDITIONED VOWEL RAISING 3 Tonally Conditioned Vowel Raising in Shuijingping Mang
- David R. Mortensen. 2012. The emergence of obstruents after high vowels. Abstract: While a few cases of the emergence of obstruents after high vowels are found in the literature (Burling 1966, 1967, Blust 1994), no attempt has been made to comprehensively collect instances of this sound change or give them a unified explanation. This paper attempts to resolve this gap in the literature by introducing a post-vocalic obstruent emergence (POE) as a recurring sound change with a phonetic (aerodynamic) basis. Possible cases are identified in Tibeto-Burman, Austronesian, and Grassfields Bantu. Special attention is given to a novel case in the Tibeto-Burman language Huishu.
- David R. Mortensen. 2011. Lexical prefixes and Tibeto-Burman laryngeal contrasts. Abstract: Proceedings of the 37th Annual Meeting of the Berkeley Linguistics 
Society (2013), pp. 272-286
- David R. Mortensen. 2006. Logical and Substantive Scales in Phonology. Abstract: Logical and Substantive Scales in Phonology by David Roland Mortensen B.A (Utah State University) 2000 M.A. (University of California, Berkeley) 2003 A dissertation submitted in partial fulfillment of the requirements for the degree of Doctor of Philosophy in Linguistics in the GRADUATE DIVISION of the UNIVERSITY OF CALIFORNIA, BERKELEY Committee in charge: Professor Sharon Inkelas (co-chair) Professor James A. Matisoff (co-chair) Professor Larry M. Hyman Professor Johanna Nichols Fall 2006
- David R. Mortensen. 2004. Abstract Scales in Phonology. Abstract: Scales in Phonology David Mortensen dmort@socrates.berkeley.edu University of California, Berkeley
- David R. Mortensen. 2004. The Emergence of Dorsal Stops after High Vowels in Huishu. Abstract: 0. Introduction Huishu, a Tibeto-Burman language of Manipur belonging to the Tangkhul group, features an unusual sound change in which dorsal stop codas are inserted after high vowels in open syllables. Thus PTB *s@y > PTk > *k@.thi > Huishu k@.tik ‘to die’. This development seems both formally and functionally aberrant: epenthesis usually inserts vowels, and consonant epenthesis, when it does occur, usually inserts glides (Blevins to appear).1 I propose that this change and others like it were not motivated by either formal or functional factors. Rather, they result from the conjunction of aerodynamic, acoustic, and perceptual facts, which lead to a systematic misperception (and thus, misinterpretation) of the forms involved in these innovations. This model, I argue, is able to account not only for the general facts surrounding the emergence of consonants after high vowels, but is also able to account for speci c facts of this phenomenon in Huishu.
- David R. Mortensen. 2004. The Development of Tone Sandhi in Western Hmongic : A New Hypothesis. Abstract: The tone sandhi patterns in Western Hmongic languages have been widely discussed from the point of view of synchronic phonology (Downer 1967; Sprigg 1975; Ratliff 1992a), and these discussions have often assumed a certain degree of knowledge of the historical development of these alternations. Specifically, earlier investigators like Downer and Ratliff have pointed out that, especially in Hmong proper (the Chuanqiandian group) and A-Hmao (the Diandongbei group), alternations that look rather different from the point of view of synchronic phonetics are very similar when examined in terms of historical tone categories. Ratliff (1992a, 1992b), Downer (1967) and Niederer (1998:214, passim.) have all presented pictures of the development of these patterns that extend some distance back into the histories of these languages. The goal of the current paper is to extend these insights, supplemented with my own, into a specific proposal about the development of this system of alternations which will provide insight into some of the unusual patterns found in daughter languages.
- David R. Mortensen. 2004. Preliminaries to Mong Leng (Hmong Njua) Phonology. Abstract: Mong Leng (also called Hmong Njua or Green Hmong) is a dialect group within Far Western Hmong, and Mong Leng varieties are mutually intelligible with several other dialects of Far Western Hmong, including Hmong Daw (White Hmong). The Mong Leng speaker population is quite large for a Hmongic language, and there are perhaps 1,245,000 or more speakers worldwide. These speakers are distributed through parts of Southwestern China (Guizhou, Sichuan, and Yunnan provices), Vietnam, Laos, Thailand, Burma and (via migration from Laos) the United States, French Guiana, France, Australia, and several other western nations. This paper is meant as a short sketch of the phonological inventory and phonotactics of Mong Leng. The dialect presented in this paper is a somewhat idealized form of the language variety spoken by Mong Leng emigres from Xieng Khoang province in Laos. A different treatment of a similar dialect of Mong Leng (from Thailand) is to be found in Lyman (1974). Basic information about Hmong Daw (White Hmong) phonology is to be found in Heimbach (1969:xi-xiv, xvii-xxiii), and a different treatment is given by Ratliff (1992:8-13). Wang (1983:16-23) gives a good phonological sketch of the Dananshan dialect of Hmong, closely related to both Mong Leng and Hmong Daw.
- David R. Mortensen. 2003. Hmong Elaborate Expressions are Coordinate Compounds. Abstract: On exposure to Hmong discourse 1 discourse, or that of many other structurally-similar Southeast Asian languages—the speaker of English can hardly help but be impressed by the pervasiveness of parallelism in this discourse tradition. Almost everything seems to be repeated, often in balanced pairs. Of course, parallelism in language is by no means confined to Southeast Asia—as a stylistic device it is ubiquitous. However, in Hmong at least, it is hard to escape the conclusion that parallelism plays a greater role in the grammatical structure of the language than it does in English. In addition to the usual types of stylistic parallelism, Hmong features an impressive array of symmetrical grammatical structures. Of particular interest in this regard are two morphological constructions: headless coordinate compounds consisting of pairs of synonyms, nearsynonyms, antonyms, and converses like caij-nyoog ‘time-time’ (‘time’), num-tswv ‘official-lord’ (‘leader’), andmuag-nug‘sister-brother’ (‘brother and sister’); and socalled elaborate expressions—parallel expressions superficially like the English idioms easy-come easy-go andlike father like son. In this latter category are compounds like
- David R. Mortensen. 2003. Two Kinds of Variable Elements in Hmong Anaphora. Abstract: ∗This paper was made possible by Hmong consultants and teachers too numerous to name exhaustively. However, it would be ungracious not to mention a few individuals who provided data, judgments, and guidance without which this paper could not have come to be. A special debt is owed to Neeb Hawj (Leena Her), Nchais Laaj Hawj, Tshuv Ntxaij Yaaj (Shawn Yang), Xab Yaj (Sa Yang), Ntaub Muas (Dao Moua), and Iab Hawj (Ia Her). 1The Hmong data in this paper are from Mong Leng (also called Green Hmong, Blue Hmong, Blue Meo, Hmong Njua, etc.), a dialect of Hmong spoken by around 1,000,000 speakers in Southern China, Vietnam, Laos, Thailand, and various western countries (due to the Hmong diaspora from Laos following the “Secret War” there). Hmong is a member of the Far Western Hmongic group of the Western Hmongic branch of the Hmongic subfamily, which is, in turn, a member of the Hmong-Mien family. The wider genetic affiliations of Hmong-Mien are undetermined. Like other members of the Hmong-Mien family, Mong Leng is tonal, having 7 contrastive tones. In the RPA orthography used in this paper (and by most Hmong in the West), tones are represented by letters at the end of syllables (-b, -j, -v, -∅, -g, -s, and -m). There are other aspects of this orthography that the naive linguist may not find completely transparent. For example, doubled vowels represent the presence of nasalization or a velar nasal coda. For a good introduction to the sounds and orthographic representation of the closely related Hmong Daw (White Hmong) dialect, see Ratliff (1992). Mong Leng has several sounds not present in Hmong Daw, and these are represented here in the conventional Mong Leng adaptation of the RPA orthography. The only important differences are as follows: [ti ∼ ki], [thi ∼ khi], [nti ∼ Nki], [nthi ∼ Nkhi], and [ aN ∼ a].
- S. Cole, David R. Mortensen, H. H. Kassarjian, V. Mishra, J. DeMott, B. Bagdikian, B. Maddox, C. Degand. 1973. Book Reviews. Abstract: 166 Lippmann, Liberty, and the Press, by John Luskin 167 Ethnic Voters and the Election of Lincoln, edited by Frederick C. Luebke; The Image of Lincoln in the South, by Michael Davis 167 The Paper Revolutionaries: The Rise of the Underground Press, by Laurence Learner; Underground Press Anthology, edited by Thomas King Forcade 168 A History of the Marconi Company, by W. J. Baker 169 The Clocks of Columbus: The Literary Career of James Thurber, by Charles S. Holmes D. Ruben
