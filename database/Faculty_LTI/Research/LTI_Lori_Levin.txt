Lori Levin
Paper count: 174
- Callie E Tyner, J. Slotkin, Pamela A. Kisala, Lori S. Levin, Scott M. Tintle, D. Tulsky. 2023. Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains. Abstract: Upper extremity transplantation offers the promise of restored function and regained quality of life (QOL) for individuals who have sustained hand or arm amputation. However, a major challenge for this procedure becoming an accessible treatment option for patients is the lack of standard measures to document benefits to QOL. Patient-reported outcomes (PRO) measures are well-suited for this kind of intervention, where the perspective of the patient is central to defining treatment success. To date, qualitative work with experts, clinicians, and patients has been used to identify the most important domains of QOL for PRO item development. Specifically, our group’s qualitative work has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures. These include emotional and social aspects of upper extremity transplant, such as Expectations and Perceived Outcomes, Integration and Assimilation of Transplant, Fitting in, and Post-Surgical Challenges and Complications. The broad topic of Satisfaction with Transplant was subdivided into three subtopics: Function, Sensation, and Aesthetics. Satisfaction with Sensation was also identified as a unique domain not evaluated by existing PRO measures. This report operationalizes these eight QOL domains by presenting scoping definitions. This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.
- Yoshiko Toyoda, Lori S. Levin. 2023. What is needed to ensure long-term sustainability for the field of vascularized composite allotransplantation?. Abstract: The field of vascularized composite allotransplantation (VCA) has demonstrated remarkable advances since its inception with some excellent long-term results in a variety of graft types. However, unlike solid organ transplantation, it has yet to become mainstream. We therefore discuss strategies on ensuring long-term sustainability by addressing continued clinical developments of VCA to improve the risk-to-benefit balance, importance of public support, improved policy and financial support, and need for a bridge to the future of transplant surgery. There has been headway on all fronts and collaboration among the VCA centers for centralization of data and incorporation of patient voices will be essential for continued progress.
- S. Azoury, S. Kovach, Lori S. Levin. 2022. Reconstruction Options for Lower Extremity Traumatic Wounds.. Abstract: The senior author first coined the "orthoplastic" approach to traumatic lower extremity reconstruction, by which multidisciplinary surgeons and specialists work together for optimal patient success. The goals of lower extremity salvage are to optimize limb appearance, restore unrestricted pain-free ambulation, and improve quality of life. Composite traumatic defects require an organized approach, and the reconstructive ladder is used for strategies of varying complexity for repair of soft-tissue wounds. The lower rungs of the ladder include simpler reconstructive options such as the use of skin grafts and local flaps, and the higher rungs represent complex techniques such as free tissue transfer. Although there is no notable difference between muscle and fasciocutaneous/perforator flaps in reconstructive outcomes, there has been a trend toward perforator flaps to minimize donor site morbidity.
- Todd J. Levy, Callie E Tyner, S. Amaral, Debra S. Lefkowitz, S. Kessler, Lori S. Levin. 2022. 5-Year Activity and Participation Outcomes of the First Successful Pediatric Bilateral Hand Transplantation: A Case Report. Abstract: Abstract Aims Describe the 5-year outcomes of the first successful pediatric bilateral hand transplantation. Methods The child underwent quadrimembral amputation at age two and received bilateral hand allografts at age eight. Rehabilitation included biomechanical, neurorehabilitation, and occupational approaches in acute and outpatient settings. Therapist observed outcomes, patient-reported measures, and parent-reported measures were repeated over a 5-year period. Results Observation assessments revealed functional dexterity skills and modified independence to full independence with self-care activities. The parent reported the child had moderate difficulty with upper extremity functioning 25-, 41-, and 48-months post-transplantation, and mild difficulty at 60-months; the child reported no difficulties in this domain at 41 months. Five years post-transplantation the child reported enjoying many age-appropriate activities, and high-quality peer relations were endorsed by both parent and child. Conclusion The child developed hand movements for daily activities and was completing daily activities with improved efficiency. Health-related quality of life outcomes were favorable.
- Yoshiko Toyoda, S. Azoury, A. Bauder, Lori S. Levin, S. Kovach. 2022. Lower extremity amputation: the emerging role of targeted muscle reinnervation (TMR) and regenerative peripheral nerve interface (RPNI). Abstract: Lower extremity amputation is increasingly prevalent in the United States, with growing numbers of patients suffering from diabetes and peripheral vascular disease. Amputation has significant functional sequelae as more than half of patients are unable to ambulate at one year postoperatively. Improving mobility and decreasing chronic post-amputation pain can significantly improve the quality of life for these patients and reduce the cost burden on the healthcare system. Plastic and reconstructive surgery has been at the forefront of “reconstructive amputation”, in which nerve pedicles can be surgically guided to decrease painful neuroma formation as well as provide targets for myoelectric prosthesis use. We herein review post-amputation outcomes, epidemiology of chronic, post-amputation pain, and current treatments, including total muscle reinnervation and regenerative peripheral nerve interface, which are at the forefront of multidisciplinary treatment of lower extremity amputees.
- Kevin M. Klifto, S. Azoury, Christopher S. Klifto, S. Mehta, Lori S. Levin, S. Kovach. 2021. Treatment of Posttraumatic Tibial Diaphyseal Bone Defects: A Systematic Review and Meta-Analysis. Abstract: Supplemental Digital Content is Available in the Text. Objective: To describe evidenced-based treatment options for patients who sustained trauma and/or posttraumatic osteomyelitis of the tibia resulting in diaphyseal bone defects and to compare outcomes between patients treated with nonvascularized bone grafts (NBGs), bone transport (BT), or vascularized bone grafts (VBGs). Data Source: The Preferred Reporting Items for Systematic Review and Meta-Analyses of individual participant data and Cochrane guidelines were followed. PubMed, EMBASE, Cochrane Library, Web of Science, Scopus, and CINAHL were searched from inception to June 2020. Study Selection: Patients who were ≥18 years, had sustained trauma to the tibia resulting in fracture and/or osteomyelitis with measurable diaphyseal bone defects, and were treated by interventions such as NBGs, BT, or VBGs were eligible. Excluded studies were non-English, reviews, nonreviewed literature, cadavers, animals, unavailable full texts, nondiaphyseal defects, atrophic nonunions, malignancy, and replantations. Data Extraction: A total of 108 studies were included with 826 patients. Two reviewers systematically/independently screened titles/abstracts, followed by full texts to ensure quality, accuracy, and consensus among authors for inclusion/exclusion of studies. A third reviewer addressed disagreements if investigators were unable to reach a consensus. Studies were quality assessed using “Methodological Quality and Synthesis of Case Series and Case Reports”. Data Synthesis: Analyses were performed with IBM SPSS version 25.0 (IBM Corporation, Armonk, NY) and G*Power3.1.9.2. Conclusions: NBGs may be considered first line for trauma defect sizes ≤ 10 cm or posttraumatic osteomyelitis defect sizes <5 cm. BT may be considered first line for posttraumatic osteomyelitis defect sizes <5 cm. VBGs may be considered first line for trauma and posttraumatic osteomyelitis defect sizes ≥5 cm. Level of Evidence: Therapeutic Level IV. See Instructions for Authors for a complete description of levels of evidence.
- Alfred P Yoon, Yibo Wang, Lu Wang, K. Chung, Kevin C Chung H Myra Kim, S. Haase, J. Lawton, John R. Lien, Adeyiza O. Momoh, K. Ozer, Erika D. Sears, J. Waljee, Matthew S. Brown, H. Cho, B. Michelotti, Sunitha Malay, Melissa J Shauver, T. Rozental, P. Appleton, E. Rodriguez, Laura N. Deschamps, Lindsay Mattfolk, Katiri Wagner Philip Blazar, Brandon E. Earp, W. Floyd, Dexter L. Louie, Raser J Leversedge, M. Richard, D. Ruch, S. Finley, C. Howe, M. Manson, Janna Whitfield, B. Perey, K. Apostle, Dory S. Boyer, F. Moola, T. Stone, D. Viskontas, Mauri Zomar, Karyn Moon, Raely Moon, L. Kalliainen, C. Ward, J. Fletcher, C. Heinrich, Katharine S. Pico, Ashish Y. Mahajan, B. Hill, S. Vang, D. Laporte, E. Hasenboehler, Scott D. Lifchez, G. Osgood, B. Shafiq, J. Shores, V. Laljani, H. B. Bamberger, Timothy W. Harman, D. Martineau, C. Robinson, Brandi Palmer Ruby Grewal, Ken A. Faber, J. Macdermid, Kate Kelly, Katrina Munro, J. Vincent, D. Ring, J. Jupiter, Abigail Finger, Jillian S. Gruber, R. Reddy, Taylor M. Pong, Emily R. Thornton, D. Dennison, S. Kakar, M. Rizzo, Alexander Y. Shin, Tyson L. Scrabeck, K. Chepla, K. Malone, H. Hoyen, B. Bafus, Roderick B. Jordan, Bram R. Kaufman, Ali Totonchil, Dana R. Hromyak, L. Humbert, S. Sebastin, Sally Tay, Kate W Nellans, S. Merwin, Ethan W. Blackburn, Sandra J. Hanlin, Barbara Patterson R Glenn Gaston, R. C. Cadderdon, Erika Gordon Gantt, J. Gaul, Daniel R. Lewis, B. Loeffler, L. K. Osier, P. C. Perlik, W. A. Ward, Benjamin Connell, Pricilla Haug, C. Michalek, T. Clark, S. McRae, J. Moriatis Wolf, C. Rodner, Katy Coyle, T. Lehman, Yuri Lansinger, Gavin D. O'Mahony, Kathy Carl, J. Wells, D. Bozentka, Lori S. Levin, D. Steinberg, A. Horan, Denise Knox, Kara Napolitano John Fowler, R. Goitz, Cathy A. Naccarelli, Joelle Tighe, W. Hammert, A. McIntyre, Krista L. Noble, Kaili Waldrick, Jeffery Friedrich, David Bowman, Angela Wilson Zhongyu Li, L. Koman, Benjamin R. Graves, Beth P. Smith, Debra Bullard. 2021. What Are the Tradeoffs in Outcomes after Casting Versus Surgery for Closed Extraarticular Distal Radius Fractures in Older Patients? A Statistical Learning Model. Abstract: Abstract Background Distal radius fractures (DRFs) are one of the most common major fractures. Despite their frequency, the tradeoffs in different outcomes after casting or surgery for closed extraarticular DRFs in older adults are unknown. Questions/purposes (1) For adults older than 60 years with closed extraarticular DRFs, what are the tradeoffs in outcomes for choosing casting versus surgery? (2) In what settings would surgery be preferred over casting? Method This is a secondary analysis of data from the Wrist and Radius Injury Surgical Trial (WRIST), a randomized, multicenter clinical trial that enrolled patients from April 10, 2012 to December 31, 2016. For WRIST, researchers recruited patients older than 60 years who sustained closed extraarticular distal radius fractures from 24 sites in the United States, Canada, and Singapore. We conducted a secondary analysis using data from WRIST, which had longitudinal data from a robust collection of covariates for patients who underwent surgery and casting. Among the 296 patients recruited in the WRIST study, 59% (174) of patients (mean age 71 ± 9 years) with complete sociodemographic data and 12-month follow-up for each primary outcome were included in the main analysis. More patients underwent surgery than casting (72% [126 of 174] versus 28% [48 of 174]). Most sociodemographic variables were similar between the surgery and casting groups, except for age and volar tilt. The surgical cohort was composed of patients randomized to external fixation, closed reduction percutaneous pinning, or volar locking plate internal fixation. The casting cohort consisted of patients who elected to be treated with closed reduction and casting. A tree-based reinforcement statistical learning method was used to determine the best treatment, either surgery or casting, to maximize functional and esthetic outcomes while minimizing pain. Tree-based reinforcement learning is a statistical learning method to build an unsupervised decision tree within a causal inference framework that will identify useful variables and their cutoff values to tailor treatment assignment accordingly to achieve the best health outcome desired. The primary outcome was minimization of pain (12-month Michigan Hand Outcomes Questionnaire pain subdomain score), maximization of grip strength, total ROM (supination and wrist arc of motion), and esthetics (12-month Michigan Hand Outcomes Questionnaire esthetics subdomain score). Results Casting was the best treatment to reduce pain and maximize esthetics, whereas surgery maximized grip strength and ROM. When the patient favored gaining ROM over pain reduction (more than 80:20), surgery was the preferred treatment. When the patient prioritized the importance of grip strength over pain reduction (more than 70:30), surgery was also the preferred treatment. Conclusion There are tradeoffs in outcomes after treating patients older than 60 years with closed extraarticular distal radius fractures with casting or surgery. When patients are attempting to balance minimizing pain and improving functional outcomes, unless they desire maximal functional recovery, casting may be the better treatment. Surgery may be beneficial if patients want to regain as much grip strength and ROM as possible, even with the possibility of having residual pain. These findings can be referenced for more concrete preoperative counseling and patient expectation management before treatment selection. Level of Evidence Level III, therapeutic study.
- Naoki Otani, Satoru Ozaki, Xingyuan Zhao, Y. Li, Micaelah St Johns, Lori S. Levin. 2020. Pre-tokenization of Multi-word Expressions in Cross-lingual Word Embeddings. Abstract: Cross-lingual word embedding (CWE) algorithms represent words in multiple languages in a unified vector space. Multi-Word Expressions (MWE) are common in every language. When training word embeddings, each component word of an MWE gets its own separate embedding, and thus, MWEs are not translated by CWEs. We propose a simple method for word translation of MWEs to and from English in ten languages: we first compile lists of MWEs in each language and then tokenize the MWEs as single tokens before training word embeddings. CWEs are trained on a word-translation task using the dictionaries that only contain single words. In order to evaluate MWE translation, we created bilingual word lists from multilingual WordNet that include single-token words and MWEs, and most importantly, include MWEs that correspond to single words in another language. We release these dictionaries to the research community. We show that the pre-tokenization of MWEs as single tokens performs better than averaging the embeddings of the individual tokens of the MWE. We can translate MWEs at a top-10 precision of 30-60%. The tokenization of MWEs makes the occurrences of single words in a training corpus more sparse, but we show that it does not pose negative impacts on single-word translations.
- Zhisong Zhang, X. Kong, Lori S. Levin, E. Hovy. 2020. An Empirical Exploration of Local Ordering Pre-training for Structured Learning. Abstract: Recently, pre-training contextualized encoders with language model (LM) objectives has been shown an effective semi-supervised method for structured prediction. In this work, we empirically explore an alternative pre-training method for contextualized encoders. Instead of predicting words in LMs, we “mask out” and predict word order information, with a local ordering strategy and word-selecting objectives. With evaluations on three typical structured prediction tasks (dependency parsing, POS tagging, and NER) over four languages (English, Finnish, Czech, and Italian), we show that our method is consistently beneficial. We further conduct detailed error analysis, including one that examines a specific type of parsing error where the head is misidentified. The results show that pre-trained contextual encoders can bring improvements in a structured way, suggesting that they may be able to capture higher-order patterns and feature combinations from unlabeled data.
- Xingyuan Zhao, Satoru Ozaki, Antonios Anastasopoulos, Graham Neubig, Lori S. Levin. 2020. Automatic Interlinear Glossing for Under-Resourced Languages Leveraging Translations. Abstract: Interlinear Glossed Text (IGT) is a widely used format for encoding linguistic information in language documentation projects and scholarly papers. Manual production of IGT takes time and requires linguistic expertise. We attempt to address this issue by creating automatic glossing models, using modern multi-source neural models that additionally leverage easy-to-collect translations. We further explore cross-lingual transfer and a simple output length control mechanism, further refining our models. Evaluated on three challenging low-resource scenarios, our approach significantly outperforms a recent, state-of-the-art baseline, particularly improving on overall accuracy as well as lemma and tag recall.
- W. Piwnica-Worms, John T. Stranix, S. Othman, Geoffrey M. Kozak, Ilaina Moyer, A. Spencer, S. Azoury, Lori S. Levin, S. Kovach. 2020. Risk Factors for Lower Extremity Amputation Following Attempted Free Flap Limb Salvage. Abstract: Abstract Background Traumatic limb salvage with free flap reconstruction versus primary amputation for lower extremity (LE) injuries remains an oft debated topic. Limb salvage has well-studied benefits and advances in microsurgery have helped reduce the complication rates. A subset of patients eventually requires secondary amputation after a failed attempt at limb salvage. A better understanding of risk factors that predict subsequent amputation after failed free flap reconstruction of LE injuries may improve operative management. Patients and Methods A retrospective study (2002–2019) was conducted on all patients who underwent free flap reconstruction of the LE within 120 days of the original inciting event at a single institution. Patient and operative factors were reviewed including comorbidities, severity of the injury, flap choice, outcomes, and complications. Predictors of subsequent amputation were analyzed. Results A total of 129 patients requiring free flap reconstructions for LE limb salvage met inclusion criteria. Anterolateral thigh flaps (70.5%) were performed most frequently. Secondary amputation occurred in 10 (7.8%) patients. Preoperative factors associated with eventual amputation include diabetes mellitus (p = 0.044), number of preoperative debridements (p = 0.013), evidence of any arterial injury/pathology (p = 0.008), specifically posterior tibial artery (p = < 0.0001), and degree of three-vessel runoff (p = 0.007). Operative factors associated with subsequent amputation include evidence of recipient artery injury/pathology (p = 0.008). Postoperative factors associated with secondary amputation include total flap failure (p = 0.001), partial flap failure (p = 0.002), minor complications (p = 0.037), and residual osteomyelitis (p = 0.028). Conclusion Many factors contribute to the reconstructive surgical team's decision to proceed with limb salvage or perform primary amputation. Several variables are associated with failed limb salvage resulting in secondary amputation. Further studies are required to better guide management during the limb salvage process.
- Lane Schwartz, Francis M. Tyers, Lori S. Levin, Christo Kirov, Patrick Littell, Chi-kiu (羅致翹) Lo, Emily Prudhommeaux, Hyunji Hayley Park, K. Steimel, Rebecca Knowles, J. Micher, Lonny Strunk, Han Liu, Coleman Haley, Katherine J. Zhang, Robbie Jimmerson, Vasilisa Andriyanets, Aldrian Obaja Muis, Naoki Otani, J. Park, Zhisong Zhang. 2020. Neural Polysynthetic Language Modelling. Abstract: Research in natural language processing commonly assumes that approaches that work well for English and and other widely-used languages are "language agnostic". In high-resource languages, especially those that are analytic, a common approach is to treat morphologically-distinct variants of a common root as completely independent word types. This assumes, that there are limited morphological inflections per root, and that the majority will appear in a large enough corpus, so that the model can adequately learn statistics about each form. Approaches like stemming, lemmatization, or subword segmentation are often used when either of those assumptions do not hold, particularly in the case of synthetic languages like Spanish or Russian that have more inflection than English. 
In the literature, languages like Finnish or Turkish are held up as extreme examples of complexity that challenge common modelling assumptions. Yet, when considering all of the world's languages, Finnish and Turkish are closer to the average case. When we consider polysynthetic languages (those at the extreme of morphological complexity), approaches like stemming, lemmatization, or subword modelling may not suffice. These languages have very high numbers of hapax legomena, showing the need for appropriate morphological handling of words, without which it is not possible for a model to capture enough word statistics. 
We examine the current state-of-the-art in language modelling, machine translation, and text prediction for four polysynthetic languages: Guarani, St. Lawrence Island Yupik, Central Alaskan Yupik, and Inuktitut. We then propose a novel framework for language modelling that combines knowledge representations from finite-state morphological analyzers with Tensor Product Representations in order to enable neural language models capable of handling the full range of typologically variant languages.
- Zhong Zhou, Lori S. Levin, David R. Mortensen, A. Waibel. 2019. Using Interlinear Glosses as Pivot in Low-Resource Multilingual Machine Translation.. Abstract: We demonstrate a new approach to Neural Machine Translation (NMT) for low-resource languages using a ubiquitous linguistic resource, Interlinear Glossed Text (IGT). IGT represents a non-English sentence as a sequence of English lemmas and morpheme labels. As such, it can serve as a pivot or interlingua for NMT. Our contribution is four-fold. Firstly, we pool IGT for 1,497 languages in ODIN (54,545 glosses) and 70,918 glosses in Arapaho and train a gloss-to-target NMT system from IGT to English, with a BLEU score of 25.94. We introduce a multilingual NMT model that tags all glossed text with gloss-source language tags and train a universal system with shared attention across 1,497 languages. Secondly, we use the IGT gloss-to-target translation as a key step in an English-Turkish MT system trained on only 865 lines from ODIN. Thirdly, we we present five metrics for evaluating extremely low-resource translation when BLEU is no longer sufficient and evaluate the Turkish low-resource system using BLEU and also using accuracy of matching nouns, verbs, agreement, tense, and spurious repetition, showing large improvements.
- Zhong Zhou, Lori S. Levin, David R. Mortensen, A. Waibel. 2019. Low-Resource Machine Translation using Interlinear Glosses. Abstract: Neural Machine Translation (NMT) does not handle low-resource translation well because NMT is data-hungry and low-resource languages, by their nature, have limited parallel data. Many low-resource languages are morphologically rich, which complicates matters further by increasing data sparsity. However, a good linguist is capable of building a morphological analyzer in far fewer hours than it would take to collect and translate the amount of parallel data needed for conventional NMT. We combine the benefits of both NMT and linguistic information in our work. We use morphological analyzer to automatically generate interlinear glosses with dictionary or parallel data, and translate the source text to interlinear gloss as an interlingua representation, and finally translate into the target text using NMT trained on the ODIN dataset that includes a large collection of interlinear glosses and their corresponding target translations. Our result for translating from the interlinear gloss to the target text using the entire ODIN dataset achieves a BLEU score of 35.07. And our qualitative results show positive findings in a low-resource scenario of Turkish-English translation using 865 lines of training data. Our translation system yield better results than training NMT directly from the source language to the target language in a constrained-data setting, and is helpful to produce translation with sufficiently good content and fluency when data is scarce.
- M. Duan, Carlos Fasola, Sai Krishna Rallabandi, R. Vega, Antonios Anastasopoulos, Lori S. Levin, A. Black. 2019. A Resource for Computational Experiments on Mapudungun. Abstract: We present a resource for computational experiments on Mapudungun, a polysynthetic indigenous language spoken in Chile with upwards of 200 thousand speakers. We provide 142 hours of culturally significant conversations in the domain of medical treatment. The conversations are fully transcribed and translated into Spanish. The transcriptions also include annotations for code-switching and non-standard pronunciations. We also provide baseline results on three core NLP tasks: speech recognition, speech synthesis, and machine translation between Spanish and Mapudungun. We further explore other applications for which the corpus will be suitable, including the study of code-switching, historical orthography change, linguistic structure, and sociological and anthropological studies.
- Aditi Chaudhary, Siddharth Dalmia, Junjie Hu, Xinjian Li, Austin Matthews, Aldrian Obaja Muis, Naoki Otani, Shruti Rijhwani, Zaid A. W. Sheikh, Nidhi Vyas, Xinyi Wang, Jiateng Xie, Ruochen Xu, Chunting Zhou, Peter J. Jansen, Yiming Yang, Lori S. Levin, Florian Metze, T. Mitamura, David R. Mortensen, Graham Neubig, E. Hovy, A. Black, J. Carbonell, Graham Horwood, Shabnam Tafreshi, Mona T. Diab, Efsun Sarioglu Kayi, N. Farra, K. McKeown. 2019. The ARIEL-CMU Systems for LoReHLT18. Abstract: This paper describes the ARIEL-CMU submissions to the Low Resource Human Language Technologies (LoReHLT) 2018 evaluations for the tasks Machine Translation (MT), Entity Discovery and Linking (EDL), and detection of Situation Frames in Text and Speech (SF Text and Speech).
- Lori S. Levin. 2018. Annotation Schemes for Surface Construction Labeling. Abstract: In this talk I will describe the interaction of linguistics and language technologies in Surface Construction Labeling (SCL) from the perspective of corpus annotation tasks such as definiteness, modality, and causality. Linguistically, following Construction Grammar, SCL recognizes that meaning may be carried by morphemes, words, or arbitrary constellations of morpho-lexical elements. SCL is like Shallow Semantic Parsing in that it does not attempt a full compositional analysis of meaning, but rather identifies only the main elements of a semantic frame, where the frames may be invoked by constructions as well as lexical items. Computationally, SCL is different from tasks such as information extraction in that it deals only with meanings that are expressed in a conventional, grammaticalized way and does not address inferred meanings. I review the work of Dunietz (2018) on the labeling of causal frames including causal connectives and cause and effect arguments. I will describe how to design an annotation scheme for SCL, including isolating basic units of form and meaning and building a “constructicon”. I will conclude with remarks about the nature of universal categories and universal meaning representations in language technologies. This talk describes joint work with Jaime Carbonell, Jesse Dunietz, Nathan Schneider, and Miriam Petruck.
- Jesse Dunietz, J. Carbonell, Lori S. Levin. 2018. DeepCx: A transition-based approach for shallow semantic parsing with complex constructional triggers. Abstract: This paper introduces the surface construction labeling (SCL) task, which expands the coverage of Shallow Semantic Parsing (SSP) to include frames triggered by complex constructions. We present DeepCx, a neural, transition-based system for SCL. As a test case for the approach, we apply DeepCx to the task of tagging causal language in English, which relies on a wider variety of constructions than are typically addressed in SSP. We report substantial improvements over previous tagging efforts on a causal language dataset. We also propose ways DeepCx could be extended to still more difficult constructions and to other semantic domains once appropriate datasets become available.
- Patrick Littell, R. Thomas McCoy, Na-Rae Han, Shruti Rijhwani, Zaid A. W. Sheikh, David R. Mortensen, T. Mitamura, Lori S. Levin. 2018. Parser combinators for Tigrinya and Oromo morphology. Abstract: We present rule-based morphological parsers in the Tigrinya and Oromo languages, based on a parser-combinator rather than finite-state paradigm. This paradigm allows rapid development and ease of integration with other systems, although at the cost of non-optimal theoretical efficiency. These parsers produce multiple output representations simultaneously, including lemmatization, morphological segmentation, and an English word-for-word gloss, and we evaluate these representations as input for entity detection and linking and humanitarian need detection.
- Aditi Chaudhary, Chunting Zhou, Lori S. Levin, Graham Neubig, David R. Mortensen, J. Carbonell. 2018. Adapting Word Embeddings to New Languages with Morphological and Phonological Subword Representations. Abstract: Much work in Natural Language Processing (NLP) has been for resource-rich languages, making generalization to new, less-resourced languages challenging. We present two approaches for improving generalization to low-resourced languages by adapting continuous word representations using linguistically motivated subword units: phonemes, morphemes and graphemes. Our method requires neither parallel corpora nor bilingual dictionaries and provides a significant gain in performance over previous methods relying on these resources. We demonstrate the effectiveness of our approaches on Named Entity Recognition for four languages, namely Uyghur, Turkish, Bengali and Hindi, of which Uyghur and Bengali are low resource languages, and also perform experiments on Machine Translation. Exploiting subwords with transfer learning gives us a boost of +15.2 NER F1 for Uyghur and +9.7 F1 for Bengali. We also show improvements in the monolingual setting where we achieve (avg.) +3 F1 and (avg.) +1.35 BLEU.
- Jesse Dunietz, Lori S. Levin, J. Carbonell. 2017. The BECauSE Corpus 2.0: Annotating Causality and Overlapping Relations. Abstract: Language of cause and effect captures an essential component of the semantics of a text. However, causal language is also intertwined with other semantic relations, such as temporal precedence and correlation. This makes it difficult to determine when causation is the primary intended meaning. This paper presents BECauSE 2.0, a new version of the BECauSE corpus with exhaustively annotated expressions of causal language, but also seven semantic relations that are frequently co-present with causation. The new corpus shows high inter-annotator agreement, and yields insights both about the linguistic expressions of causation and about the process of annotating co-present semantic relations.
- Jesse Dunietz, Lori S. Levin, J. Carbonell. 2017. Automatically Tagging Constructions of Causation and Their Slot-Fillers. Abstract: This paper explores extending shallow semantic parsing beyond lexical-unit triggers, using causal relations as a test case. Semantic parsing becomes difficult in the face of the wide variety of linguistic realizations that causation can take on. We therefore base our approach on the concept of constructions from the linguistic paradigm known as Construction Grammar (CxG). In CxG, a construction is a form/function pairing that can rely on arbitrary linguistic and semantic features. Rather than codifying all aspects of each construction’s form, as some attempts to employ CxG in NLP have done, we propose methods that offload that problem to machine learning. We describe two supervised approaches for tagging causal constructions and their arguments. Both approaches combine automatically induced pattern-matching rules with statistical classifiers that learn the subtler parameters of the constructions. Our results show that these approaches are promising: they significantly outperform naïve baselines for both construction recognition and cause and effect head matches.
- Jesse Dunietz, Lori S. Levin, Miriam R. L. Petruck. 2017. Construction Detection in a Conventional NLP Pipeline. Abstract: This paper presents an approach to detecting constructions based on a conventional NLP pipeline: the “constructions on top” approach to integrating constructions into NLP, as opposed to “constructions all the way down.” The approach is illustrated with the BECauSE corpus of causal language, the BECauSE constructicon, and the Causeway causal language detector, described elsewhere. We argue here that although BECauSE is not a full construction grammar, its lightweight design and compatibility with conventional NLP tools have facilitated progress on and insights into issues related to construction detection in news corpora. The issues we discuss are (1) individuating families of constructions, and (2) dealing with co-present, non-prototypical meanings that may be present alongside the prototypical meaning of a construction. Particularly signiﬁcant is the observation that the BECauSE constructicon highlights the importance of integrating frame-evoking constructions into frame semantic resources such as FrameNet.
- Lori S. Levin, Patrick Littell, David R. Mortensen, Ke Lin, Katherine Kairis, Carlisle Turner. 2017. URIEL and lang2vec: Representing languages as typological, geographical, and phylogenetic vectors. Abstract: We introduce the URIEL knowledge base for massively multilingual NLP and the lang2vec utility, which provides information-rich vector identifications of languages drawn from typological, geographical, and phylogenetic databases and normalized to have straightforward and consistent formats, naming, and semantics. The goal of URIEL and lang2vec is to enable multilingual NLP, especially on less-resourced languages and make possible types of experiments (especially but not exclusively related to NLP tasks) that are otherwise difficult or impossible due to the sparsity and incommensurability of the data sources. lang2vec vectors have been shown to reduce perplexity in multilingual language modeling, when compared to one-hot language identification vectors.
- Patrick Littell, Kartik Goyal, David R. Mortensen, Alexa Little, Chris Dyer, Lori S. Levin. 2016. Named Entity Recognition for Linguistic Rapid Response in Low-Resource Languages: Sorani Kurdish and Tajik. Abstract: This paper describes our construction of named-entity recognition (NER) systems in two Western Iranian languages, Sorani Kurdish and Tajik, as a part of a pilot study of “Linguistic Rapid Response” to potential emergency humanitarian relief situations. In the absence of large annotated corpora, parallel corpora, treebanks, bilingual lexica, etc., we found the following to be effective: exploiting distributional regularities in monolingual data, projecting information across closely related languages, and utilizing human linguist judgments. We show promising results on both a four-month exercise in Sorani and a two-day exercise in Tajik, achieved with minimal annotation costs.
- Patrick Littell, David R. Mortensen, Kartik Goyal, Chris Dyer, Lori S. Levin. 2016. Bridge-Language Capitalization Inference in Western Iranian: Sorani, Kurmanji, Zazaki, and Tajik. Abstract: In Sorani Kurdish, one of the most useful orthographic features in named-entity recognition – capitalization – is absent, as the language’s Perso-Arabic script does not make a distinction between uppercase and lowercase letters. We describe a system for deriving an inferred capitalization value from closely related languages by phonological similarity, and illustrate the system using several related Western Iranian languages.
- Yulia Tsvetkov, Sunayana Sitaram, Manaal Faruqui, Guillaume Lample, Patrick Littell, David R. Mortensen, A. Black, Lori S. Levin, Chris Dyer. 2016. Polyglot Neural Language Models: A Case Study in Cross-Lingual Phonetic Representation Learning. Abstract: We introduce polyglot language models, recurrent neural network models trained to predict symbol sequences in many different languages using shared representations of symbols and conditioning on typological information about the language to be predicted. We apply these to the problem of modeling phone sequences---a domain in which universal symbol inventories and cross-linguistically shared feature representations are a natural fit. Intrinsic evaluation on held-out perplexity, qualitative analysis of the learned representations, and extrinsic evaluation in two downstream applications that make use of phonetic features show (i) that polyglot models better generalize to held-out data than comparable monolingual models and (ii) that polyglot phonetic feature representations are of higher quality than those learned monolingually.
- Lori S. Levin, A. Lavie, M. Woszczyna, D. Gates, Marsal Gavaldà, D. Koll, A. Waibel. 2016. The Janus-III Translation System: Speech-toSpeech Translation in Multiple. Abstract: The Janus-III system translates spoken languages in limited domains. The current re- search focus is on expanding beyond tasks involving a single limited semantic domain to significantly broader and richer domains. To achieve this goal, The MT components of our system have been engineered to build and manipulate multi-domain parse lattices that are based on modular grammars for multiple semantic domains. This approach yields solutions to several problems including multi- domain disambiguation, segmentation of spoken utterances into sentence units, modularity of system design, and re-use of earlier systems with incompatible output.
- David R. Mortensen, Patrick Littell, Akash Bharadwaj, Kartik Goyal, Chris Dyer, Lori S. Levin. 2016. PanPhon: A Resource for Mapping IPA Segments to Articulatory Feature Vectors. Abstract: This paper contributes to a growing body of evidence that—when coupled with appropriate machine-learning techniques–linguistically motivated, information-rich representations can outperform one-hot encodings of linguistic data. In particular, we show that phonological features outperform character-based models. PanPhon is a database relating over 5,000 IPA segments to 21 subsegmental articulatory features. We show that this database boosts performance in various NER-related tasks. Phonologically aware, neural CRF models built on PanPhon features are able to perform better on monolingual Spanish and Turkish NER tasks that character-based models. They have also been shown to work well in transfer models (as between Uzbek and Turkish). PanPhon features also contribute measurably to Orthography-to-IPA conversion tasks.
- Chu-Cheng Lin, Waleed Ammar, Chris Dyer, Lori S. Levin. 2015. Unsupervised POS Induction with Word Embeddings. Abstract: Unsupervised word embeddings have been shown to be valuable as features in supervised learning problems; however, their role in unsupervised problems has been less thoroughly explored. In this paper, we show that embeddings can likewise add value to the problem of unsupervised POS induction. In two representative models of POS induction, we replace multinomial distributions over the vocabulary with multivariate Gaussian distributions over word embeddings and observe consistent improvements in eight languages. We also analyze the effect of various choices while inducing word embeddings on "downstream" POS induction results.
- Jesse Dunietz, Lori S. Levin, J. Carbonell. 2015. Annotating Causal Language Using Corpus Lexicography of Constructions. Abstract: Detecting and analyzing causal language is essential to extracting semantic relationships. To that end, we present an annotation scheme for English causal language (not metaphysical causality), and discuss two methodologies for annotation. The first uses only a coding manual to train annotators in distinguishing causal from non-causal language. To address low inter-coder agreement, we adopted a second methodology, in which we first created a causal language constructicon based on corpus analysis, then required annotators only to annotate instances based on the constructicon. (This resembles the methodology used for annotating the FrameNet and PropBank corpora.) Our contributions, in addition to the annotation scheme itself, are methodological: we discuss when constructicon-based methodology is appropriate, and address the validity of annotation schemes that require expertlevel metalinguistic awareness.
- Emily M. Bender, Lori S. Levin, Stefan Müller, Y. Parmentier, Aarne Ranta. 2015. Proceedings of the Grammar Engineering Across Frameworks (GEAF) 2015 Workshop. Abstract: Grammar Engineering Across Frameworks (GEAF) 2015 took place on 30 July 2015 in Beijing. This workshop builds on several previous workshop on the same topic, namely GEAF 2007 at the LSA Linguistic Institute at Stanford, GEAF 2008 at COLING in Manchester, GEAF 2009 at ACL/IJCNLP in Singapore and HMGE 2013 at ESSLLI 2013 in Dusseldorf. 
Grammar engineering, the practice of developing linguistically motivated grammars in software, is an active area of research in computational linguistics and comprises contemporary works across many different theoretical frameworks. The fruits of grammar engineering, namely linguistically motivated grammars which in many cases provide rich, detailed semantic representations, support the development of natural language technologies, including both natural language understanding and generation, that derive much more information from the linguistic signal than is otherwise possible. The goal of this workshop is to bring together researchers working in grammar engineering and to advance the state of the art in this field. In addition to the nine papers included in these proceedings, the workshop featured a panel discussion on how grammar engineering can continue to be relevant in computational linguistics. The panel addressed questions such as, What are the strengths of grammars that cannot be ignored? What success stories do we have? What should be done differently? And what can we learn from other approaches?
- Maite Taboada, Lori S. Levin, A. Waibel, N. Green, A. Lavie. 2015. Discourse Information for Disambiguation The Phoenix Approach in JANUS M S Project Report. Abstract: For any given utterance out of what we can loosely call context there is usually more than one possible interpretation A speaker s utterance of an elliptical expression like the gure twelve fteen might have a di erent meaning depending on the discourse context the way the conver sation has evolved until that point and the previous speaker s utterance If this is a problem for any human listener the problem grows considerably when it is a parser doing the disambiguation In this project I intend to help a parser disambiguate among di erent possible parses for an input sentence with the nal goal of improving the translation in an end to end speech translation system
- Lori S. Levin, T. Mitamura, B. MacWhinney, Davida Fromm, J. Carbonell, Wes Feely, R. Frederking, A. Gershman, Carlos Ramírez. 2014. Resources for the Detection of Conventionalized Metaphors in Four Languages. Abstract: This paper describes a suite of tools for extracting conventionalized metaphors in English, Spanish, Farsi, and Russian. The method depends on three significant resources for each language: a corpus of conventionalized metaphors, a table of conventionalized conceptual metaphors (CCM table), and a set of extraction rules. Conventionalized metaphors are things like “escape from poverty” and “burden of taxation”. For each metaphor, the CCM table contains the metaphorical source domain word (such as “escape”) the target domain word (such as “poverty”) and the grammatical construction in which they can be found. The extraction rules operate on the output of a dependency parser and identify the grammatical configurations (such as a verb with a prepositional phrase complement) that are likely to contain conventional metaphors. We present results on detection rates for conventional metaphors and analysis of the similarity and differences of source domains for conventional metaphors in the four languages.
- Wes Feely, Mehdi Manshadi, R. Frederking, Lori S. Levin. 2014. The CMU METAL Farsi NLP Approach. Abstract: While many high-quality tools are available for analyzing major languages such as English, equivalent freely-available tools for important but lower-resourced languages such as Farsi are more difficult to acquire and integrate into a useful NLP front end. We report here on an accurate and efficient Farsi analysis front end that we have assembled, which may be useful to others who wish to work with written Farsi. The pre-existing components and resources that we incorporated include the Carnegie Mellon TurboParser and TurboTagger (Martins et al., 2010) trained on the Dadegan Treebank (Rasooli et al., 2013), the Uppsala Farsi text normalizer PrePer (Seraji, 2013), the Uppsala Farsi tokenizer (Seraji et al., 2012a), and Jon Dehdaris PerStem (Jadidinejad et al., 2010). This set of tools (combined with additional normalization and tokenization modules that we have developed and made available) achieves a dependency parsing labeled attachment score of 89.49%, unlabeled attachment score of 92.19%, and label accuracy score of 91.38% on a held-out parsing test data set. All of the components and resources used are freely available. In addition to describing the components and resources, we also explain the rationale for our choices.
- Lori S. Levin. 2014. Keynote Lecture 3: Modeling Non-Propositional Semantics. Abstract: By non-propositional semantics, we mean things other than semantic roles that are expressed in a single sentence and tend to be grammaticalized. These include tense, aspect, modality, existence, possession, causality, conditionality, comparison, quantification, and definiteness. Non-propositional semantic categories evade definition because they are prototypes, not discrete categories. The centroids match across languages, but the extensions of the prototypes do not match. Furthermore, the grammaticalization of non-propositional semantics varies widely, including lexical items, affixes, and syntactic constructions, making cross-linguistic models difficult. In this talk we will focus on definiteness. Definiteness differs widely in grammaticalization across languages. We will present an annotation scheme that captures the semantic points that are relevant for definiteness across languages and logistic regression model of definiteness for English.
- Archna Bhatia, M. Simons, Lori S. Levin, Yulia Tsvetkov, Chris Dyer, J. Bender. 2014. A Unified Annotation Scheme for the Semantic/Pragmatic Components of Definiteness. Abstract: We present a definiteness annotation scheme that captures the semantic, pragmatic, and discourse information, which we call communicative functions, associated with linguistic descriptions such as “a story about my speech”, “the story”, “every time I give it”, “this slideshow”. A survey of the literature suggests that definiteness does not express a single communicative function but is a grammaticalization of many such functions, for example, identifiability, familiarity, uniqueness, specificity. Our annotation scheme unifies ideas from previous research on definiteness while attempting to remove redundancy and make it easily annotatable. This annotation scheme encodes the communicative functions of definiteness rather than the grammatical forms of definiteness. We assume that the communicative functions are largely maintained across languages while the grammaticalization of this information may vary. One of the final goals is to use our semantically annotated corpora to discover how definiteness is grammaticalized in different languages. We release our annotated corpora for English and Hindi, and sample annotations for Hebrew and Russian, together with an annotation manual.
- Chu-Cheng Lin, Waleed Ammar, Lori S. Levin, Chris Dyer. 2014. The CMU Submission for the Shared Task on Language Identification in Code-Switched Data. Abstract: We describe the CMU submission for the 2014 shared task on language identification in code-switched data. We participated in all four language pairs: Spanish‐English, Mandarin‐English, Nepali‐English, and Modern Standard Arabic‐Arabic dialects. After describing our CRF-based baseline system, we discuss three extensions for learning from unlabeled data: semi-supervised learning, word embeddings, and word lists.
- Archna Bhatia, Chu-Cheng Lin, Nathan Schneider, Yulia Tsvetkov, Fatima Al-Raisi, Laleh Roostapour, J. Bender, Abhimanu Kumar, Lori S. Levin, M. Simons, Chris Dyer. 2014. Automatic Classification of Communicative Functions of Definiteness. Abstract: Definiteness expresses a constellation of semantic, pragmatic, and discourse properties—the communicative functions—of an NP. We present a supervised classifier for English NPs that uses lexical, morphological, and syntactic features to predict an NP’s communicative function in terms of a language-universal classification scheme. Our classifiers establish strong baselines for future work in this neglected area of computational semantic analysis. In addition, analysis of the features and learned parameters in the model provides insight into the grammaticalization of definiteness in English, not all of which is obvious a priori.
- Patrick Littell, Kaitlyn Price, Lori S. Levin. 2014. Morphological parsing of Swahili using crowdsourced lexical resources. Abstract: We describe a morphological analyzer for the Swahili language, written in an extension of XFST/LEXC intended for the easy declaration of morphophonological patterns and importation of lexical resources. Our analyzer was supplemented extensively with data from the Kamusi Project (kamusi.org), a user-contributed multilingual dictionary. Making use of this resource allowed us to achieve wide lexical coverage quickly, but the heterogeneous nature of user-contributed content also poses some challenges when adapting it for use in an expert system.
- Yulia Tsvetkov, Chris Dyer, Lori S. Levin, Archna Bhatia. 2013. Generating English Determiners in Phrase-Based Translation with Synthetic Translation Options. Abstract: We propose a technique for improving the quality of phrase-based translation systems by creating synthetic translation options—phrasal translations that are generated by auxiliary translation and postediting processes—to augment the default phrase inventory learned from parallel data. We apply our technique to the problem of producing English determiners when translating from Russian and Czech, languages that lack definiteness morphemes. Our approach augments the English side of the phrase table using a classifier to predict where English articles might plausibly be added or removed, and then we decode as usual. Doing so, we obtain significant improvements in quality relative to a standard phrase-based baseline and to a to post-editing complete translations with the classifier.
- Jesse Dunietz, Lori S. Levin, J. Carbonell. 2013. The Effects of Lexical Resource Quality on Preference Violation Detection. Abstract: Lexical resources such as WordNet and VerbNet are widely used in a multitude of NLP tasks, as are annotated corpora such as treebanks. Often, the resources are used as-is, without question or examination. This practice risks missing significant performance gains and even entire techniques. This paper addresses the importance of resource quality through the lens of a challenging NLP task: detecting selectional preference violations. We present DAVID, a simple, lexical resource-based preference violation detector. With asis lexical resources, DAVID achieves an F1-measure of just 28.27%. When the resource entries and parser outputs for a small sample are corrected, however, the F1-measure on that sample jumps from 40% to 61.54%, and performance on other examples rises, suggesting that the algorithm becomes practical given refined resources. More broadly, this paper shows that resource quality matters tremendously, sometimes even more than algorithmic improvements.
- Lori S. Levin, David A. Evans, D. Gates. 2013. The ALICE System: A Workbench for Learning and Using Language.. Abstract: ALICE is a multi-media framework for ICALI programs that is being developed at Carnegie Mellon University. It is not a single instructional program, but rather a set of tools for building a number of different types of ICALI programs in any language. The central components of ALICE are (1) a set of Natural Language Processing (NLP) tools for syntactic error detection, morphological analysis, and generation of morphological paradigms, (2) a set of on-line text, video, and audio corpora that serve as sources of realistic, in-context examples, and (3) an authoring language that allows teachers to configure the NLP tools and excerpts from the corpora into ICALI programs. This paper describes the NLP components of ALICE and the role of excerpts from corpora in treating student errors.
- Patrick Littell, Lori S. Levin, Jason Eisner, Dragomir R. Radev. 2013. Introducing Computational Concepts in a Linguistics Olympiad. Abstract: Linguistics olympiads, now offered in more than 20 countries, provide secondary-school students a compelling introduction to an unfamiliar field. The North American Computational Linguistics Olympiad (NACLO) includes computational puzzles in addition to purely linguistic ones. This paper explores the computational subject matter we seek to convey via NACLO, as well as some of the challenges that arise when adapting problems in computational linguistics to an audience that may have no background in computer science, linguistics, or advanced mathematics. We present a small library of reusable design patterns that have proven useful when composing puzzles appropriate for secondary-school students. 1 What is a Linguistics Olympiad? A linguistics olympiad (LO) (Payne and Derzhanski, 2010) is a puzzle contest for secondary-school students in which contestants compete to solve self-contained linguistics problem sets. LOs have their origin in the Moscow Traditional Olympiad in Linguistics, established in 1965, and have since spread around the world; an international contest (http://www.ioling.org) has been held yearly since 2003. In an LO, every problem set is self-contained, so no prior experience in linguistics is necessary to compete. In fact, LO contests are fun and rewarding for exactly this reason: by the end of the contest, contestants are managing to read hieroglyphics, conjugate verbs in Swahili, and perform other amazing feats. Furthermore, they have accomplished this solely through their own analytical abilities and linguistic intuition. Based on our experience going into high schools and presenting our material, this “linguistic” way of thinking about languages almost always comes as a novel surprise to students. They largely think about languages as collections of known facts that you learn in classes and from books, not something that you can dive into and figure out for yourself. This is a hands-on antidote to the common public misconception that linguists are fundamentally polyglots, rather than language scientists, and students come out of the experience having realized that linguistics is a very different field (and hopefully a more compelling one) than they had assumed it to be. 2 Computational Linguistics at the LO Our goal, since starting the North American Computational Linguistics Olympiad (NACLO) in 2007 (Radev et al., 2008), has been to explore how this LO experience can be used to introduce students to computational linguistics. Topics in computational linguistics have been featured before in LOs, occasionally in the Moscow LO and with some regularity in the Bulgarian LO. Our deliberations began with some troubling statistics regarding enrollments in computer science programs (Zweben, 2013). Between 2003 and 2007 enrollments in computer science dropped dramatically. This was attributed in part to the dip in the IT sector, but it also stemmed in
- Vinodkumar Prabhakaran, Michael Bloodgood, Mona T. Diab, B. Dorr, Lori S. Levin, C. Piatko, Owen Rambow, Benjamin Van Durme. 2012. Statistical Modality Tagging from Rule-based Annotations and Crowdsourcing. Abstract: We explore training an automatic modality tagger. Modality is the attitude that a speaker might have toward an event or state. One of the main hurdles for training a linguistic tagger is gathering training data. This is particularly problematic for training a tagger for modality because modality triggers are sparse for the overwhelming majority of sentences. We investigate an approach to automatically training a modality tagger where we first gathered sentences based on a high-recall simple rule-based modality tagger and then provided these sentences to Mechanical Turk annotators for further annotation. We used the resulting set of training data to train a precise modality tagger using a multi-class SVM that delivers good performance.
- K. Baker, Michael Bloodgood, B. Dorr, Chris Callison-Burch, N. Filardo, C. Piatko, Lori S. Levin, Scott Miller. 2012. Modality and Negation in SIMT Use of Modality and Negation in Semantically-Informed Syntactic MT. Abstract: This article describes the resource- and system-building efforts of an 8-week Johns Hopkins University Human Language Technology Center of Excellence Summer Camp for Applied Language Exploration (SCALE-2009) on Semantically Informed Machine Translation (SIMT). We describe a new modality/negation (MN) annotation scheme, the creation of a (publicly available) MN lexicon, and two automated MN taggers that we built using the annotation scheme and lexicon. Our annotation scheme isolates three components of modality and negation: a trigger (a word that conveys modality or negation), a target (an action associated with modality or negation), and a holder (an experiencer of modality). We describe how our MN lexicon was semi-automatically produced and we demonstrate that a structure-based MN tagger results in precision around 86% (depending on genre) for tagging of a standard LDC data set.We apply our MN annotation scheme to statistical machine translation using a syntactic framework that supports the inclusion of semantic annotations. Syntactic tags enriched with semantic annotations are assigned to parse trees in the target-language training texts through a process of tree grafting. Although the focus of our work is modality and negation, the tree grafting procedure is general and supports other types of semantic information. We exploit this capability by including named entities, produced by a pre-existing tagger, in addition to the MN elements produced by the taggers described here. The resulting system significantly outperformed a linguistically naive baseline model (Hiero), and reached the highest scores yet reported on the NIST 2009 Urdu–English test set. This finding supports the hypothesis that both syntactic and semantic information can improve translation quality.
- Vinodkumar Prabhakaran, Michael Bloodgood, Mona T. Diab, B. Dorr, Lori S. Levin, C. Piatko, Owen Rambow, Benjamin Van Durme. 2012. from Rule-based Annotations and Crowdsourcing. Abstract: We explore training an automatic modality tagger. Modality is the attitude that a speaker might have toward an event or state. One of the main hurdles for training a linguistic tagger is gathering training data. This is particularly problematic for training a tagger for modality because modality triggers are sparse for the overwhelming majority of sentences. We investigate an approach to automatically training a modality tagger where we first gathered sentences based on a high-recall simple rule-based modality tagger and then provided these sentences to Mechanical Turk annotators for further annotation. We used the resulting set of training data to train a precise modality tagger using a multi-class SVM that delivers good performance.
- Lori S. Levin. 2011. Variety, Idiosyncracy, and Complexity in Language and Language Technologies. Abstract: This paper addresses three issues in language technologies. For each issue, the paper recommends an area of linguistics that is easily accessible to computer scientists and provides some examples that may be thought-provoking. The first issue is linguistic diversity, which is addressed by language typology. Typology provides an insightful view of the syntax and semantics of word order, as presented in Section 2.2. The second issue is the long tail of sparse phenomena. Section 3.3 uses Construction Grammar as a framework for addressing the details of definiteness and modality. Finally, Section 4 addresses how to make error analysis fun. It moves beyond monoclausal sentences and revives some rules from 1970s style transformational grammar as a fun way to analyze complex sentences.
- S. Hollenbeck, S. Hollenbeck, J. Toranto, Jason D. Toranto, Bruce J. Taylor, Bruce J. Taylor, Trung Ho, Trung Ho, M. Zenn, M. Zenn, D. Erdmann, D. Erdmann, Lori S. Levin, Lori S. Levin. 2011. Perineal and Lower Extremity Reconstruction. Abstract: Learning Objectives: After reading this article, the participant should be able to: 1. Perform a preoperative assessment of patients undergoing perineal and lower extremity reconstruction. 2. Describe the various tissue flaps used to perform these reconstructions and the advantages and disadvantages of each. 3. Provide appropriate postoperative care and interventions to maximize outcomes. Background: The lower extremity and perineum provide the foundation for upright posture and ambulation. These areas are made up of intricate contours with variable skin types and must withstand the functional demands of organ orifice support and weight-bearing forces. Successful reconstruction calls for careful preoperative planning and consideration of the site-specific demands. Methods: The authors reviewed literature regarding the most current treatment strategies for lower extremity and perineal reconstruction. Results: Perineal reconstruction is typically related to genitourinary or digestive tract abnormalities, mainly malignancies. Local and regional flaps are the mainstay of therapy, depending on their availability and the need for adjuvant therapy. Postoperatively, pressure reduction and closed-suction drainage are of major consideration. The lower extremities are prone to trauma, and these wounds often involve underlying and exposed bony abnormalities, and this must be considered in operative planning. Significant defects may be reconstructed with local or regional flaps and free-tissue transfer. The location of the wound and extent of surrounding tissue compromise are of major concern when determining flap coverage. Postoperatively, transition to ambulation and weight-bearing status is paramount. Conclusions: Reconstruction of the lower extremity and perineum requires recognition of the high functional demands of these areas. Local and regional flaps and free tissue transfer allow reconstruction of complex wounds in these areas. Selecting the correct flap and navigating the postoperative recovery to arrive at functional restoration remain a significant challenge.
- K. Baker, Michael Bloodgood, Chris Callison-Burch, B. Dorr, N. Filardo, Lori S. Levin, Scott Miller, C. Piatko. 2010. Semantically-Informed Syntactic Machine Translation: A Tree-Grafting Approach. Abstract: We describe a unified and coherent syntactic framework for supporting a semantically-informed syntactic approach to statistical machine translation. Semantically enriched syntactic tags assigned to the target-language training texts improved translation quality. The resulting system significantly outperformed a linguistically naive baseline model (Hiero), and reached the highest scores yet reported on the NIST 2009 Urdu-English translation task. This finding supports the hypothesis (posed by many researchers in the MT community, e.g., in DARPA GALE) that both syntactic and semantic information are critical for improving translation quality—and further demonstrates that large gains can be achieved for low-resource languages with different word order than English.
- B. Dorr, E. Hovy, Lori S. Levin. 2010. Natural Language Processing and Machine Translation Encyclopedia of Language and Linguistics , 2 nd ed . ( ELL 2 ) . Machine Translation : Interlingual Methods. Abstract: An interlingua is a notation for representing the content of a text that abstracts away from the characteristics of the language itself and focuses on the meaning (semantics) alone. Interlinguas are typically used as pivot representations in machine translation, allowing the contents of a source text to be generated in many different target languages. Due to the complexities involved, few interlinguas are more than demonstration prototypes, and only one has been used in a commercial MT system. In this article we define the components of an interlingua and the principal issues faced by designers and builders of interlinguas and interlingua MT systems, illustrating with examples from operational systems and research prototypes. We discuss current efforts to annotate texts with interlingua-based information.
- C. Messmer, R. Kellogg, Yixin Zhang, Andresa Baiak, Clinton Leiweke, J. Marcus, Lori S. Levin, M. Zenn, D. Erdmann. 2010. A technique to perfuse cadavers that extends the useful life of fresh tissues: The Duke experience. Abstract: The demand for laboratory‐based teaching and training is increasing worldwide as medical training and education confront the pressures of shorter training time and rising costs. This article presents a cost‐effective perfusion technique that extends the useful life of fresh tissue. Refrigerated cadavers are preserved in their natural state for up to 45 days with a daily working period of ten hours. Tissues maintain their color and natural consistency throughout this period. This new process for preservation of tissue opens the door to improved surgical training and to numerous research opportunities. Anat Sci Educ. © 2010 American Association of Anatomists.
- K. Baker, Michael Bloodgood, B. Dorr, N. Filardo, Lori S. Levin, C. Piatko. 2010. A Modality Lexicon and its use in Automatic Tagging. Abstract: This work is supported, in part, by the Johns Hopkins Human Language Technology Center of Excellence. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsor.
- Fei Xia, W. Lewis, Lori S. Levin. 2010. Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground. Abstract: Since early 1990s, with the advancement of machine learning methods and the availability of data resources such as treebanks and parallel corpora, data-driven approaches to NLP have made significant progress. The success of such data-driven approaches has cast doubt on the relevance of linguistics to NLP. Conversely, NLP techniques are rarely used to help linguistics studies. We believe that there is room to expand the involvement of linguistics in NLP, and likewise, NLP in linguistics, and that the cross-pollination of ideas between the disciplines can greatly benefit both fields. We are pleased to present the workshop on NLP and Linguistics: Finding the Common Ground in order to focus on some of the work that uses NLP and linguistics for mutual benefit, and discuss future plans for continuing collaborations. 
 
The workshop is intended to spur discussion on how NLP and linguistics can help each other, including new methods in incorporating linguistic knowledge into statistical systems to advance the state of the art of NLP, and the feasibility of using NLP techniques to acquire linguistic knowledge for a large number of languages and to assist linguistic studies. Fifteen papers were submitted and nine were accepted (one later withdrew), and the accepted papers are oriented around the following themes: 
 
• Research that shows awareness of a particular linguistic phenomenon and its effects on statistical systems: Caines and Buttery discuss the zero auxiliary construction (You talking to me?), awareness of which can improve performance of NLP on spoken English. Samaradzic and Merlo suggest that awareness of different types of light verb constructions could affect word alignment. Su, Huang, and Chen show that the linguistic notion of evidentiality can be used for automatic detection of trustworthiness. 
 
• New methods in incorporating linguistic knowledge into statistical systems to improve the start of the art: The papers by Caines and Buttery, Cook and Stevenson, Samaradzic and Merlo, and Su, Huang, and Chen all present a number of linguistic features that can be used for modeling or other corpus-based tasks. 
 
• Research that demonstrates the feasibility of creating NLP systems to automatically acquire linguistic knowledge for a large number of languages: Mayer, Rohrdantz, Plank, Bak, Butt, and Keim examine a phonotactic constraint in 3,200 languages. Poornima and Good propose the repurposing of traditional word lists from historical and comparative linguistics to NLP applications. 
 
• Research that demonstrates the benefits of using NLP techniques to help particular linguistic studies: This volume is rich with examples of corpus-based techniques shedding light on linguistic phenomena, including the ambiguity of German past participles (Zarries, Cahill, Kuhn, and Rohrer), zero auxiliary constructions (Caines and Buttery), light verbs (Samaradzic and Merlo), a paradoxical reading of "no X is too Y to Z" (Cook and Stevenson), the phonotactic constraint of Similar Place Avoidance (Mayer, Rohrdantz, Plank, Bak, Butt, and Keim), and evidentiality (Su, Huang, and Chen). 
 
• The relative strengths and weaknesses of corpus-based and rule-based resources: Plank and van Noord examine the domain portability of rule-based and corpus-trained parsers. Zarries, Cahill, Kunh, and Rohrer show that a corpus-based analysis can help reduce ambiguity of German past participles in a rule-based parser.
- G. Pauw, G. D. Schryver, Lori S. Levin. 2009. Proceedings of the First Workshop on Language Technologies for African Languages. Abstract: In multilingual situations, language technologies are crucial for providing access to information and opportunities for economic development. With somewhere between 1,000 and 2,000 different languages, Africa is a multilingual continent par excellence and presents acute challenges for those seeking to promote and use African languages in the areas of business development, education, research, and relief aid. 
 
In recent times a number of researchers and institutions, both from Africa and elsewhere, have come forward to share the common goal of developing capabilities in language technologies for the African languages. The goal of the workshop, then, is to provide a forum to meet and share the latest developments in this field. It also seeks to attract linguists who specialize in African languages and would like to leverage the tools and approaches of computational linguistics, as well as computational linguists who are interested in learning about the particular linguistic challenges posed by the African languages. 
 
The workshop consists of an invited talk on African language families and their structural properties by Prof. Sonja Bosch (UNISA, South Africa), followed by refereed research papers in computational linguistics. The call for papers specified that the focus would be on the less-commonly studied and lesser-resourced languages, such as those of sub-Saharan Africa. These could include languages from all four families: Niger-Congo, Nilo-Saharan, Khoisan and Afro-Asiatic, with the exception of Arabic (which is covered by the "Computational Approaches to Semitic Languages" workshop). Variants of European languages such as African French, African English or Afrikaans were also excluded from the call. The call was well answered, with 24 proposals being submitted. Following a rigorous review process, nine were withheld as full papers, and a further seven as poster presentations. These proceedings contain the double-blind, peer reviewed texts of the contributions that were withheld.
- Kathy A Baker, Steven Bethard, Michael Bloodgood, Ralf D. Brown, Chris Callison-Burch, Glen A. Coppersmith, B. Dorr, Wes Filardo, Kendall Giles, Anni Irvine, Mike Kayser, Lori S. Levin, Justin Martineau, J. Mayfield, Scott Miller, Aaron B. Phillips, A. Philpot, C. Piatko, Lane Schwartz, David M. Zajic. 2009. Semantically Informed Machine Translation ( SIMT ). Abstract: Acknowledgment: This work is supported, in part, by the Human Language Technology Center of Excellence. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsor.
- Mona T. Diab, Lori S. Levin, T. Mitamura, Owen Rambow, Vinodkumar Prabhakaran, Weiwei Guo. 2009. Committed Belief Annotation and Tagging. Abstract: We present a preliminary pilot study of belief annotation and automatic tagging. Our objective is to explore semantic meaning beyond surface propositions. We aim to model people's cognitive states, namely their beliefs as expressed through linguistic means. We model the strength of their beliefs and their (the human) degree of commitment to their utterance. We explore only the perspective of the author of a text. We classify predicates into one of three possibilities: committed belief, non committed belief, or not applicable. We proceed to manually annotate data to that end, then we build a supervised framework to test the feasibility of automatically predicting these belief states. Even though the data is relatively small, we show that automatic prediction of a belief class is a feasible task. Using syntactic features, we are able to obtain significant improvements over a simple baseline of 23% F-measure absolute points. The best performing automatic tagging condition is where we use POS tag, word type feature AlphaNumeric, and shallow syntactic chunk information CHUNK. Our best overall performance is 53.97% F-measure.
- Lori S. Levin. 2008. Chapter Five. Ephraim Discovers Philosophy (Gleanings Of Ephraim—1590). Abstract: In 1590, Ephraim published his second book, Gleanings of Ephraim, a collection of sermons for Jewish holidays and life-cycle events. The bulk of Gleanings of Ephraim is a collection of sermons, originally delivered in Yiddish, but rewritten into Hebrew for publication and edited to provide overall continuity. The lengthy Part II is devoted to holiday sermons mostly for Passover, Shavuot (Pentecost), and Sukkot (Tabernacles) in that order. Sermon 22 of Part II is one of his finest examples. It is characteristic of the Gleanings with respect to a casual reference Ephraim makes in this sermon to the 15th-century Spanish preacher Isaac Arama. Developing the ?second sight? to perceive the mysteries of the common mitzvot requires a kind of enlightenment, which is described figuratively by Jacob?s ladder. In the chapter Ephraim seeks to find a meaning in the configuration of the festival calendar as a whole.Keywords: Ephraim's philosophy; Gleanings of Ephraim (1590); holiday sermon; Isaac Arama; Jacob?s ladder; Jewish festival calendar; Shavuot; Sukkot
- Lori S. Levin. 2008. Appendix The. Polish Jewish Renaissance: A Source-Book. Abstract: This section contains an appendix of polish jewish renaissance- a source-book. The book Seeing with Both Eyes: Ephraim Luntshitz and the Polish-Jewish Renaissance advances the scholarly study of 16th-century Polish-Jewish culture, the Polish Jewish Renaissance, the philosophical interests of Ashkenazic Jewry, Jewish responses to Renaissance humanism and the Reformation, and the early-modern background for the 18th-century Jewish Enlightenment.Keywords: Ashkenazic Jewry; Ephraim Luntshitz; polish Jewish renaissance; reformation; renaissance humanism
- Dragomir R. Radev, Lori S. Levin, T. Payne. 2008. The North American Computational Linguistics Olympiad (NACLO). Abstract: NACLO (North American Computational Linguistics Olympiad) is an annual Olympiad-style contest for high school students, focusing on linguistics, computational linguistics, and language technologies.
- Lori S. Levin. 2008. Chapter Two. The First Wave (1550–1580): Isserles, Jaffe, And Horowitz. Abstract: The ?first wave? of 16th-century Polish-Jewish philosophical learning may also be called the ?Isserles school.? Between his installation as Rabbi of Cracow in 1549 and his death in 1572, Moses Isserles numbered among his students many future luminaries who would contribute to the spread of philosophical learning. Most notable among these were Mordecai Jaffe, Abraham Horowitz, David Gans, and Menahem David Ticktin. In the 1570s, it was the sexagenarian Eliezer Ashkenazi who gave the Polish-Jewish renaissance a second wind by involving Maharal and Ephraim Luntshitz in philosophical debates. The chronology of Moses Isserles?s life and that of the Maimonidean revival in central Europe are so intertwined and this chapter takes a close look at both. Here, both Lawrence Kaplan and Joseph Davis have asserted the continuity of 16th-century Polish-Jewish rationalism with the previous study of philosophy in Ashkenazic Jewry dating from the 14th-century school of R. Yom Tov Lipmann Muelhausen.Keywords: Abraham Horowitz; Eliezer Ashkenazi; Ephraim Luntshitz; Joseph Davis; Lawrence Kaplan; Maharal; Maimonidean; Mordecai Jaffe; Moses Isserles; Polish-Jewish renaissance
- Lori S. Levin. 2008. Index Of Subjects And Cited Authors. Abstract: This index section contains a list of terms and concepts that occur in the book Seeing with Both Eyes: Ephraim Luntshitz and the Polish-Jewish Renaissance. The book is an integrated study of the revival of philosophical studies in 16th-century central-European Jewry focusing on seven major thinkers and especially on the intellectual development of Ephraim Luntshitz (1550-1619). The section also presents an index of cited authors.Keywords: central-European Jewry; Ephraim Luntshitz; polish-Jewish renaissance
- Lori S. Levin. 2008. Chapter Four. The Debate Between Eliezer And Maharal. Abstract: Before examining the debate between Eliezer Ashkenazi and Maharal, this chapter reviews the status of philosophy among North European Jewry in the 1570s. Of the two scholars, it was Eliezer who had a much stronger background in philosophy. Though Maharal published his Prodigies of the Lord a year before Eliezer?s Deeds of the Lord, it is almost certain that Maharal wrote the Second Preface to the Prodigies in direct response to Eliezer?s manuscript work. The chief goal of Eliezer?s book is to understand the biblical story from the standpoint of a theological rationalist. Eliezer registers one major disagreement with Maimonides early on in his work, on the issue of the anthropocentric character of creation. Gersonides criticized Maimonides both on divine foreknowledge of man?s acts, and on man?s knowledge of God. The Eliezer-Maharal exchange introduced Ephraim Luntshitz to the world of controversy and helped him to come to his own position.Keywords: Biblical-rabbinic outlook; Deeds of the Lord; divine foreknowledge; Eliezer Ashkenazi; Ephraim Luntshitz; Gersonides; Maharal; Maimonidean philosophy; North European Jewry; Prodigies of the Lord
- Christian Monson, A. Lavie, J. Carbonell, Lori S. Levin. 2008. Evaluating an Agglutinative Segmentation Model for ParaMor. Abstract: This paper describes and evaluates a modification to the segmentation model used in the unsupervised morphology induction system, ParaMor. Our improved segmentation model permits multiple morpheme boundaries in a single word. To prepare ParaMor to effectively apply the new agglutinative segmentation model, two heuristics improve ParaMor's precision. These precision-enhancing heuristics are adaptations of those used in other unsupervised morphology induction systems, including work by Hafer and Weiss (1974) and Goldsmith (2006). By reformulating the segmentation model used in ParaMor, we significantly improve ParaMor's performance in all language tracks and in both the linguistic evaluation as well as in the task based information retrieval (IR) evaluation of the peer operated competition Morpho Challenge 2007. ParaMor's improved morpheme recall in the linguistic evaluations of German, Finnish, and Turkish is higher than that of any system which competed in the Challenge. In the three languages of the IR evaluation, our enhanced ParaMor significantly outperforms, at average precision over newswire queries, a morphologically naive baseline; scoring just behind the leading system from Morpho Challenge 2007 in English and ahead of the first place system in German.
- G. Frishkoff, Lori S. Levin, Philip I. Pavlik, K. Idemaru, N. D. Jong, cornelia. dejong. 2008. A Model-based Approach to Second-Language Learning of Grammatical Constructions. Abstract: The goal of this work is to examine how second-language learners acquire grammatical knowledge. To measure this knowledge, our research examines how native speakers of English choose between constructions that have similar meanings, but occur in different discourse contexts. An example is the dative alternation (give someone the book vs. give the book to someone). The distribution of these two constructions is explained by a four-factor model that describes the patterns or rules that underlie native-speaker usage. We hypothesized that training examples could be selected to instantiate these four factors in a way that would lead to improved learning of the dative alternation. In addition, we predicted that explicit instruction of the four grammar principles would further enhance learning. Two studies were conducted. Results showed rapid learning and good retention across a week-long delay. Examples that were labeled as “easy” or prototypical by the grammar model were learned faster than “hard” examples. In addition, explicit instruction gave an additional boost in performance. We conclude with a description of ongoing work in computational modeling and new studies that test transfer of learning based on the four-factor model. The long-term goal is to use this approach to design learning interventions that are cognitively and linguistically based and that lead to robust learning of grammar in a second language.
- Lori S. Levin. 2008. Chapter Seven. Return To Origins: The Outlook Of The Precious Ornament (Part 2). Abstract: This chapter shows that Ephraim, complemented his moderate rationalism by espousing doctrines and intellectual methods which are ?mystical but not kabbalistic?. In the introduction to the Precious Ornament, he sneaks in an allusion which sounds a note (familiar from Isserles and elsewhere) of complaint at the ignoramuses who parade their scant knowledge of kabbalah with much fanfare. Ephraim?s Omphalos-myth shows a way in which the Jewish path is not merely equal to others. Some of Arieti?s concepts apply quite aptly to the thought-world of the Middle Ages and the Renaissance. The mix of primary and secondary process in Biblical thought is heavily weighted to the primary-process. This is seen especially in the magnificent poetry of the Biblical literature, which Maimonides referred to as the ?imaginative? faculty of the prophet. Ephraim seems at his most joyful when describing the divine-human relationship as a reciprocal one.Keywords: Biblical literature; divine-human relationship; Ephraim Luntshitz; Isserles; Jewish mysticism; kabbalah; Maimonides; Omphalos-myth; Precious Ornament; Silvano Arieti
- Christian Monson, A. F. Llitjós, Vamshi Ambati, Lori S. Levin, A. Lavie, A. Alvarez, Roberto Aranovich, J. Carbonell, R. Frederking, Erik Peterson, Katharina Probst. 2008. Linguistic Structure and Bilingual Informants Help Induce Machine Translation of Lesser-Resourced Languages. Abstract: Producing machine translation (MT) for the many minority languages in the world is a serious challenge. Minority languages typically have few resources for building MT systems. For many minor languages there is little machine readable text, few knowledgeable linguists, and little money available for MT development. For these reasons, our research programs on minority language MT have focused on leveraging to the maximum extent two resources that are available for minority languages: linguistic structure and bilingual informants. All natural languages contain linguistic structure. And although the details of that linguistic structure vary from language to language, language universals such as context-free syntactic structure and the paradigmatic structure of inflectional morphology, allow us to learn the specific details of a minority language. Similarly, most minority languages possess speakers who are bilingual with the major language of the area. This paper discusses our efforts to utilize linguistic structure and the translation information that bilingual informants can provide in three sub-areas of our rapid development MT program: morphology induction, syntactic transfer rule learning, and refinement of imperfect learned rules.
- Jonathan Clark, R. Frederking, Lori S. Levin. 2008. Inductive Detection of Language Features via Clustering Minimal Pairs: Toward Feature-Rich Grammars in Machine Translation. Abstract: Syntax-based Machine Translation systems have recently become a focus of research with much hope that they will outperform traditional Phrase-Based Statistical Machine Translation (PBSMT). Toward this goal, we present a method for analyzing the morphosyntactic content of language from an Elicitation Corpus such as the one included in the LDC's upcoming LCTL language packs. The presented method discovers a mapping between morphemes and linguistically relevant features. By providing this tool that can augment structure-based MT models with these rich features, we believe the discriminative power of current models can be improved. We conclude by outlining how the resulting output can then be used in inducing a morphosyntactically feature-rich grammar for AVENUE, a modern syntax-based MT system.
- Jonathan Clark, R. Frederking, Lori S. Levin. 2008. Toward Active Learning in Data Selection: Automatic Discovery of Language Features During Elicitation. Abstract: Data Selection has emerged as a common issue in language technologies. We define Data Selection as the choosing of a subset of training data that is most effective for a given task. This paper describes deductive feature detection, one component of a data selection system for machine translation. Feature detection determines whether features such as tense, number, and person are expressed in a language. The database of the The World Atlas of Language Structures provides a gold standard against which to evaluate feature detection. The discovered features can be used as input to a Navigator, which uses active learning to determine which piece of language data is the most important to acquire next.
- Christian Monson, J. Carbonell, A. Lavie, Lori S. Levin. 2007. ParaMor: Minimally Supervised Induction of Paradigm Structure and Morphological Analysis. Abstract: Paradigms provide an inherent organizational structure to natural language morphology. ParaMor, our minimally supervised morphology induction algorithm, retrusses the word forms of raw text corpora back onto their paradigmatic skeletons; performing on par with state-of-the-art minimally supervised morphology induction algorithms at morphological analysis of English and German. ParaMor consists of two phases. Our algorithm first constructs sets of affixes closely mimicking the paradigms of a language. And with these structures in hand, ParaMor then annotates word forms with morpheme boundaries. To set ParaMor's few free parameters we analyze a training corpus of Spanish. Without adjusting parameters, we induce the morphological structure of English and German. Adopting the evaluation methodology of Morpho Challenge 2007 (Kurimo et al., 2007), we compare ParaMor's morphological analyses with Morfessor (Creutz, 2006), a modern minimally supervised morphology induction system. ParaMor consistently achieves competitive F1 measures.
- A. Alvarez, Lori S. Levin, R. Frederking. 2007. An assessment of language elicitation without the supervision of a linguist. Abstract: The AVENUE machine translation system is designed for resource poor scenarios in which parallel corpora are not available. In this situation, parallel corpora are created by bilingual consultants who translate an elicitation corpus into their languages. We have described the elicitation corpus in other publications. This paper is concerned with evaluation of the elicitation corpus: is it suitably designed so that a bilingual consultant can produce reliable data without the supervision of a linguist? We evaluated two translations of the English elicitation corpus, one into Thai and one into Bengali. Two types of evaluation were conducted: an error analysis of the translations produced by the Thai and Bengali consultants, and a comparison of Example Based MT trained on the original translations and on corrected translations.
- DomainAlon Lavie, Lori S. Levin, A. Waibel, D. Gates, Marsal Gavaldà. 2007. JANUS: a Multi-lingual Speech-to-speech Translation System for Spontaneously Spoken Language in a Limited Domain. Abstract: .Ta.mu; is a. rnulLi-lingual r,;peech tra.nr,;la.tion :;yr,;tem currently opera.ting in the domain of meeting r,;cheduling. Tra.nslating spontaneom; speech require:, a high degree of rolmstness to overcome the disfluenries of spoken l;wguage as well as errors in speerh rerognition. In t his system desuiption , we focus on the robust speech translation cornµonents in Janus-the skiµping GLR* par:;er, the segmentation of full utterances into semantic dialogue units (SDU s), and the late-stage disambigua tion of utterances. \Ve will also describe how the end-to-end translation performance of the system i:; evaluated and pre:,cnL our la.test Spanish-Lo-English cvaluaLion rc:,ulLs.
- Howard T. Wang, D. Erdmann, K. Olbrich, Allan H. Friedman, Lori S. Levin, M. Zenn. 2007. Free Flap Reconstruction of the Scalp and Calvaria of Major Neurosurgical Resections in Cancer Patients: Lessons Learned Closing Large, Difficult Wounds of the Dura and Skull. Abstract: Background: Reconstruction of major neurosurgical resections can present a significant challenge because of the morbidity of radiation therapy, cerebrospinal fluid leaks, bacterial contamination from sinus exposure, and functional and cosmetic deformity from the size and location of the defect. The authors present their experience with free tissue reconstruction of scalp and calvarial defects. In particular, the authors examine their results in relation to major comorbidities, such as preoperative cerebrospinal fluid leak, history of smoking, and perioperative radiation therapy. Methods: From 1997 to 2004, 22 patients requiring neurosurgical or head and neck resection for cancer from a single institution who underwent reconstruction with 24 flaps were examined retrospectively. Factors examined included patient demographics, indication for surgery, type of flap used, exposed critical structures, comorbidity, complications, and outcomes. Results: Of the 22 patients, seven had a cerebrospinal fluid leak present at the time of their reconstructive surgery. Of the seven, one patient died as a result of a stroke postoperatively. Of the remaining six patients, two had partial flap necrosis (33 percent). However, all six flaps survived, with resolution of cerebrospinal fluid leak. In comparison, of the 15 patients (17 flaps) without a cerebrospinal fluid leak, three had partial flap necrosis (18 percent; not significant). With regard to smoking status, the partial flap necrosis rate was 30 percent in smokers versus a rate of 14 percent in nonsmokers, although this was not statistically significant. Only one patient who received perioperative radiation (11 of 22 patients) developed partial flap necrosis. Conclusions: The authors' data support the concept that free tissue transfer is a viable option in reconstruction of cranial defects. Although complications can occur in this high-risk population, successful reconstruction with free flaps was possible. Difficult problems, such as recurrent cerebrospinal fluid leaks and large irradiated wounds, can be managed and resolved successfully using this technique.
- M. Ganapathiraju, Lori S. Levin. 2006. TelMore: Morphological Generator for Telugu Nouns and Verbs. Abstract: — Telugu is an Indian language spoken by over 50 million people in the country. The language is rich in literature and has been studied by native and foreign linguists significantly, yet it has not benefited significantly from the recent advances in computational approaches for linguistic or statistical processing of natural language texts. However with the recent progress in standardization of machine representation of text, applications like machine translation and information retrieval are beginning to surface, for example with the collaborative efforts under the umbrella of Digital Library of India (DLI). There is a need for a morphological generator for Telugu that forms an integral part of applications like machine translation and universal dictionary. Here we present the development of a tool, called TelMore, that can generate morphological forms of nouns and verbs of Telugu. It has been developed based on the previously established linguistic analyses of Telugu by C.P. Brown and H. Krishnamurthy. The tool is developed in Perl® and is made available with a web interface and in source code for use and further development at http://www.cs.cmu.edu/~madhavi/TelMore/.
- J. Carbonell, A. Lavie, Lori S. Levin, A. Black. 2006. Language Technologies for Humanitarian Aid. Abstract: Humanitarian aid missions, whether emergency famine relief, establishment of medical clinics, or missions in conjunction with peace-keeping operations, require on-demand communication with the indigenous population. If such operations take place in countries with a commonly-spoken major language, such as English or Spanish, it proves relatively easy to find participating personnel with the appropriate linguistic fluency. However, such is not the case when the operations take place in regions where less common languages are spoken, such as Bosnia (language: Serbo-Croatian), Haiti (language: Haitian Creole), Somalia (language: Somali, a.k.a. “Soomaaliga”), or Afghanistan (language: Pashto, with subpopulations of Urdu and Tadjik speakers). Even in Latin America, where Spanish and Portuguese dominate, there are over 100 indigenous languages, including Quechua in Peru, Aymara in Bolivia, Mapudungun in Southern Chile, and the Tucan languages in the Southern Colombian Putumayo region. Many native speakers of these languages are not versant in either Spanish or Portuguese, especially those in remote mountainous or jungle regions, where the need for medical or educational aid, or protection from organized drug gangs, may be paramount.
- Benjamin Han, D. Gates, Lori S. Levin. 2006. From Language to Time: A Temporal Expression Anchorer. Abstract: Understanding temporal expressions in natural language is a key step towards incorporating temporal information in many applications. In this paper we describe a system capable of anchoring such expressions in English: system TEA features a constraint-based calendar model and a compact representational language to capture the intensional meaning of temporal expressions. We also report favorable results from experiments conducted on several email datasets
- Owen Rambow, B. Dorr, D. Farwell, R. Green, Nizar Habash, Stephen Helmreich, E. Hovy, Lori S. Levin, Keith J. Miller, T. Mitamura, F. Reeder, Advaith Siddharthan. 2006. Parallel Syntactic Annotation of Multiple Languages. Abstract: This paper describes an effort to investigate the incrementally deepening development of an interlingua notation, validated by human annotation of texts in English plus six languages. We begin with deep syntactic annotation, and in this paper present a series of annotation manuals for six different languages at the deep-syntactic level of representation. Many syntactic differences between languages are removed in the proposed syntactic annotation, making them useful resources for multilingual NLP projects with semantic components.
- Jeff Good, A. Alvarez, Lori S. Levin, R. Frederking. 2006. Parallel Reverse Treebanks for the Discovery of Morpho-Syntactic Markings. Abstract: This paper describes a corpus of syntactic structures and associated sentences. However, it is not a traditional treebank. The syntactic structures are created first and are then associated with sentences in a human language. We therefore call it a reverse treebank (RTB).1 The RTB has been created for elicitation of sentences in low resource languages. First, a corpus of feature structures is created using a tool suite built by the authors. The second step is to add sentences in a widely spoken language like English or Spanish that express the meanings of each feature structure. We will call this language the Elicitation Language. The third step is to have a bilingual informant translate the sentences into a low resource language. Using an elicitation tool, the informant can also graphically align the words of the Elicitation Language to the words of the low resource language. The result is a high quality parallel, word aligned corpus annotated with feature structures, which we will call a parallel RTB. RTB sentences may have multiple clauses, but they are generally short in comparison to naturally occurring sentences in treebanks. The reason is that parallel RTBs provide small, but highly structured corpora for machine learning with small amounts of resources. Corpora such as these have been used for automatic learning of transfer rules for machine translation [8].
- A. Lavie, F. Pianesi, Lori S. Levin. 2006. The NESPOLE! System for multilingual speech communication over the Internet. Abstract: The NESPOLE! System is a speech communication system designed to support multilingual interaction between common users and providers of e-commerce services over the Internet. The core of the system is a distributed interlingua-based speech-to-speech translation system, which is supported by multimodal capabilities that allow the two parties participating in the communication to share Web pages and graphical content which can be annotated using gestures. We describe the unique features and considerations behind the design and implementation of this system, and evaluate these within the context of a constructed full prototype of the system that was developed for the domain of travel planning
- Christian Monson, A. F. Llitjós, Roberto Aranovich, Lori S. Levin, Ralf D. Brown, Eric Peterson, J. Carbonell, A. Lavie. 2006. Building NLP Systems for Two Resource-Scarce Indigenous Languages : Mapudungun and Quechua. Abstract: By adopting a “first-things-first” approach we overcome a number of challenges inherent in developing NLP Systems for resourcescarce languages. By first gathering the necessary corpora and lexicons we are then enabled to build, for Mapudungun, a spellingcorrector, morphological analyzer, and two Mapudungun-Spanish machine translation systems; and for Quechua, a morphological analyzer as well as a rule-based Quechua-Spanish machine translation system. We have also worked on languages (Hebrew, Hindi, Dutch, and Chinese) for which resources such as lexicons and morphological analyzers were available. The flexibility of the AVENUE project architecture allows us to take a different approach as needed in each case. This paper describes the Mapudungun and Quechua systems. 1. The AVENUE Project The long-term goal of the AVENUE project at CMU is to facilitate machine translation for a larger percentage of the world’s languages by reducing the cost and time of producing MT systems. There are a number of radically different ways to approach MT. Each of these methods of accomplishing machine translation has a different set of strengths and weaknesses and each requires different resources to build. The AVENUE approach combines these different types of MT in one “omnivorous” system that will “eat” whatever resources are available to produce the highest quality MT possible given the resources. If a parallel corpus is available in electronic form, we can use example-based machine translation (EBMT) (Brown et al., 2003; Brown, 2000), or Statistical machine translation (SMT). If native speakers are available with training in computational linguistics, a human-engineered set of rules can be developed. Finally, if neither a corpus nor a human computational linguist is available, AVENUE uses a newly developed machine learning technique (Probst, 2005) to learn translation rules from data that is elicited from native speakers. As detailed in the remainder of this paper, the particular resources that the AVENUE project produced facilitated developing an EBMT and a humancoded rule-based MT system for Mapudungun, and a hand-built rule-based MT system for Quechua. Automatic rule learning has been applied experimentally for several other language pairs: Hindi-to-English (Lavie et al. 2003) and Hebrew-to-English (Lavie et al. 2004). The AVENUE project as a whole consists of six main modules (Figure 1), which are used in different combinations for different languages: 1) elicitation of a word aligned parallel corpus (Levin et al. in press); 2) automatic learning of translation rules (Probst, 2005) and morphological rules (Monson et al. 2004); 3) the run time MT system for performing source to target language translation based on transfer rules; 4) the EBMT system (Brown, 1997); 5) a statistical “decoder” for selecting the most likely translation from the available alternatives; and 6) a module that allows a user to interactively correct translations and automatically refines the translation rules (Font Llitjós et al. 2005a). 2. AVENUE and Indigenous Languages of the Western Hemisphere Over the past six years the AVENUE project at the Language Technologies Institute at Carnegie Mellon University has worked with native informants and the government of Chile to produce a variety of natural language processing (NLP) tools for Mapudungun, an indigenous South American language spoken by less than 1 million people in Chile and Argentina. During the final year and a half of this time, the AVENUE team has also been developing tools for Quechua, spoken by approximately 10 million people in Peru, Bolivia, Ecuador, South of Colombia, and northern Argentina. Electronic resources for both Quechua and Mapudungun are scarce. At the time the AVENUE team started working on Mapudungun, even simple natural language tools such as morphological analyzers or spelling correctors did not exist. In fact, there were few electronic resources from which such natural language tools might be built. There were no standard Mapudungun text or speech corpora, or lexicons, and no parsed treebanks. The text that does exist is in a variety of competing orthographic formats. More resources exist for Quechua but they are still far from what is needed to build a complete MT system. In addition to these practical challenges facing construction of natural language systems for Mapudungun and Quechua, there are also theoretical and human factor challenges. Both Mapudungun and Quechua pose unique challenges from a linguistic theory perspective, since they have complex agglutinative morphological structures. In addition Mapudungun is polysynthetic, incorporating objects into the verb of a sentence. Agglutination and polysynthesis are both properties that the majority languages, for which most natural language resources have been built, do not possess. Human factors also pose a particular challenge for these two languages. Namely, there is a scarcity of people trained in computational linguistics who
- Benjamin Han, D. Gates, Lori S. Levin. 2006. Understanding Temporal Expressions in Emails. Abstract: Recent years have seen increasing research on extracting and using temporal information in natural language applications. However most of the works found in the literature have focused on identifying and understanding temporal expressions in newswire texts. In this paper we report our work on anchoring temporal expressions in a novel genre, emails. The highly under-specified nature of these expressions fits well with our constraint-based representation of time, Time Calculus for Natural Language (TCNL). We have developed and evaluated a Temporal Expression Anchoror (TEA), and the result shows that it performs significantly better than the baseline, and compares favorably with some of the closely related work.
- A. Alvarez, Lori S. Levin, R. Frederking, Simon Fung, D. Gates, Jeff Good. 2006. The MILE Corpus for Less Commonly Taught Languages. Abstract: This paper describes a small, structured English corpus that is designed for translation into Less Commonly Taught Languages (LCTLs), and a set of re-usable tools for creation of similar corpora. The corpus systematically explores meanings that are known to affect morphology or syntax in the world's languages. Each sentence is associated with a feature structure showing the elements of meaning that are represented in the sentence. The corpus is highly structured so that it can support machine learning with only a small amount of data. As part of the REFLEX program, the corpus will be translated into multiple LCTLs, resulting in parallel corpora can be used for training of MT and other language technologies. Only the untranslated English corpus is described in this paper.
- A. Alvarez, Lori S. Levin, R. Frederking, Erik Peterson, Jeff Good. 2005. Semi-Automated Elicitation Corpus Generation. Abstract: In this document we will describe a semi-automated process for creating elicitation corpora. An elicitation corpus is translated by a bilingual consultant in order to produce high quality word aligned sentence pairs. The corpus sentences are automatically generated from detailed feature structures using the GenKit generation program. Feature structures themselves are automatically generated from information that is provided by a linguist using our corpus specification software. This helps us to build small, flexible corpora for testing and development of machine translation systems.
- Lori S. Levin. 2005. Syntactic Theory and Grammar Design for Machine Translation. Abstract: Recently, the field of machine translation has increasingly reflected the influence of linguistic theory. Some systems have been designed around principles or structures of specific theories (Dorr, 1989; Kaplan, Netter, Wedekind, & Zaenen, 1989; Sharp, 1986), whereas others, adhering less strongly to particular theories, nevertheless reflect great care in considering and adapting the work of linguists. Most notable in this respect is the EUROTRA project as described, for example, in Arnold & des Tombe (1987) and Durand et al. (to appear). There seems to be general agreement that linguistic theory can contribute to machine translation (Raskin, 1987a, 1987b; Wehrli, 1987), but at the same time there is skepticism about its potential to break the barriers to robust, high quality translation (Nagao et al., 1988). As a result, many questions remain about the place of linguistic theory in machine translation.
- Benjamin Han, D. Gates, Lori S. Levin. 2005. Anchoring Temporal Expressions in Scheduling-related Emails. Abstract: In this paper we adopt a constraint-based representation of time, Time Calculus (TC), for anchoring temporal expressions in a novel genre, emails. Email is sufficiently different from the most studied genre - newswire texts, and its highly under-specified nature fits well with our representation. The evaluation of our anchoring system shows that it performs significantly better than the baseline, and the result compares favorably with some of the closest related work.
- B. Dorr, D. Farwell, R. Green, Nizar Habash, Stephen Helmreich, E. Hovy, Lori S. Levin, Keith J. Miller, T. Mitamura, Owen Rambow, F. Reeder, Advaith Siddharthan. 2004. Interlingua Development and Testing through Semantic Annotation of Multilingual Text Corpora. Abstract: This paper describes a multi-site project to annotate the interlingual content of six sizable bilingual parallel corpora. The project addresses several principal problems in parallel: specification of interlingua content and notation, development of reliable annotation methods, and evaluation of annotated corpora. As a by-product, a growing corpus of annotated texts is being produced, which may eventually be useful for machine learning of semantics-based processing.
- A. Lavie, Katharina Probst, Erik Peterson, S. Vogel, Lori S. Levin, Ariadna Font-Llitjos, J. Carbonell. 2004. A trainable transfer-based MT approach for languages with limited resources. Abstract: We describe a Machine Translation (MT) approach that is specifically designed to enable rapid development of MT for languages with limited amounts of online resources. Our approach assumes the availability of a small number of bi-lingual speakers of the two languages, but these need not be linguistic experts. The bi-lingual speakers create a comparatively small corpus of word aligned phrases and sentences (on the order of magnitude of a few thousand sentence pairs) using a specially designed elicitation tool. From this data, the learning module of our system automatically infers hierarchical syntactic transfer rules, which encode how syntactic constituent structures in the source language transfer to the target language. The collection of transfer rules is then used in our run-time system to translate previously unseen source language text into the target language. We describe the general principles underlying our approach, and present results from an experiment, where we developed a basic Hindi-to-English MT system over the course of two months, using extremely limited resources.
- Stephen Helmreich, D. Farwell, B. Dorr, Nizar Habash, Lori S. Levin, T. Mitamura, F. Reeder, Keith J. Miller, E. Hovy, Owen Rambow, Advaith Siddharthan. 2004. Interlingual Annotation of Multilingual Text Corpora. Abstract: This paper describes a multi-site project to annotate six sizable bilingual parallel corpora for interlingual content. After presenting the background and objectives of the effort, we will go on to describe the data set that is being annotated, the interlingua representation language used, an interface environment that supports the annotation task and the annotation process itself. We will then present a preliminary version of our evaluation methodology and conclude with a summary of the current status of the project along with a number of issues which have arisen.
- A. Lavie, Katharina Probst, Erik Peterson, S. Vogel, Lori S. Levin, Ariadna Font-Llitjos, J. Carbonell. 2004. A Trainable Transfer-based Machine Translation Approach for Languages with Limited Resources. Abstract: We describe a Machine Translation (MT) approach that is specifically designed to enable rapid development of MT for languages with limited amounts of online resources. Our approach assumes the availability of a small number of bi-lingual speakers of the two languages, but these need not be linguistic experts. The bi-lingual speakers create a comparatively small corpus of word aligned phrases and sentences (on the order of magnitude of a few thousand sentence pairs) using a specially designed elicitation tool. From this data, the learning module of our system automatically infers hierarchical syntactic transfer rules, which encode how syntactic constituent structures in the source language transfer to the target language. The collection of transfer rules is then used in our run-time system to translate previously unseen source language text into the target language. We describe the general principles underlying our approach, and present results from an experiment, where we developed a basic Hindi-to-English MT system over the course of two months, using extremely limited resources.
- Christian Monson, A. Lavie, J. Carbonell, Lori S. Levin. 2004. Unsupervised Induction of Natural Language Morphology Inflection Classes. Abstract: We propose a novel language-independent framework for inducing a collection of morphological inflection classes from a monolingual corpus of full form words. Our approach involves two main stages. In the first stage, we generate a large data structure of candidate inflection classes and their interrelationships. In the second stage, search and filtering techniques are applied to this data structure, to identify a select collection of "true" inflection classes of the language. We describe the basic methodology involved in both stages of our approach and present an evaluation of our baseline techniques applied to induction of major inflection classes of Spanish. The preliminary results on an initial training corpus already surpass an F1 of 0.5 against ideal Spanish inflectional morphology classes.
- Christian Monson, Lori S. Levin, R. Vega, Ralf D. Brown, A. F. Llitjós, A. Lavie, J. Carbonell, Eliseo Cañulef, Rosendo Huisca. 2004. Data Collection and Analysis of Mapudungun Morphology for Spelling Correction. Abstract: This paper describes part of a three year collaboration between Carnegie Mellon University's Language Technologies Institute, the Programa de Educacion Intercultural Bilingue of the Chilean Ministry of Education, and Universidad de La Frontera (Temuco, Chile). We are currently constructing a spelling checker for Mapudungun, a polysynthetic language spoken by the Mapuche people in Chile and Argentina. The spelling checker will be built in MySpell, the spell checking system used by the open source office suite OpenOffice. This paper also describes the spoken language corpus that is used as a source of data for developing the spelling checker.
- Lori S. Levin, C. Langley, A. Lavie, D. Gates, D. Wallace, Kay Peterson. 2003. Domain Specific Speech Acts for Spoken Language Translation. Abstract: We describe a coding scheme for machine translation of spoken taskoriented dialogue. The coding scheme covers two levels of speaker intention − domain independent speech acts and domain dependent domain actions. Our database contains over 14,000 tagged sentences in English, Italian, and German. We argue that domain actions, and not speech acts, are the relevant discourse unit for improving translation quality. We also show that, although domain actions are domain specific, the approach scales up to large domains without an explosion of domain actions and can be coded with high inter-coder reliability across research sites. Furthermore, although the number of domain actions is on the order of ten times the number of speech acts, sparseness is not a problem for the training of classifiers for identifying the domain action. We describe our work on developing high accuracy speech act and domain action classifiers, which is the core of the source language analysis module of our NESPOLE machine translation system.
- A. Waibel, A. Badran, A. Black, R. Frederking, D. Gates, A. Lavie, Lori S. Levin, K. Lenzo, L. Tomokiyo, Jürgen Reichert, Tanja Schultz, D. Wallace, M. Woszczyna, Jing Zhang. 2003. Speechalator: two-way speech-to-speech translation on a consumer PDA. Abstract: This paper describes a working two-way speech-to-speech translation system that runs in near real-time on a consumer handheld computer. It can translate from English to Arabic and Arabic to English in the domain of medical interviews. We describe the general architecture and frameworks within which we developed each of the components: HMM-based recognition, interlingua translation (both rule and statistically based), and unit selection synthesis.
- Lori S. Levin, T. Tokunaga, Alessandro Lenci. 2003. Proceedings of the ACL 2003 workshop on Multiword expressions: analysis, acquisition and treatment - Volume 18. Abstract: There have been a number of workshops in recent years on collocations, terminology and named entity recognition. However, multiword expressions (MWEs) that encompass all of these subtypes remain a real challenge for natural language processing (NLP) despite several decades of research effort. The aim of this SIGLEX workshop is to bring together NLP researchers working on all areas of MWEs. The objectives are to summarise what has been achieved in the area, to establish common themes between different approaches and to discuss future trends, with particular emphasis on addressing the problems that MWEs pose for real-world NLP applications. We welcomed submissions on all aspects of analysis, acquisition and treatment of these 'words with spaces' which often require special semantic interpretation and may have peculiar syntactic behaviour.
- A. Waibel, A. Badran, A. Black, R. Frederking, D. Gates, A. Lavie, Lori S. Levin, K. Lenzo, L. Tomokiyo, Jürgen Reichert, Tanja Schultz, D. Wallace, M. Woszczyna, Jing Zhang. 2003. Speechalator: Two-Way Speech-to-Speech Translation in Your Hand. Abstract: This demonstration involves two-way automatic speech-to-speech translation on a consumer off-the-shelf PDA. This work was done as part of the DARPA-funded Babylon project, investigating better speech-to-speech translation systems for communication in the field. The development of the Speechalator software-based translation system required addressing a number of hard issues, including a new language for the team (Egyptian Arabic), close integration on a small device, computational efficiency on a limited platform, and scalable coverage for the domain.
- A. Lavie, S. Vogel, Lori S. Levin, Erik Peterson, Katharina Probst, A. F. Llitjós, Rachel Reynolds, J. Carbonell, Richard Cohen. 2003. Experiments with a Hindi-to-English transfer-based MT system under a miserly data scenario. Abstract: We describe an experiment designed to evaluate the capabilities of our trainable transfer-based (Xfer) machine translation approach, as applied to the task of Hindi-to-English translation, and trained under an extremely limited data scenario. We compare the performance of the Xfer approach with two corpus-based approaches---Statistical MT (SMT) and Example-based MT (EBMT)---under the limited data scenario. The results indicate that the Xfer system significantly outperforms both EBMT and SMT in this scenario. Results also indicate that automatically learned transfer rules are effective in improving translation performance, compared with a baseline word-to-word translation version of the system. Xfer system performance with a limited number of manually written transfer rules is, however, still better than the current automatically inferred rules. Furthermore, a "multiengine" version of our system that combined the output of the Xfer and SMT systems and optimizes translation selection outperformed both individual systems.
- J. Kim, L. Labree, Lori S. Levin, S. Feldon. 2003. The relation of Graves’ ophthalmopathy to circulating thyroid hormone status. Abstract: Aim: The risk factors and epidemiological data for Graves’ ophthalmopathy with and without abnormal circulating thyroid levels were examined to determine the relation of thyroid dysfunction to ophthalmopathy. Methods: The authors retrospectively evaluated 482 patients seen with Graves’ ophthalmopathy. Of these, 413 were classified as having abnormal levels of circulating thyroid hormone (ALTH) and 69 as having normal levels of circulating thyroid hormone (NLTH). Results: Patients in the NLTH group, compared to the ALTH group, were older on average (56 (SD 13.5) v 52 (15.4)) and had a higher age adjusted body mass index (26.1 (0.8) v 23.4 (0.3)). In addition, a higher percentage of NLTH patients had hypercholesterolaemia. Those in the ALTH group were more likely to be female (76% v 51%), to have a family history of thyroid problems, and to have had eye surgery. Conclusion: NLTH and ALTH appear to differ from each other in terms of risk factors and epidemiological characteristics. Additionally, thyroid dysfunction seems to be associated with a more severe ophthalmopathy compared to the euthyroid state.
- M. Finke, Maria Lapata, A. Lavie, Lori S. Levin, L. Tomokiyo, T. Polzin, K. Ries, A. Waibel, K. Zechner, finkem. 2002. CLARITY: INFERRING DISCOURSE STRUCTURE FROM SPEECH. Abstract: The goal of the CLARITY project is to explore the use of discourse structure in the understanding of conversational speech. Within project CLARITY we aim to develop automatic classifiers for three levels of discourse structure in Spanish telephone conversations: speech acts, dialogue games, and discourse segments. This paper presents our first results and research plans in three areas: definition of discourse structure units and manual annotation of CALLHOME SPANISH, speech recognition, and automated segmentation and labeling of speech acts.
- Lori S. Levin, R. Vega, J. Carbonell, Ralf D. Brown, A. Lavie, Eliseo Cañulef, C. Huenchullan. 2002. Data Collection and Language Technologies for Mapudungun. Abstract: Mapudungun is spoken by over 900,000 people (Mapuche) in Chile and Argentina. Thanks to an active bilingual and multicultural education program, Mapuche children are now being taught to be literate in both Mapudungun and Spanish. The Chilean Ministry of Education has teamed up with the Language Technologies Institute’s AVENUE project to collect data and produce language technologies that support bilingual education. The main resource that has come out of the Mineduc-LTI partnership is Mapudungun-Spanish parallel corpus consisting of approximately 200,000 words of text and 120 hours of transcribed speech. Plans are being made for machine translation and computer-assisted instruction.
- Katharina Probst, Lori S. Levin. 2002. Challenges in automated elicitation of a controlled bilingual corpus.. Abstract: In this paper we will address an uncommon but important approach to automated learning for MT, namely learning of translation rules from carefully elicited sentences. The approach is uncommon for good reason — anyone who has tried linguistic field work knows that elicitation will go awry if not carefully monitored by a human. We will address eight challenges of automated elicitation and discuss their solution in the AVENUE machine translation project. The elicited sentences in AVENUE are used to semi-automatically infer transfer rules for the desired language pair.
- Lori S. Levin, D. Gates, Dorcas Pianta, R. Cattoni, N. Mana, Kay Peterson, A. Lavie, F. Pianesi. 2002. Balancing Expressiveness and Simplicity in an Interlingua for Task Based Dialogue. Abstract: In this paper we compare two interlingua representations for speech translation. The basis of this paper is a distributional analysis of the C-STAR II and NESPOLE databases tagged with interlingua representations. The C-STAR II database has been partially re-tagged with the NESPOLE interlingua, which enables us to make comparisons on the same data with two types of interlinguas and on two types of data (C-STAR II and NESPOLE) with the same interlingua. The distributional information presented in this paper show that the NESPOLE interlingua maintains the language-independence and simplicity of the C-STAR II speech-act-based approach, while increasing semantic expressiveness and scalability.
- A. Tribble, A. Lavie, Lori S. Levin. 2002. Rapid adaptive development of semantic analysis grammars.. Abstract: In this paper we describe a process for rapid development of semantic analysis grammars for Interlingual Machine Translation. The technique applies to existing systems and can be used to extend coverage into new languages quickly by separating the informant tasks performed by native speakers from the grammar writing tasks performed by engineers familiar with the system. A tool for automatic manipulation of parse trees uses information provided by both informant and engineer to create an example base of parse trees in the new language from which a grammar for that language can be read. Experimental results from a small-scale application of these tools are given to assess feasibility of the technique.
- A. Waibel, Lori S. Levin. 2001. Published in "Proceedings of ICSLP-96" Translation of Conversational Speech with JANUS-II. Abstract: In this paper we investigate the possibility of translating continuous spoken conversations in a cross-talk environment. This is a task known to be difficult for human translators due to several factors. It is characterized by rapid and even overlapping turn-taking, a high degree of co-articulation, and fragmentary language. We describe experiments using both push-to-talk as well as cross-talk recording conditions. Our results indicate that conversational speech recognition and translation is possible, even in a free crosstalk environment. To date, our system has achieved performances of over 80% acceptable translations on transcribed input, and over 70% acceptable translations on speech input recognized with a 70-80% word accuracy. The system’s performance on spontaneous conversations recorded in a cross-talk environment is shown to be as good and even slightly superior to the simpler and easier push-to-talk scenario.
- A. Lavie, Lori S. Levin, Tanja Schultz, C. Langley, Benjamin Han, A. Tribble, D. Gates, D. Wallace, Kay Peterson. 2001. Domain Portability in Speech-to-Speech Translation. Abstract: Speech-to-speech translation has made significant advances over the past decade, with several high-visibility projects (C-STAR, Verb-mobil, the Spoken Language Translator, and others) significantly advancing the state-of-the-art. While speech recognition can currently effectively deal with very large vocabularies and is fairly speaker independent, speech translation is currently still effective only in limited, albeit large, domains. The issue of domain portability is thus of significant importance, with several current research efforts designed to develop speech-translation systems that can be ported to new domains with significantly less time and effort than is currently possible.
- Katharina Probst, Ralf D. Brown, J. Carbonell, A. Lavie, Lori S. Levin, Erik Peterson. 2001. Design and implementation of controlled elicitation for machine translation of low-density languages. Abstract: NICE is a machine translation project for low-density languages. We are building a tool that will elicit a controlled corpus from a bilingual speaker who is not an expert in linguistics. The corpus is intended to cover major typological phenomena, as it is designed to work for any language. Using implicational universals, we strive to minimize the number of sentences that each informant has to translate. From the elicited sentences, we learn transfer rules with a version space algorithm. Our vision for MT in the future is one in which systems can be quickly trained for new languages by native speakers, so that speakers of minor languages can participate in education, health care, government, and internet without having to give up their languages.
- Lori S. Levin, Boris Bartlog, A. F. Llitjós, D. Gates, A. Lavie, D. Wallace, Taro Watanabe, M. Woszczyna. 2000. Lessons Learned from a Task-based Evaluation of Speech-to-Speech Machine Translation. Abstract: For several years we have been conducting Accuracy Based Evaluations (ABE) of the JANUS speech-to-speech MT system (Gates et al., 1997) which measure quality and delity of translation. Recently we have begun to design a Task Based Evaluation for JANUS (Thomas, 1999) which measures goal completion. This paper describes what we have learned by comparing the two types of evaluation. Both evaluations (ABE and TBE) were conducted on a common set of user studies in the semantic domain of travel planning.
- K. Ries, Lori S. Levin, Liza Valle, A. Lavie, A. Waibel. 2000. Shallow Discourse Genre Annotation in CallHome Spanish. Abstract: The classification of speech genre is not yet an established task in language technologies. However we believe that it is a task that will become fairly important as large amounts of audio (and video) data become widely available. The technological cability to easily transmit and store all human interactions in audio and video could have a radical impact on our social structure. The major open question is how this information can be used in practical and beneficial ways. As a first approach to this question we are looking at issues involving information access to databases of human-human interactions. Classification by genre is a first step in the process of retrieving a document out of a large collection. In this paper we introduce a local notion of speech activities that are exist side-by-side in conversations that belong to speech-genre: While the genre of CallHome Spanish is personal telephone calls between family members the actual instances of these calls contain activities such as storytelling, advising, interrogation and so forth. We are presenting experimental work on the detection of those activities using a variety of features. We have also observed that a limited number of distinguised activities can be defined that describes most of the activities in this database in a precise way. Proceedings of the Second International Conference On Language Ressources And Evaluation, LREC 2000, Athens, Greece, 31st May-2nd June 2000
- Lori S. Levin, D. Gates, A. Lavie, F. Pianesi, D. Wallace, Taro Watanabe. 2000. Evaluation of a Practical Interlingua for Task-Oriented Dialogue. Abstract: IF (Interchange Format), the interlingua used by the C-STAR consortium, is a speech-act based interlingua for task-oriented dialogue. IF was designed as a practical interlingua that could strike a balance between expressivity and simplicity. If it is too simple, components of meaning will be lost and coverage of unseen data will be low. On the other hand, if it is too complex, it cannot be used with a high degree of consistency by collaborators on different continents. In this paper, we suggest methods for evaluating the coverage of IF and the consistency with which it was used in the C-STAR consortium.
- Lori S. Levin, K. Ries, Ann E. Thymé-Gobbel, A. Lavie. 1999. Tagging of Speech Acts and Dialogue Games in Spanish Call Home. Abstract: The Clarity project is devoted to automatic detection and classification of discourse structures in casual, non-task-oriented conversation using shallow, corpus-based methods of analysis. For the Clarity project, we have tagged speech acts and dialogue games in the Call Home Spanish corpus. We have done preliminary cross-level experiments on the relationship of word and speech act n-grams to dialogue games. Our results show that the label of a game cannot be predicted from n-grams of words it contains. We get better than baseline results for predicting the label of a game from the sequence of speech acts it contains, but only when the speech acts are hand tagged, and not when they are automatically detected. Our future research will focus on finding linguistic cues that are more predictive of game labels. The automatic classification of speech acts and games is carried out in a multi-level architecture that integrates classification at multiple discourse levels instead of performing them sequentially.
- Lori S. Levin, Ann E. Thymé-Gobbel, A. Lavie, K. Ries, K. Zechner. 1998. A discourse coding scheme for conversational Spanish. Abstract: This paper describes a 3-level manual discourse coding scheme that we have devised for manual tagging of the CallHome Spanish (CHS) and CallFriend Spanish (CFS) databases used in the CLARITY project. The goal of CLARITY is to explore the use of discourse structure in understanding conversational sp eech. The project combines empirical methods for dialogue processing with state-of-the art LVCSR (using the JANUS recognizer). The three levels of the coding scheme are (1) a speech act level consisting of a tag set extended from DAMSL and Switchboard; (2) dialogue game level defined by initiative and intention; and (3) an act ivity level defined within topic units. The manually tagged dialog ues are used to train automatic classifiers. We present preliminary results for statement categorization, and give an in-progress repo rt of automatic speech act classification and topic boundary identific ation.
- M. Finke, Maria Lapata, A. Lavie, Lori S. Levin, L. Tomokiyo, T. Polzin, K. Ries, A. Waibel, K. Zechner. 1998. INFERRING DISCOURSE STRUCTURE FROM SPEECH. Abstract: The goal of the CLARITY project is to explore the use of discourse structure in the understanding of conversational speech. Within project CLARITY we aim to develop automatic classifiers for three levels of discourse structure in Spanish telephone conversations: speech acts, dialogue games, and discourse segments. This paper presents our first results and research plans in three areas: definition of discourse structure units and manual annotation of CALLHOME SPANISH, speech recognition, and automated segmentation and labeling of speech acts.
- Lori S. Levin, D. Gates, A. Lavie, A. Waibel. 1998. An interlingua based on domain actions for machine translation of task-oriented dialogues. Abstract: This paper describes an interlingua for spoken language translation that is based on domain actions in the travel planning domain. Domain actions are composed of speech acts (e.g., request-information), attributes (e.g., size, price), and objects (e.g., hotel, ﬂight) and can take arguments. Development of the interlingua is guided by a database containing travel dialogues in English, Korean, Japanese, and Italian. There are currently 423 domain actions that cover hotel reservation and transportation. The interlingua will soon be extended to cover tours, tourist attractions, and events. The interlingua is used by the C-STAR speech translation consortium for translating travel planning dialogues in six languages: English, Japanese, German, Korean, Italian, and French. The paper also addresses the role of the interlingua in Carnegie Mellon’s J ANUS translation system.
- Lori S. Levin, Ann E. Thymé-Gobbel, A. Lavie, K. Ries, K. Zechner. 1998. In Proceedings of ICSLP-98 A DISCOURSE CODING SCHEME FOR CONVERSATIONAL SPANISH. Abstract: This paper describes a 3-level manual discourse coding scheme that we have devised for manual tagging of the CallHome Spanish (CHS) and CallFriend Spanish (CFS) databases used in the CLARITY project. The goal of CLARITY is to explore the use of discourse structure in understanding conversational speech. The project combines empirical methods for dialogue processing with state-of-the art LVCSR (using the JANUS recognizer). The three levels of the coding scheme are (1) a speech act level consisting of a tag set extended from DAMSL and Switchboard; (2) dialogue game level defined by initiative and intention; and (3) an activity level defined within topic units. The manually tagged dialogues are used to train automatic classifiers. We present preliminary results for automatic speech act classification and topic boundary identification and inter-coder speech act confusion matrices.
- C. Rosé, Lori S. Levin. 1998. An Interactive Domain Independent Approach to Robust Dialogue Interpretation. Abstract: We discuss an interactive approach to robust interpretation in a large scale speech-to-speech translation system. Where other interactive approaches to robust interpretation have depended upon domain dependent repair rules, the approach described here operates efficiently without any such hand-coded repair knowledge and yields a 37% reduction in error rate over a corpus of noisy sentences.
- A. Waibel, A. Lavie, Lori S. Levin. 1997. Janus: A System for Translation of Conversational Speech. Abstract: Janus is a large scale system for interactive spoken language translation that has been developed at Carnegie Mellon University and the University of Karlsruhe in the course of the last seven years. The system currently accepts spontaneous conversational speech in a limited domain in English, German or Spanish and produces output in German, English, Spanish, Japanese and Korean. In this overview article of the Janus system we describe how the system has evolved over the years and developed it's current architecture. We brieey describe the current system components, summarize our system development and evaluation methods, and present some of our most recent performance evaluation results. Finally , we discuss our current eeorts to signiicantly expand the domain of coverage of the system, and the future directions we intend to explore within the context of this project.
- Maite Taboada, Lori S. Levin, A. Waibel, N. Green, A. Lavie. 1997. Discourse Information for Disambiguation : The Phoenix Approach in JANUSM. Abstract: For any given utterance out of what we can loosely call context, there is usually more than one possible interpretation. A speaker's utterance of an elliptical expression, like the gure \twelve fteen", might have a diierent meaning depending on the discourse context, the way the conversation has evolved until that point, and the previous speaker's utterance. If this is a problem for any human listener, the problem grows considerably when it is a parser doing the disambiguation. In this project, I intend to help a parser disambiguate among diierent possible parses for an input sentence, with the nal goal of improving the translation in an end-to-end speech translation system. One of the problems machine translation within a speech system faces is the presence of dissuencies and recognizer errors. A grammar designed to accept only perfectly formed sentences will fail on this type of input. The Phoenix parser Ward 91, Ward 94] was designed to capture the content of spoken dialogue through semantic grammars, which assign an input string to a concept, putting together a sequence of concepts that might form a complete thought or sequence, usually assigning a speech act to the sequence. If we are able to understand illocutionary force in the input language, we can produce the same illocutionary force in the output language, irrespective of the actual 1
- A. Lavie, A. Waibel, Lori S. Levin, M. Finke, D. Gates, Marsal Gavaldà, T. Zeppenfeld, P. Zhan. 1997. Janus-III: speech-to-speech translation in multiple languages. Abstract: This paper describes JANUS-III, our most recent version of the JANUS speech-to-speech translation system. We present an overview of the system and focus on how system design facilitates speech translation between multiple languages, and allows for easy adaptation to new source and target languages. We also describe our methodology for evaluation of end-to-end system performance with a variety of source and target languages. For system development and evaluation, we have experimented with both push-to-talk as well as cross-talk recording conditions. To date, our system has achieved performance levels of over 80% acceptable translations on transcribed input, and over 70% acceptable translations on speech input recognized with a 75-90% word accuracy. Our current major research is concentrated on enhancing the capabilities of the system to deal with input in broad and general domains.
- A. Waibel, M. Finke, D. Gates, Marsal Gavaldà, T. Kemp, A. Lavie, Lori S. Levin, M. Maier, L. Tomokiyo, A. McNair, I. Rogina, K. Shima, T. Sloboda, M. Woszczyna, T. Zeppenfeld, P. Zhan. 1996. JANUS-II-translation of spontaneous conversational speech. Abstract: JANUS-II is a research system to design and test components of speech-to-speech translation systems as well as a research prototype for such a system. We focus on two aspects of the system: (1) the new features of the speech recognition component JANUS-SR, and (2) the end-to-end performance of JANUS-II, including a comparison of two machine translation strategies used for JANUS-MT (PHOENIX and GLR*).
- A. Lavie, Lori S. Levin, Yan Qu, A. Waibel, D. Gates, Marsal Gavaldà, L. Tomokiyo, Maite Taboada. 1996. Dialogue processing in a conversational speech translation system. Abstract: Attempts at discourse processing of spontaneously spoken dialogue face several difficulties: multiple hypotheses that result from the parser's attempts to make sense of the output from the speech recognizer, ambiguity that results from segmentation of multi-sentence utterances, and cumulative error-errors in the discourse context which cause further errors when subsequent sentences are processed. In this paper we describe how the JANUS multi-lingual speech-to-speech translation system addresses problems that arise in discourse processing of spontaneous speech. We describe our robust parsers, our procedures for segmenting long utterances, and two approaches to discourse processing that attempt to deal with ambiguity and cumulative error.
- A. Lavie, D. Gates, Marsal Gavaldà, L. Tomokiyo, A. Waibel, Lori S. Levin. 1996. Multi-lingual Translation of Spontaneously Spoken Language in a Limited Domain. Abstract: JANUS is a multi-lingual speech-to-speech translation system designed to facilitate communication between two parties engaged in a spontaneous conversation in a limited domain. In an attempt to achieve both robustness and translation accuracy we use two different translation components: the GLR module, designed to be more accurate, and the Phoenix module, designed to be more robust. We analyze the strengths and weaknesses of each of the approaches and describe our work on combining them. Another recent focus has been on developing a detailed end-to-end evaluation procedure to measure the performance and effectiveness of the system. We present our most recent Spanish-to-English performance evaluation results.
- A. Lavie, A. Waibel, Lori S. Levin, D. Gates, Marsal Gavaldà, T. Zeppenfeld, P. Zhan, Oren Glickman. 1996. Translation of conversational speech with JANUS-II. Abstract: We investigate the possibility of translating continuous spoken conversations in a cross talk environment. This is a task known to be difficult for human translators due to several factors. It is characterized by rapid and even overlapping turn taking, a high degree of coarticulation, and fragmentary language. We describe experiments using both push to talk as well as cross talk recording conditions. Our results indicate that conversational speech recognition and translation is possible, even in a free crosstalk environment. To date, our system has achieved performances of over 80%, acceptable translations on transcribed input, and over 70% acceptable translations on speech input recognized with a 70-80% word accuracy. The system's performance on spontaneous conversations recorded in a cross talk environment is shown to be as good and even slightly superior to the simpler and easier push to talk scenario.
- A. Lavie, Lori S. Levin, A. Waibel, D. Gates, Marsal Gavaldà, L. Tomokiyo. 1996. JANUS: multi-lingual translation of spontaneous speech in limited domain. Abstract: Janus is a multi-lingual speech translation system currently operating in the domain of meeting scheduling. Translating spontaneous speech requires a high degree of robustness to overcome the disfluencies of spoken language as well as errors in speech recognition. In this system description, we focus on the robust speech translation components in Janus—the skipping GLR* parser, the segmentation of full utterances into semantic dialogue units (SDUs), and the late-stage disambiguation of utterances. We will also describe how the end-to-end translation performance of the system is evaluated and present our latest Spanish-to-English evaluation results.
- C. Rosé, Barbara Maria Di Eugenio, Lori S. Levin, C. V. Ess-Dykema. 1995. Discourse Processing of Dialogues with Multiple Threads. Abstract: In this paper we will present our ongoing work on a plan-based discourse processor developed in the context of the Enthusiast Spanish to English translation system as part of the JANUS multi-lingual speech-to-speech translation system. We will demonstrate that theories of discourse which postulate a strict tree structure of discourse on either the intentional or attentional level are not totally adequate for handling spontaneous dialogues. We will present our extension to this approach along with its implementation in our plan-based discourse processor. We will demonstrate that the implementation of our approach outperforms an implementation based on the strict tree structure approach.
- Lori S. Levin, Oren Glickman, Yan Qu, C. Rosé, D. Gates, A. Lavie, A. Waibel, Carol Van Ess-Dykema. 1995. Using Context in Machine Translation of Spoken Language. Abstract: We report on techniques for using discourse context to reduce ambiguity and improve translation accuracy in a multi-lingual (Spanish, German, and English) spoken language translation system. The techniques involve statistical models as well as knowledge-based models including discourse plan inference. This work is carried out in the context of the Janus project at Carnegie Mellon University and the University of Karlsruhe.
- Lori S. Levin, S. Nirenburg. 1994. The Correct Place of Lexical Semantics in Interlingual MT. Abstract: Inlerlingual MT has tyl)ically come to incltLde a syntactic analysis of source language (SI ,) text followed hy its semm~tic interpretation ~.uld representation in terms of a text meaning representation (TMR) scheme, an interlingu,'t. Recently two distinct views of the nattzre of lhe inlerlingua have become current one based on a worhl model (e.g., Nirenburg et al., 1992) and another one based on the notion of lexieal conceptual structure (LCS) (e.g., Dorr, 1992). In this paper we analyze the role of LCS in the extraction of text memfing and argue that, thotlgh it cannot be considered an interlingua when used by itself, it etmtribtltes signilic+mtly 1o the Sl)eciiication of an ac~ teal interlingua. The task of ;el interlingual MT system btfilder is, then, to lind tt way to integrate the informalion provided in LCS into an ontology-molivaled text meaning representation serving as interlingua. In this paper, we propose a model for Ibis integration mid illustrate the processes and static knowledge sources involved, centrally including tile lexicon. In Section 2 wc propose a model of MT that involves both an LCS-based lexical semantic slruclure and a 'FMR that is not b:tsed on LCS. Because our lexicon lbrmalism does not represent LeSs , but semantic role names that serve ~us labels for LCS variables, we will use Ihe abhreviation SDI+S (for synlax-driven lexical semanlies, Nirenburg grad Levin, 1992) in reference 1o our system instead of LCS. We argue that TMR and SI)LS are both necessary and that they are distinct. This model forms the basis of lexical-semanlic treatment of lexls in the multilingual MTl)rojectMikrokosmos. In Seclion 3 we present specific exmnples as analyzed in Mikrokosmos. Wc illustrate the static knowledge sources (primarily the lexicon) and the representations that are l)roduccd (syntax, lexical semantics, and TMR). The Mikrokosmos model is based on a Iheory of form-to-meaning corrcsl)ondence which relies on the concept of a society of microlheories inlegrated in a noLi-Slratiticational manner. We brielly sketch the main points of this theory in the [inal SeCliOn of this paper,
- J. Carbonell, D. Farwell, R. Frederking, Stephen Helmreich, E. Hovy, Kevin Knight, Lori S. Levin, S. Nirenburg. 1994. PANGLOSS. Abstract: The PANGLOSS project is a three-way equal Machine Translation partnership funded since 1991 by the US Advanced Research Projects Agency (ARPA). The three participating partners are the Center for Machine Translation (CMT) at Carnegie Mellon University in Pittsburgh, the Computing Research Laboratory (CRL) at New Mexico State University in Las Cruces, and the Information Sciences Institute (ISI) of the University of Southern California in Marina del Rey.
- Lori S. Levin, S. Nirenburg. 1993. Principles and Idiosyncracies in MT Lexicons. Abstract: The purpose of an MT lexicon is to facilitate translation. If we adhere to a symbolic (non-statistical) approach then we need a representation of meaning as the basis of translation. This representation is produced by programs typically called semantic and pragmatic interpreters, based on a variety of knowledge sources, such as grammars and lexicons. The grammar rules and lexicon entries vary in generality (productivity) in that they can apply to a very broad class of phenomena, such as all nouns, or to a particular lexical unit, such as however. The size of these rule domains forms, in fact, a range from the former to the latter. It is, naturally, preferable, from the point of view of generality of theory and economy ("capturing generalizations") to prefer the use of few powerful rules applicable to broad domains. However, language analysis shows that this noble pursuit promises but limited success. In a multitude of routine cases it becomes difficult to make generalizations. This leads to the necessity of directly recording information about how to process small classes of phenomena, specifically those that could not be covered by general rules. The trick is to find the watershed between what can be processed on general principles and what is idiosyncratic in language, what we can calculate and what we have to know literally.
- H. Kitano, H. Tomabechi, Lori S. Levin. 1989. Ambiguity Resolution in the DMTRANS PLUS. Abstract: We present a cost-based (or energy-based) model of disambiguation. When a sentence is ambiguous, a parse with the least cost is chosen from among multiple hypotheses. Each hypothesis is assigned a cost which is added when: (1) a new instance is created to satisfy reference success, (2) links between instances are created or removed to satisfy constraints on concept sequences, and (3) a concept node with insufficient priming is used for further processing. This method of ambiguity resolution is implemented in DMTRANS PLUS, which is a second generation bi-directional English/Japanese machine translation system based on a massively parallel spreading activation paradigm developed at the Center for Machine Translation at Carnegie Mellon University.
