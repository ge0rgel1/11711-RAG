Ralf Brown
Paper count: 78
- Jae Dong Kim, Ralf D. Brown, J. Carbonell. 2015. - 2010 Chunk-Based EBMT. Abstract: Corpus driven machine translation approaches such as Phrase-Based Statistical Machine Translation and Example-Based Machine Translation have been successful by using word alignment to find translation fragments for matched source parts in a bilingual training corpus. However, they still cannot properly deal with systematic translation for insertion or deletion words between two distant languages. In this work, we used syntactic chunks as translation units to alleviate this problem, improve alignments and show improvement in BLEU for Korean to English and Chinese to English translation tasks.
- Yiming Yang, J. Lafferty, Ralf D. Brown, Thomas Pierce, Xin Liu. 2015. Approach to TDT-2 : Segmentation , Detection , and Tracking. Abstract: This paper reports the results achieved by Carnegie Mellon University on the Topic Detection and Tracking Project’s secondyear evaluation for the segmentation, detection, and tracking tasks. Additional post-evaluation improvements are also
- Ralf D. Brown. 2014. Non-linear Mapping for Improved Identification of 1300+ Languages. Abstract: Non-linear mappings of the form P (ngram)γ and log(1+τP (ngram)) log(1+τ) are applied to the n-gram probabilities in five trainable open-source language identifiers. The first mapping reduces classification errors by 4.0% to 83.9% over a test set of more than one million 65-character strings in 1366 languages, and by 2.6% to 76.7% over a subset of 781 languages. The second mapping improves four of the five identifiers by 10.6% to 83.8% on the larger corpus and 14.4% to 76.7% on the smaller corpus. The subset corpus and the modified programs are made freely available for download at http://www.cs.cmu.edu/∼ralf/langid.html.
- Aaron B. Phillips, Ralf D. Brown. 2011. Training Machine Translation with a Second-Order Taylor Approximation of Weighted Translation Instances. Abstract: The Cunei Machine Translation Platform is an open-source MT system designed to model instances of translation. One of the challenges to this approach is effective training. We describe two techniques that improve the training procedure and allow us to leverage the strengths of instance-based modeling. First, during training we approximate our model with a second-order Taylor series. Second, we discount models based on the magnitude of their approximation. By reducing error in training, our model now consistently outperforms the standard SMT model with gains ranging from 0.51 to 3.77 BLEU on GermanEnglish and Czech-English test sets.
- Rashmi Gangadharaiah, Ralf D. Brown, J. Carbonell. 2010. Monolingual Distributional Profiles for Word Substitution in Machine Translation. Abstract: Out-of-vocabulary (OOV) words present a significant challenge for Machine Translation. For low-resource languages, limited training data increases the frequency of OOV words and this degrades the quality of the translations. Past approaches have suggested using stems or synonyms for OOV words. Unlike the previous methods, we show how to handle not just the OOV words but rare words as well in an Example-based Machine Translation (EBMT) paradigm. Presence of OOV words and rare words in the input sentence prevents the system from finding longer phrasal matches and produces low quality translations due to less reliable language model estimates. The proposed method requires only a monolingual corpus of the source language to find candidate replacements. A new framework is introduced to score and rank the replacements by efficiently combining features extracted for the candidate replacements. A lattice representation scheme allows the decoder to select from a beam of possible replacement candidates. The new framework gives statistically significant improvements in English-Chinese and English-Haitian translation systems.
- Ralf D. Brown. 2010. Taming Structured Perceptrons on Wild Feature Vectors. Abstract: Structured perceptrons are attractive due to their simplicity and speed, and have been used successfully for tuning the weights of binary features in a machine translation system. In attempting to apply them to tuning the weights of real-valued features with highly skewed distributions, we found that they did not work well. This paper describes a modification to the update step and compares the performance of the resulting algorithm to standard minimum error-rate training (MERT). In addition, preliminary results for combining MERT or structured-perceptron tuning of the log-linear feature weights with coordinate ascent of other translation system parameters are presented.
- Jae Dong Kim, Ralf D. Brown, J. Carbonell. 2010. Chunk-Based EBMT. Abstract: Corpus driven machine translation approaches such as Phrase-Based Statistical Machine Translation and Example-Based Machine Translation have been successful by using word alignment to find translation fragments for matched source parts in a bilingual training corpus. However, they still cannot properly deal with systematic translation for insertion or deletion words between two distant languages. In this work, we used syntactic chunks as translation units to alleviate this problem, improve alignments and show improvement in BLEU for Korean to English and Chinese to English translation tasks.
- Rashmi Gangadharaiah, Ralf D. Brown, J. Carbonell. 2010. Automatic Determination of Number of clusters for creating Templates in Example-Based Machine Translation. Abstract: Example-Based Machine Translation (EBMT), like other corpus based methods, requires substantial parallel training data. One way to reduce data requirements and improve translation quality is to generalize parts of the parallel corpus into translation templates. This automated generalization process requires clustering. In most clustering approaches the optimal number of clusters (N ) is found empirically on a tune set which often takes several days. This paper introduces a spectral clustering framework that automatically estimates the optimal N and removes unstable oscillating points. The new framework produces significant improvements in low-resource EBMT settings for English-to-French (≈1.4 BLEU points), English-to-Chinese (≈1 BLEU point), and English-to-Haitian (≈2 BLEU points). The translation quality with templates created using automatically and empirically found best N were almost the same. By discarding “incoherent” points, a further boost in translation scores is observed, even above the empirically found N .
- Kathy A Baker, Steven Bethard, Michael Bloodgood, Ralf D. Brown, Chris Callison-Burch, Glen A. Coppersmith, B. Dorr, Wes Filardo, Kendall Giles, Anni Irvine, Mike Kayser, Lori S. Levin, Justin Martineau, J. Mayfield, Scott Miller, Aaron B. Phillips, A. Philpot, C. Piatko, Lane Schwartz, David M. Zajic. 2009. Semantically Informed Machine Translation ( SIMT ). Abstract: Acknowledgment: This work is supported, in part, by the Human Language Technology Center of Excellence. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsor.
- Aaron B. Phillips, Ralf D. Brown. 2009. Cunei Machine Translation Platform : System Description. Abstract: In this work we present Cunei, a hybrid, open-source platform for machine translation that models each example of a phrase-pair at run-time and combines them in dynamic collections. This results in a flexible framework that provides consistent modeling and the use of non-local features.
- Rashmi Gangadharaiah, Ralf D. Brown, J. Carbonell. 2009. Active Learning in Example-Based Machine Translation. Abstract: In data-driven Machine Translation ap-proaches, like Example-Based MachineTranslation (EBMT) (Brown, 2000) andStatistical Machine Translation (Vogel etal., 2003), the quality of the translationsproduced depends on the amount of train-ing data available. While more data is al-ways useful, a large training corpus canslow down a machine translation system.We would like to selectively sample thehugecorpustoobtainasub-corpusofmostinformative sentence pairs that would leadto good quality translations. Reducing theamount of training data also enables oneto easily port an MT system onto smalldevices that have less memory and stor-age capacity. In this paper, we proposeusingActiveLearningstrategiestosamplethemostinformativesentencepairs. Therehas not been much progress in the ap-plication of active learning theory in ma-chine translation due to the complexity ofthe translation models. We use a pool-based strategy to selectively sample in-stances from a parallel corpora which notonly outperformed a random selector butalso a previously used sampling strategy(Eck et al., 2005) in an EBMT framework(Brown, 2000) by about one BLEU point(Papineni et al., 2002).
- Ralf D. Brown. 2008. Exploiting Document-Level Context for Data-Driven Machine Translation. Abstract: This paper presents a method for exploiting document-level similarity between the documents in the training corpus for a corpus-driven (statistical or example-based) machine translation system and the input documents it must translate. The method is simple to implement, efficient (increases the translation time of an example-based system by only a few percent), and robust (still works even when the actual document boundaries in the input text are not known). Experiments on French-English and Arabic-English showed relative gains over the same system without using document-level similarity of up to 7.4% and 5.4%, respectively, on the BLEU metric.
- Aaron B. Phillips, V. Cavalli-Sforza, Ralf D. Brown. 2007. Improving example-based machine translation through morphological generalization and adaptation. Abstract: Example Based Machine Translation (EBMT) is limited by the quantity and scope of its training data. Ev en with a reasonably large corpus, we will not have examples that cover everyt hing we want to translate. This problem is especial ly severe in Arabic due to its rich morphology. We demonstrate a novel method that exploits the regular nature of Arabic morphology t o increase the quality and coverage of machine translation. Through the use of generalization and rewrite rules, we are able to r ecover the English translation of phrases that do not exist in the training corpora. Furthermore, this system shows improvement in BLEU even with a training corpus of 1.4 million sentence pairs.
- Rashmi Gangadharaiah, Ralf D. Brown, J. Carbonell. 2006. Spectral Clustering for Example Based Machine Translation. Abstract: Prior work has shown that generalization of data in an Example Based Machine Translation (EBMT) system, reduces the amount of pre-translated text required to achieve a certain level of accuracy (Brown, 2000). Several word clustering algorithms have been suggested to perform these generalizations, such as k-Means clustering or Group Average Clustering. The hypothesis is that better contextual clustering can lead to better translation accuracy with limited training data. In this paper, we use a form of spectral clustering to cluster words, and this is shown to result in as much as 29.08% improvement over the baseline EBMT system.
- Christian Monson, A. F. Llitjós, Roberto Aranovich, Lori S. Levin, Ralf D. Brown, Eric Peterson, J. Carbonell, A. Lavie. 2006. Building NLP Systems for Two Resource-Scarce Indigenous Languages : Mapudungun and Quechua. Abstract: By adopting a “first-things-first” approach we overcome a number of challenges inherent in developing NLP Systems for resourcescarce languages. By first gathering the necessary corpora and lexicons we are then enabled to build, for Mapudungun, a spellingcorrector, morphological analyzer, and two Mapudungun-Spanish machine translation systems; and for Quechua, a morphological analyzer as well as a rule-based Quechua-Spanish machine translation system. We have also worked on languages (Hebrew, Hindi, Dutch, and Chinese) for which resources such as lexicons and morphological analyzers were available. The flexibility of the AVENUE project architecture allows us to take a different approach as needed in each case. This paper describes the Mapudungun and Quechua systems. 1. The AVENUE Project The long-term goal of the AVENUE project at CMU is to facilitate machine translation for a larger percentage of the world’s languages by reducing the cost and time of producing MT systems. There are a number of radically different ways to approach MT. Each of these methods of accomplishing machine translation has a different set of strengths and weaknesses and each requires different resources to build. The AVENUE approach combines these different types of MT in one “omnivorous” system that will “eat” whatever resources are available to produce the highest quality MT possible given the resources. If a parallel corpus is available in electronic form, we can use example-based machine translation (EBMT) (Brown et al., 2003; Brown, 2000), or Statistical machine translation (SMT). If native speakers are available with training in computational linguistics, a human-engineered set of rules can be developed. Finally, if neither a corpus nor a human computational linguist is available, AVENUE uses a newly developed machine learning technique (Probst, 2005) to learn translation rules from data that is elicited from native speakers. As detailed in the remainder of this paper, the particular resources that the AVENUE project produced facilitated developing an EBMT and a humancoded rule-based MT system for Mapudungun, and a hand-built rule-based MT system for Quechua. Automatic rule learning has been applied experimentally for several other language pairs: Hindi-to-English (Lavie et al. 2003) and Hebrew-to-English (Lavie et al. 2004). The AVENUE project as a whole consists of six main modules (Figure 1), which are used in different combinations for different languages: 1) elicitation of a word aligned parallel corpus (Levin et al. in press); 2) automatic learning of translation rules (Probst, 2005) and morphological rules (Monson et al. 2004); 3) the run time MT system for performing source to target language translation based on transfer rules; 4) the EBMT system (Brown, 1997); 5) a statistical “decoder” for selecting the most likely translation from the available alternatives; and 6) a module that allows a user to interactively correct translations and automatically refines the translation rules (Font Llitjós et al. 2005a). 2. AVENUE and Indigenous Languages of the Western Hemisphere Over the past six years the AVENUE project at the Language Technologies Institute at Carnegie Mellon University has worked with native informants and the government of Chile to produce a variety of natural language processing (NLP) tools for Mapudungun, an indigenous South American language spoken by less than 1 million people in Chile and Argentina. During the final year and a half of this time, the AVENUE team has also been developing tools for Quechua, spoken by approximately 10 million people in Peru, Bolivia, Ecuador, South of Colombia, and northern Argentina. Electronic resources for both Quechua and Mapudungun are scarce. At the time the AVENUE team started working on Mapudungun, even simple natural language tools such as morphological analyzers or spelling correctors did not exist. In fact, there were few electronic resources from which such natural language tools might be built. There were no standard Mapudungun text or speech corpora, or lexicons, and no parsed treebanks. The text that does exist is in a variety of competing orthographic formats. More resources exist for Quechua but they are still far from what is needed to build a complete MT system. In addition to these practical challenges facing construction of natural language systems for Mapudungun and Quechua, there are also theoretical and human factor challenges. Both Mapudungun and Quechua pose unique challenges from a linguistic theory perspective, since they have complex agglutinative morphological structures. In addition Mapudungun is polysynthetic, incorporating objects into the verb of a sentence. Agglutination and polysynthesis are both properties that the majority languages, for which most natural language resources have been built, do not possess. Human factors also pose a particular challenge for these two languages. Namely, there is a scarcity of people trained in computational linguistics who
- Ralf D. Brown, Jae Dong Kim, Peter J. Jansen, J. Carbonell. 2005. Symmetric Probabilistic Alignment. Abstract: We recently decided to develop a new alignment algorithm for the purpose of improving our Example-Based Machine Translation (EBMT) system's performance, since subsentential alignment is critical in locating the correct translation for a matched fragment of the input. Unlike most algorithms in the literature, this new Symmetric Probabilistic Alignment (SPA) algorithm treats the source and target languages in a symmetric fashion. 
 
In this short paper, we outline our basic algorithm and some extensions for using context and positional information, and compare its alignment accuracy on the Romanian-English data for the shared task with IBM Model 4 and the reported results from the prior workshop.
- Ralf D. Brown. 2005. Context-sensitive Retrieval for Example-based Translation. Abstract: Example-Based Machine Translation (EBMT) systems have typically operated on individual sentences without taking into account prior context. By adding a simple reweighting of retrieved fragments of training examples on the basis of whether the previous translation retrieved any fragments from examples within a small window of the current instance, translation performance is improved. A further improvement is seen by performing a similar reweighting when another fragment of the current input sentence was retrieved from the same training example. Together, a simple, straightforward implementation of these two factors results in an improvement on the order of 1.0–1.6% in the BLEU metric across multiple data sets in multiple languages.
- Jae Dong Kim, Ralf D. Brown, Peter J. Jansen, J. Carbonell. 2005. Symmetric probabilistic alignment for example-based translation. Abstract: Since subsentential alignment is critically important to the translation quality of an Example-Based Machine Translation (EBMT) system which operates by finding and combining phrase-level matches against the training examples, we recently decided to de- velop a new alignment algorithm for the purpose of improving the EBMT system's per- formance. Unlike most algorithms in the literature, this new Symmetric Probabilistic Align- ment (SPA) algorithm treats the source and target languages in a symmetric fashion. In this paper, we describe our basic algorithm and some extensions for using context and posi- tional information, compare its alignment accuracy with IBM Model 4, and report on ex- periments in which either IBM Model 4 or SPA alignments are substituted for the aligner currently built into the EBMT system. Both Model 4 and SPA are significantly better than the internal aligner and SPA slightly outperforms Model 4 despite being handicapped by incomplete integration with EBMT.
- V. Cavalli-Sforza, Ralf D. Brown, J. Carbonell, Peter J. Jansen, Jae Dong Kim. 2004. Challenges in using an example-based MT system for a transnational digital government project. Abstract: We describe ongoing efforts towards and challenges in using an Example-Based Machine Translation (EBMT) system in the context of a multinational, multi-university and multi-agency transnational digital government project. The project is aimed at applying information technology to the problem of collecting and sharing information securely in a multilingual context. We report on a number of issues encountered in obtaining and using language data for the EBMT system, discuss our current solutions, and briefly describe ongoing enhancements to the system to meet some of the technical and practical challenges posed by using this machine translation approach in the project domain.
- Christian Monson, Lori S. Levin, R. Vega, Ralf D. Brown, A. F. Llitjós, A. Lavie, J. Carbonell, Eliseo Cañulef, Rosendo Huisca. 2004. Data Collection and Analysis of Mapudungun Morphology for Spelling Correction. Abstract: This paper describes part of a three year collaboration between Carnegie Mellon University's Language Technologies Institute, the Programa de Educacion Intercultural Bilingue of the Chilean Ministry of Education, and Universidad de La Frontera (Temuco, Chile). We are currently constructing a spelling checker for Mapudungun, a polysynthetic language spoken by the Mapuche people in Chile and Argentina. The spelling checker will be built in MySpell, the spell checking system used by the open source office suite OpenOffice. This paper also describes the spoken language corpus that is used as a source of data for developing the spelling checker.
- R. Hutchinson, Paul N. Bennett, J. Carbonell, Peter J. Jansen, Ralf D. Brown. 2003. Maximal Lattice Overlap in Example-Based Machine Translation. Abstract: Example-Based Machine Translation (EBMT) retrieves pre-translated phrases from a sentence-aligned bilingual training corpus to translate new input sentences. EBMT uses long pre-translated phrases effectively but is subject to disfluencies at phrasal translation boundaries. We address this problem by introducing a novel method that exploits overlapping phrasal translations and the increased confidence in translation accuracy they imply. We specify an efficient algorithm for producing translations using overlap. Finally, our empirical analysis indicates that this approach produces higher quality translations than the standard method of EBMT in a peak-to-peak comparison. Email: rah+@cs.cmu.edu, pbennett+@cs.cmu.edu, jgc+@cs.cmu.edu, pjj+@cs.cmu.edu, ralf+@cs.cmu.edu Work supported in part by the National Science Foundation under grant number IIS-9982226 (MLIAM: MUCHMORE: Multilingual Concept Hierarchies for Medical Information Organization and Retrieval) and award number IIS-9873009 (KDI: Universal Information Access: Translingual Retrieval, Summarization, Tracking, Detection and Validation).
- Ralf D. Brown, R. Hutchinson, Paul N. Bennett, J. Carbonell, Peter J. Jansen. 2003. Reducing boundary friction using translation-fragment overlap. Abstract: Many corpus-based Machine Translation (MT) systems generate a number of partial translations which are then pieced together rather than immediately producing one overall translation. While this makes them more robust to ill-formed input, they are subject to disfluencies at phrasal translation boundaries even for well-formed input. We address this “boundary friction” problem by introducing a method that exploits overlapping phrasal translations and the increased confidence in translation accuracy they imply. We specify an efficient algorithm for producing translations using overlap. Finally, our empirical analysis indicates that this approach produces higher quality translations than the standard method of combining non-overlapping fragments generated by our Example-Based MT (EBMT) system in a peak-to-peak comparison.
- Lori S. Levin, R. Vega, J. Carbonell, Ralf D. Brown, A. Lavie, Eliseo Cañulef, C. Huenchullan. 2002. Data Collection and Language Technologies for Mapudungun. Abstract: Mapudungun is spoken by over 900,000 people (Mapuche) in Chile and Argentina. Thanks to an active bilingual and multicultural education program, Mapuche children are now being taught to be literate in both Mapudungun and Spanish. The Chilean Ministry of Education has teamed up with the Language Technologies Institute’s AVENUE project to collect data and produce language technologies that support bilingual education. The main resource that has come out of the Mineduc-LTI partnership is Mapudungun-Spanish parallel corpus consisting of approximately 200,000 words of text and 120 hours of transcribed speech. Plans are being made for machine translation and computer-assisted instruction.
- Katharina Probst, Ralf D. Brown. 2002. Using Similarity Scoring To Improve the Bilingual Dictionary for Word Alignment. Abstract: We describe an approach to improve the bilingual cooccurrence dictionary that is used for word alignment, and evaluate the improved dictionary using a version of the Competitive Linking algorithm. We demonstrate a problem faced by the Competitive Linking algorithm and present an approach to ameliorate it. In particular, we rebuild the bilingual dictionary by clustering similar words in a language and assigning them a higher cooccurrence score with a given word in the other language than each single word would have otherwise. Experimental results show a significant improvement in precision and recall for word alignment when the improved dicitonary is used.
- Ralf D. Brown. 2002. Dynamic stopwording for story link detection. Abstract: Carnegie Mellon University entered two systems in the Story Link Detection track of the 2001 Topic Detection and Tracking (TDT) evaluation. These systems were one of our systems from the 1999 TDT evaluation [1], retuned for the new corpus, which had the third-best cost measure; and a new system that adds clustering and dynamically-generated stopwording, which had the best cost measure among all submissions for the default evaluation condition. This paper describes the enhancements which were made and some which were attempted but not used in the evaluation.
- R. Frederking, E. Steinbrecher, Ralf D. Brown, Alexander I. Rudnicky, J. Moody. 2002. Speech Translation on a Tight Budget without Enough Data. Abstract: The Tongues speech-to-speech translation system was developed for the US Army chaplains, with fairly stringent constraints on time, budget, and available data. The resulting prototype was required to undergo a quite realistic field test. We describe the development and architecture of the system, the field test, and our analysis of its results. The system performed quite well, especially given its development constraints.
- Katharina Probst, Ralf D. Brown. 2002. Using Similarity Scoring to Improve the Bilingual Dictionary for Sub-sentential Alignment. Abstract: We describe an approach to improve the bilingual cooccurrence dictionary that is used for word alignment, and evaluate the improved dictionary using a version of the Competitive Linking algorithm. We demonstrate a problem faced by the Competitive Linking algorithm and present an approach to ameliorate it. In particular, we rebuild the bilingual dictionary by clustering similar words in a language and assigning them a higher cooccurrence score with a given word in the other language than each single word would have otherwise. Experimental results show a significant improvement in precision and recall for word alignment when the improved dicitonary is used.
- A. Black, Ralf D. Brown, R. Frederking, K. Lenzo, J. Moody, Alexander I. Rudnicky, Rita Singh, E. Steinbrecher. 2002. RAPID DEVLOPEMENT OF SPEECH-TO-SPEECH TRANSLATION SYSTEMS. Abstract: This paper describes building of the basic components, par-ticularly speech recognition and synthesis, of a speech-to-speech translation system. This work is described within the framework of the “Tongues: small footprint speech-to-speech translation device” developed at CMU and Lockheed Martin for use by US Army Chaplains.
- A. Black, Ralf D. Brown, R. Frederking, Rita Singh, J. Moody, E. Steinbrecher. 2002. TONGUES: rapid development of a speech-to-speech translation system. Abstract: We carried out a one-year project to build a portable speech-to-speech translation system in a new language that could run on a small portable computer. Croatian was chosen as the target language. The resulting system was tested with real users on a trip to Croatia in the spring of 2001. We describe its basic components, the methods we used to build them, initial evaluation results, and related significant observations. This work was done in conjunction with the US Army Chaplain School; chaplains are often the only personnel in a position to communicate with local people over non-military issues such as medical supplies, refugees, etc. This paper thus reports on a realistic instance of rapidly deploying and field-testing a speech-to-speech translator using current technology.
- R. Frederking, A. Black, Ralf D. Brown, J. Moody, E. Steinbrecher. 2002. Field Testing the Tongues Speech-to-Speech Machine Translation System. Abstract: The Tongues portable, rapid-development, speech-to-speech machine translation system was developed specifically to allow a realistic field-test of a deployable prototype. In this paper we will describe the system, its field-testing using regular US Army officers and naive Croatians, and the evaluation of these tests. The evaluation includes analysis of answers to a questionnaire, analysis of system transcript logs, and the authors’ qualitative observations. The overall result of the test was that while the system did successfully aid translation, it requires further development before it would be ready for regular field use. 1. The Tongues System The Tongues system was funded by the US Army to support the mission of the US Army chaplains, who are increasingly called upon to deal with local populations, usually without the benefit of human translators. It is thus intended to be used by a trained US Army chaplain with a completely naive and untrained non-English speaker. The architecture and user interface of the Tongues system were based in large measure on the Diplomat system (Frederking et al., 2000). The speech recognition system used was the open-source Sphinx II (Huang et al., 1992); the translation system was a EBMT/MEMT (ExampleBased MT/Multi-Engine MT) system (Brown, 1996; Frederking and Nirenburg, 1994; Brown and Frederking, 1995) very similar to that in Diplomat; and the synthesis system was the open-source Festival (Black et al., 1998). While the initial system was specifically to demonstrate translation in both directions between English and Croatian, the design was also required to allow rapid development for new languages. To ensure rapid development, the entire project was only allowed to take one calendar year, including contractual arrangements, hiring language experts, etc. The total development effort was similarly restricted: six senior research personnel (the authors of this paper) provided an estimated total of about two (2) fulltime person-years of effort. In addition to the senior staff, there were also part-time Croatian informants, chaplains, and some student programmers. We should note that some of the translation data used to train the system was collected for the Diplomat project (Frederking et al., 2000). In addition to rapid development, the system was not permitted to be restricted to a narrowly-limited domain, but had to be wide-coverage. (Both of these properties were important for the chaplains’ envisioned activities.) Since we were to build a broad-coverage system in a short period of time on a small budget, data-driven approaches were the only reasonable choice. In order to provide in-domain conversational data, we arranged at the start of the project to record a number of chaplains in role-playing conversations of the type they expected the device to encounter. Fortunately, the chaplains were familiar with role-playing exercises, and all had relevant field experiences to re-enact. Both sides of the conversations were spoken in English. These were digitally recorded with head-mounted microphones at 16KHz in stereo (one speaker on each channel), as this was closest to the intended audio channel characteristics of the eventual system. In all, we recorded 46 conversations, ranging from a few minutes to 20 minutes length. This provided a total of 4.25 hours of actual speech. The recorded conversations were hand-transcribed at the word level, and translated into Croatian by native Croatian speakers. The English recordings were used for training the English speech recognition models. The transcripts and their translations were added to the EBMT system’s example base of parallel sentences. A subset of the Croatian translations were read by native Croatian speakers to create data for the Croatian speech recognizer, as described elsewhere (Black et al., 2002). This simple approach appears to be surprisingly adequate. Simply stringing together a recognizer, translator, and synthesizer does not make a very useful speech-to-speech translation system. A good interface is necessary to make the parts work together in such a way that a user can actually derive benefit from it. Using our experience from the earlier Diplomat system, we designed the Tongues interface to be asymmetric, with the Croatian side being as simple as possible, and any necessary complexity handled on the English side, since the chaplain would be trained and practiced in using the system. Even the English side was not terribly complex (see Figure 1). We included a back-translation capability, to allow a user with no knowledge of the target language to better assess the quality of the translation. (We could not use the approach of generating paraphrases from meaning representations, since the system does not use any meaning representations.) We also included several user-requested features, such as built-in pre-recorded instructions and explanations for the Croatian (since the Croatian speaker is completely naive regarding the device and the chaplain’s intentions), emergency key phrases (such as “Don’t move!”), and enhancements such as being able to modify the translation lexicon in the field, so that the system could be tuned to more specific tasks. The final system ran on a Windows-based Toshiba Libretto, running at 200MHz with 192MB of memory. At the time of the project (2000) this was the best combination of speed and size that was readily available. The system was equipped with a custom touchscreen, so that the Croatian-speaker would not need to type or use a mouse at all. Aware that the system might be used in situations where the non-English participant would be unfamiliar with computer technology, we included a microphone/speaker handset that looks like a conventional telephone handset. This has the advantage of provided a close-talking microphone, thus making speech recognition easier, while coming in a form factor that will be familiar to most people. We have provided a more detailed description of the development of the Tongues system elsewhere (Black et al., 2002). Our design provides abundant opportunities for user error correction, in an effort to enable cooperative users to communicate well enough to accomplish significant tasks that they could not accomplish without the system (or a bilingual human interpreter), despite the error-prone nature of current speech recognition, broad-coverage rapiddevelopment machine translation, and speech synthesis. Determining whether we have met such a goal requires task-based evaluation; while error rates of components are useful information, the real system-level issue is whether communication is achieved, and at what level of effort. Figure 1: Tongues User Interface.
- Ted Briscoe, B. Boguraev, Ralf D. Brown, S. Nirenburg, L. Cahill, N. Calzolari, R. Bindi, Lauri Carlson, Maria Vilkuna, Julie Carson-Berndsen. 2002. COLING 90: Contents in Volumes 1-3. Abstract: Using Lexicalized Tags for Translation Anne Abeill6 & Yves Schabes & & Aravind K Joshi 3 Combining Phrase Structure and Field Structure Lars Ahrenberg 2 Knowledge Acquisition from Corpora Peter Anick & James Pustejovsky 2 Constraint Logic Grammars Sergio Balari & Luis Damas & Nelma Moreira & & Giovanni B Varile 3 Translation and Grammatical Metaphor John A Bateman 2 Backwards Phonology John Bear 3 A Karaka-based Approach to Parsing Akshar Bharati & Rajeev Sangal 3 Bottom-Up Filtering: A Parsing Strategy for GPSG Philippe Blache & Jeaque-Yves Morin 2 Generating Referring Expressions Russel Block & Helmut Horacek 2 Lexical Ambiguity and Knowledge Representation Branimir Boguraev & James Pustejovsky 2 Towards Personal MT Christian Boitet 3 Partial Descriptions and Systemic Grammar Chris Brew 3 Lexical Semantics via Lexicology Vol
- Ralf D. Brown. 2002. Corpus-driven splitting of compound words.. Abstract: A method is presented for splitting compound words into their constituents based on cognate words in the other language of a parallel corpus. A minor extension to the method using a bilingual lexicon (which may be statistically derived from the corpus) allows the decompounding of words that do not have cognates in the other language. Further, the algorithm can produce, as a by-product, a mapping from compound words in one language to phrases in the other language. The method described in this paper is applied to an example-based machine translation (EBMT) by decompounding the training corpus, and training both the EBMT system and the bilingual lexicon it uses for subsentential alignment from the decompounded corpous. Compared with the original corpus, the decompounded corpus substantially reduces the incidence of word-alignment failure, resulting in a modest overall improvement in performance.
- Katharina Probst, Ralf D. Brown, J. Carbonell, A. Lavie, Lori S. Levin, Erik Peterson. 2001. Design and implementation of controlled elicitation for machine translation of low-density languages. Abstract: NICE is a machine translation project for low-density languages. We are building a tool that will elicit a controlled corpus from a bilingual speaker who is not an expert in linguistics. The corpus is intended to cover major typological phenomena, as it is designed to work for any language. Using implicational universals, we strive to minimize the number of sentences that each informant has to translate. From the elicited sentences, we learn transfer rules with a version space algorithm. Our vision for MT in the future is one in which systems can be quickly trained for new languages by native speakers, so that speakers of minor languages can participate in education, health care, government, and internet without having to give up their languages.
- Ying Zhang, Ralf D. Brown, R. Frederking, A. Lavie. 2001. Pre-processing of bilingual corpora for Mandarin-English EBMT. Abstract: Pre-processing of bilingual corpora plays an important role in Example-Based Machine Translation (EBMT) and Statistical-Based Machine Translation (SBMT). For our Mandarin-English EBMT system, pre-processing includes segmentation for Mandarin, bracketing for English and building a statistical dictionary from the corpora. We used the Mandarin segmenter from the Linguistic Data Consortium (LDC). It uses dynamic programming with a frequency dictionary to segment the text. Although the frequency dictionary is large, it does not completely cover the corpora. In this paper, we describe the work we have done to improve the segmentation for Mandarin and the bracketing process for English to increase the length of English phrases. A statistical dictionary is built from the aligned bilingual corpus. It is used as feedback to segmentation and bracketing to re-segment / re-bracket the corpus. The process iterates several times to achieve better results. The final results of the corpus pre-processing are a segmented/bracketed aligned bilingual corpus and a statistical dictionary. We achieved positive results by increasing the average length of Chinese terms about 60% and 10% for English. The statistical dictionary gained about a 30% increase in coverage.
- Y. Zhang, Ralf D. Brown, R. Frederking. 2001. Adapting an Example-Based Translation System to Chinese. Abstract: We describe an Example-Based Machine Translation (EBMT) system and the adaptations and enhancements made to create a Chinese-English translation system from the Hong Kong legal code and various other bilingual resources available from the Linguistic Data Consortium (LDC).
- Ralf D. Brown. 2001. A Server for Real-Time Event Tracking in News. Abstract: As the flood of information continues to grow, it becomes ever more necessary to extract just the portion of the flow which is of interest to each user. The Topic Detection and Tracking (TDT) project [1, 3, 6, 5] addressed and continues to address this need, but has been of necessity applied in a batch-processing context on a static collection. What is required for topic detection and tracking to be of utility to end-users is a real-time system which operates on a live stream of information. This paper describes the extension and modification of a batch-oriented tracking system into a real-time server for event detection, event tracking, document summarization, and translation.
- Ralf D. Brown. 2001. Transfer-rule induction for example-based translation. Abstract: Previous work has shown that grammars and similar structure can be induced from unlabeled text (both monolingually and bilingually), and that the performance of an example-based machine translation (EBMT) system can be substantially enhanced by using clustering techniques to determine equivalence classes of individual words which can be used interchangeably, thus converting translation examples into templates. This paper describes the combination of these two approaches to further increase the coverage (or conversely, decrease the required training text) of an EBMT system. Preliminary results show that a reduction in required training text by a factor of twelve is possible for translation from French into English.
- Ralf D. Brown. 2000. Automated Generalization of Translation Examples. Abstract: Previous work has shown that adding generalization of the examples in the corpus of an example-based machine translation (EBMT) system can reduce the required amount of pretranslated example text by as much as an order of magnitude for Spanish-English and French-English EBMT. Using word clustering to automatically generalize the example corpus can provide the majority of this improvement for French-English with no manual intervention; the prior work required a large bilingual dictionary tagged with parts of speech and the manual creation of grammar rules. By seeding the clustering with a small amount of manually-created information, even better performance can be achieved. This paper describes a method whereby bilingual word clustering can be performed using standard monolingual document clustering techniques, and its effectiveness at reducing the size of the example corpus required.
- J. Carbonell, Yiming Yang, J. Lafferty, Ralf D. Brown, Thomas Pierce, Xin Liu. 1999. on TDT-2 : Segmentation , Detection and Tracking. Abstract: This paper reports the results achieved by Carnegie Mellon University on the Topic Detection and Tracking Project’s secondyear evaluation for the segmentation, detection, and tracking tasks. Additional post-evaluation improvements are also
- Yiming Yang, J. Carbonell, Ralf D. Brown, Thomas Pierce, B. T. Archibald, Xin Liu. 1999. Learning Approaches to Topic Detection and Tracking. Abstract: This paper studies the eeective use of information retrieval and machine learning techniques in a new task, event detection and tracking. The objective is to automatically detect novel events from chronologically-ordered streams of news stories, and track events of interest over time. We extended existing supervised learning and unsupervised clustering algorithms to allow document classiication based on both information content and temporal aspects of events. A task-oriented evaluation was conducted using Reuters and CNN news stories. We found agglomerative document clustering highly eeective (82% in the F 1 measure) for retrospective event detection, and single-pass clustering with time windowing a better choice for on-line alerting of novel events. We also observed robust learning behavior for k-nearest neighbor (kNN) classiication and a decision-tree approach in event tracking, under the diicult condition when the number of positive training examples is extremely small.
- Ralf D. Brown. 1999. Adding linguistic knowledge to a lexical example-based translation system. Abstract: Example-Based Machine Translation (EBMT) using partial exact matching against a database of translation examples has proven quite successful, but requires a large amount of pre-translated text in order to achieve broad coverage of unrestricted text. By adding linguistically tagged entries to the example base and permitting recursive matches that replace the matched text with the associated tag, substantial reductions in the required amount of pre-translated text can be achieved. A modest investment of time on the order of two person-weeks adding linguistic knowledge reduces the required example text by a factor of six or more, while retaining comparable translation quality. This reduction makes EBMT more attractive for so-called "low-density" languages for which little data is available.
- Yiming Yang, J. Carbonell, J. Lafferty, Ralf D. Brown, Thomas Pierce, Xin Liu. 1999. CMU Report on TDT-2: Segmentation, Detection and Tracking. Abstract: This paper reports the results achieved by Carnegie Mellon University on the Topic Detection and Tracking Project’s secondyear evaluation for the segmentation, detection, and tracking tasks. Additional post-evaluation improvements are also
- Yiming Yang, J. Carbonell, Ralf D. Brown, Thomas Pierce, B. T. Archibald, Xin Liu. 1999. Learning approaches for detecting and tracking news events. Abstract: The authors extend existing supervised-learning and unsupervised-clustering algorithms to allow document classification based on the information content and temporal aspects of news events. They've adapted several IR and machine learning techniques for effective event detection and tracking. The article discusses our research using manually segmented documents.
- Ralf D. Brown, Thomas Pierce, Yiming Yang, J. Carbonell. 1999. Link Detection – Results and Analysis. Abstract: This paper describes the two Story Link Detection systems Carnegie Mellon University (CMU) developed, and examines why their performance on the evaluation data was considerably worse than expected while performance on an alternate evaluation set matched the performance on the training data.
- J. Carbonell, Yiming Yang, J. Lafferty, Ralf D. Brown, Thomas Pierce, Xin Liu. 1999. CMU Approach to TDT-2: Segmentation, Detection, and Tracking. Abstract: This paper reports the results achieved by Carnegie Mellon University on the Topic Detection and Tracking Project’s secondyear evaluation for the segmentation, detection, and tracking tasks. Additional post-evaluation improvements are also
- Ralf D. Brown. 1998. Automatically-Extracted Thesauri for Cross-Language IR: When Better is Worse. Abstract: A statistical algorithm for extracting bilingual term dictionaries (thesauri) from parallel text is presented, along with reenements for improving their size and accuracy. Somewhat paradoxically , increasing the accuracy of the extracted thesaurus can in fact reduce the performance of an IR system using it to perform query translation for cross-language information retrieval.
- J. Carbonell, Yiming Yang, R. Frederking, Ralf D. Brown, Y. Geng, Danny Lee. 1997. Translingual Information Retrieval: A Comparative Evaluation. Abstract: Translingual information retrieval TIR con sists of providing a query in one language and searching document collections in one or more di erent languages This paper introduces new TIR methods and reports on comparative TIR experiments with these new methods and with previously reported ones in a realistic setting Methods fall into two categories query trans lation based and statistical IR approaches es tablishing translingual associations The re sults show that using bilingual corpora for au tomated extraction of term equivalences in con text outperforms other methods Translin gual versions of the Generalized Vector Space Model GVSM and Latent Semantic Indexing LSI perform relatively well as does translin gual pseudo relevance feedback PRF All showed relatively small performance loss be tween monolingual and translingual versions Query translation based on a general machine readable bilingual dictionary heretofore the most popular method did not match the per formance of other more sophisticated methods Also the previous very high LSI results in the literature were discon rmed by more realistic relevance based evaluations
- Ralf D. Brown. 1997. Automated dictionary extraction for “knowledge-free” example-based translation. Abstract: An Example-Based Machine Translation system is supplied with a sentencealigned bilingual corpus, but no other knowledge sources. Using the knowledge implicit in the corpus, it generates a bilingual word-for-word dictionary for alignment during translation. With such an automatically-generated dictionary, the system covers (with equivalent quality) more of its input on unseen texts than the same system does when provided with a manually-created general-purpose dictionary and other knowledge sources.
- R. Frederking, Ralf D. Brown. 1996. The Pangloss-Lite machine translation system. Abstract: 1. Pangloss-Lite Overview The Pangloss-Lite (PanLite) machine translation system is a standalone C++ re-implementation of several major components from the Pangloss machine translation system [Nirenburg et al. 95]. It incorporates the Pangloss Example-Based MT (EBMT) [Brown 96a] and Transfer-Based MT engines, and its statistical language modeller [Brown and Frederking 95], as well as a newly-implemented morphological analyzer, within the multi-engine MT architecture [Frederking and Nirenburg 94] developed during the course of the project.
- Ralf D. Brown. 1996. Example-Based Machine Translation in the Pangloss System. Abstract: The Pangloss Example-Based Machine Translation engine (PanEBMT) is a translation system requiring essentially no knowledge of the structure of a language, merely a large parallel corpus of example sentences and a bilingual dictionary. Input texts are segmented into sequences of words occurring in the corpus, for which translations are determined by subsentential alignment of the sentence pairs containing those sequences. These partial translations are then combined with the results of other translation engines to form the final translation produced by the Pangloss system. In an internal evaluation, PanEBMT achieved 70.2% coverage of unrestricted Spanish news-wire text, despite a simplistic subsentential alignment algorithm, a suboptimal dictionary, and a corpus from a different domain than the evaluation texts.
- Ralf D. Brown, R. Frederking. 1995. Applying Statistical English Language Modelling to Symbolic Machine Translation. Abstract: The PANGLOSS Mark III system [Frederking et al. 94] was from the outset designed to be a symbolic, human-aided machine translation (MT) system. The need arose to rapidly adapt it for use as a fully-automated MT system. Our solution to this problem was to add a statistical English language model (ELM) to replace the most significant user activity, selecting between alternate translations produced by the system. The language model used is a trigram model with backoff to bigram and unigram probabilities. The language modeling and search procedure are described in detail, and comparison is made to other trigram-based statistical MT work.
- Ralf D. Brown, J. Kyle. 1994. Network Interrupts: A Programmer's Reference to Network Apis. Abstract: Network Interrupts is a comprehensive reference to network-related interrupt calls on IBM PCs and compatible machines. It includes calls from over three dozen major application interfaces and various resident utilities. In addition, this book is the only available source of information on potential conflicts between calls from different network APIs.This book includes complete coverage of the following interrupt services and topics: * MS-DOS network support * FTP and other TCP/IP software * NetBIOS * LANtastic network operating system * DESQview/X networking * Network serial I/O emulation * Novell's NetWare shell and utilities * Open Data-Link Interface * Microsoft's LAN Manager * IBM mainframe connectivity. A companion volume, PC Interrupts: A Programmer's Reference to BIOS, DOS, and Third Party Calls provides concise descriptions of all the system calls from many different sources--MS-DOS, the ROM BIOS, and various APIs (application program interfaces) such as Windows 3.x, DESQview, and Advanced Power Management. Together these books represent the most comprehensive reference to PC interrupt calls available. 0201626446B04062001
- Ralf D. Brown. 1993. Using Multiple Adaptively-Weighted Strategies for the Resolution of Demonstratives. Abstract: Abstract : The resolution of demonstratives is an interesting topic which nonetheless has received relatively little attention. As with pronominal anaphora, there is currently no comprehensive theory of demonstrative references, although there are numerous partial or microtheories. This dissertation describes a multistrategy approach to resolving demonstrative pronouns and noun phrases, using constraint, preference, and recovery strategies implementing various microtheories and heuristics. The multistrategy approach, which has proven itself for resolving pro anaphora, allows easy integration of new microtheories. This provides incremental improvements in performance, permitting a decreasing reliance on user intervention as the system is able to resolve a larger percentage of demonstratives. A major weakness of the multistrategy approach, the necessity to carefully choose the weights of the strategy is overcome by automatically optimizing the weights as demonstratives are resolved. Such an adaptively-weighted multistrategy approach has been implemented in the modular and extensible MASTER-D system which is expected to be applicable to other linguistic phenomena in addition to the resolution of demonstratives.
- A. Schulman, Ralf D. Brown, David Maxey. 1992. Undocumented DOS; A Programmer's Guide to Reserved MS-DOS Functions and Data Structures, 2nd Ed. (Th. Abstract: Widely considered one of the best DOS programming books ever published, this reference has become an essential addition to any serious programmer's library. Covers Windows 3.1, DOS 5, and DR DOS 6, with coverage of all the newest interrupts and data structures. Includes 3.5" 1.4 MB disk.
- Ralf D. Brown, J. Kyle. 1991. PC Interrupts: A Programmer's Reference to BIOS, DOS, and Third Party Calls. Abstract: From the Publisher: 
The first edition of PC Interrupts was the first and only complete reference to all the system calls an IBM programmer needed. Now updated and expanded, PC Interrupts Second Edition provides concise descriptions of all the system calls from many different sources - MS-DOS, the ROM BIOS, and various APIs (application program interfaces) such as Windows 3.x, DESQview, and Advanced Power Management. Over 50 major APIs, dozens of resident utilities, as well as BIOS and MS-DOS services are covered. In addition, this book is the only available source of information on potential conflicts between calls from different APIs. This book includes complete coverage of the following interrupt services and topics: ROM BIOS; multitaskers/task-switchers; VCPI, DPMI, and DOS extenders; virtual DMA Specification; remote-control software; FAX software; hardware and video; low-level disk and serial I/O; Microsoft Windows; advanced power management; debugging tools; and programming language support. A companion volume, Network Interrupts: A Programmer's Reference to Network APIs draws together all the information about network system calls, including NetWare 4, NetWare Lite, Windows for Workgroups, and Windows NT.
- Ralf D. Brown. 1990. Human-Computer Interaction for Semantic Disambiguation. Abstract: We describe a semi-automatic semantic disambiguator integrated in a knowledge-based machine translation system. It is used to bridge the analysis and generation stages in machine translation. The user interface of the disambiguator is built on mouse-based multiple-selection menus.
- Ohoe Kim, J. Chollet, Ralf D. Brown, D. Rauschenberg. 1987. Orthonormal bases of symmetry classes with computer-generated examples. Abstract: A method is given for constructing an orthonormal basis of a symmetry class of tensor whose associated group is the full symmetric group. This construction has been used to write a computer program which efficiently calculates a basis for any such symmetry class. Two examples which illustrate both the method and the program are included.
- Yiming Yang, J. Carbonell, Ralf D. Brown, J. Lafferty, Thomas Pierce, Tom Ault. None. Chapter 5 Multi-strategy Learning for Topic Detection and Tracking A joint report of eMU approaches to multilingual TDT. Abstract: This chapter reports on eMU's work in all the five TDT-1999 tasks, including segmentation (story boundary identification), topic tracking, topic detection, first story detection, and story-link detection. We have addressed these tasks as supervised or unsupervised classification problems, and applied a variety of statistical learning algorithms to each problem for comparison. For segmentation we used exponential language models and decision trees; for topic tracking we used primarily k-nearest-neighbors classification (also language models, decision trees and a variant of the Rocchio approach); for topic detection we used a combination of incremental clustering and agglomerative hierarchical clustering, and for first story detection and story link detection we used a cosine-similarity based measure. We also studied the effect of combining the output of alternative methods for producing joint classification decisions in topic tracking. We found that a combined use of multiple methods typically improved the classification of new topics when compared to using any single method. We examined our approaches with multi-lingual corpora, including stories in English, Mandarin and Spanish, and multi-media corpora consisting of newswire texts and the results of automated speech recognition for broadcast news sources. The methods worked reasonably well under all of the above conditions.
