Scott Fahlman
Paper count: 123
- Jeffrey Chen, S. Fahlman. 2023. Score: A Rule Engine for the Scone Knowledge Base System. Abstract: We present Score, a rule engine designed and implemented for the Scone knowledge base system. Scone is a knowledge base system designed for storing and manipulating rich representations of general knowledge in symbolic form. It represents knowledge in the form of nodes and links in a network structure, and it can perform basic inference about the relationships between different elements efficiently. On its own, Scone acts as a sort of"smart memory"that can interface with other software systems. One area of improvement for Scone is how useful it can be in supplying knowledge to an intelligent agent that can use the knowledge to perform actions and update the knowledge base with its observations. We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone. Production rule systems consist of"if-then"production rules that try to match their predicates to existing knowledge and fire their actions when their predicates are satisfied. We propose two kinds of production rules, if-added and if-needed rules, that differ in how they are checked and fired to cover multiple use cases. We then implement methods to efficiently check and fire these rules in a large knowledge base. The new rule engine is not meant to be a complex stand-alone planner, so we discuss how it fits into the context of Scone and future work on planning systems.
- Alicia Sagae, S. Fahlman. 2018. Knowledge Resource Development for Identifying Matching Image Descriptions. Abstract: Background knowledge resources contribute to the performance of many current systems for textual inference tasks (QA, textual entailment, summarization, retrieval, and others). However, it can be difficult to assess how additions to such a knowledge base will impact a system that relies on it. This paper describes the incremental, task-driven development of an ontology that provides features to a system that retrieves images based on their textual descriptions. We perform error analysis on a baseline system that uses lexical features only, then focus ontology development on reducing these errors against a development set. The resulting ontology contributes more to performance than domain-general resources like WordNet, even on a test set of previously unseen
- Alicia Sagae, S. Fahlman. 2015. Image Retrieval with Textual Label Similarity Features. Abstract: This article presents a knowledge-based solution for retrieving English descriptions of images. We analyse the errors made by a baseline system that relies on term frequency, and we find that the task requires deeper semantic representation. Our solution is to perform incremental, task-driven development of an ontology. Ontological features are then applied in a machine-learning algorithm for ranking candidate image descriptions. This work demonstrates the advantage of combining knowledge-based and statistical approaches for text retrieval, and it establishes the important result that an empirically tuned task-specific ontology performs better than a domain-general resource like WordNet, even on previously unseen examples. Copyright © 2015 John Wiley & Sons, Ltd.
- S. Fahlman. 2015. Position Paper: Knowledge-Based Mechanisms for Deception. Abstract: In an earlier paper, I described in some detail how a system based on symbolic knowledge representation and reasoning could model and reason about an act of deception encountered in a children's story. This short position paper extends that earlier work, adding new analysis and discussion about the nature of deception, the desirability of building deceptive AI systems, and the computational mechanisms necessary for deceiving others and for recognizing their attempts to deceive us.
- S. Fahlman. 2012. Beyond Idiot-Savant AI. Abstract: Why has progress toward broad, flexible, human-like AI been so slow? I suggest the key reason is that, in recent years, few researchers have actually focused on this goal. Instead they have focused on achieving super-human (but brittle) performance in a few narrow problem domains. That is a valuable enterprise, but some attention should also be paid to the original ‐ and still unachieved ‐ goal stated decades ago by the founders of the AI field.
- S. Fahlman. 2011. Using Scone's Multiple-Context Mechanism to Emulate Human-Like Reasoning. Abstract: Scone is a knowledge-base system developed specifically to support human-like common-sense reasoning and the understanding of human language. One of the unusual features of Scone is its multiple-context system. Each context represents a distinct world-model, but a context can inherit most of the knowledge of another context, explicitly representing just the differences. We explore how this multiple-context mechanism can be used to emulate some aspects of human mental behavior that are difficult or impossible to emulate in other representational formalisms. These include reasoning about hypothetical or counter-factual situations; understanding how the world model changes over time due to specific actions or spontaneous changes; and reasoning about the knowledge and beliefs of other agents, and how their mental state may affect the actions of those agents.
- Wei Chen, S. Fahlman. 2008. Modeling Mental Contexts and Their Interactions. Abstract: The ability to understand and process multiple mental contexts is an important aspect of human cognition. By “mental contexts” we mean different beliefs, states of knowledge, points of view, or suppositions, all of which may change over time. In this paper, we propose an approach for modeling and reasoning about the interactions among multiple mental contexts using the context activation scheme in Scone knowledge-base (KB) system. Our model factors the mental context representation into two separate components: (1) a dynamic mental context network (2) a set of rules which guides the activities among mental contexts and their evolution as a result of this. Our model is capable of combining newly available information and old memories stored in the context network to produce new mental states. We demonstrate the approach with a storyunderstanding task, in which the users feed information to the program, then ask questions about the newly updated beliefs or assumptions.
- Miguel Angel Díaz, Miguel Angel Peña, S. Fahlman, G. Hinton. 2008. HIERARCHICAL LOGICAL DESCRIPTION AND NEURAL RECOGNITION OF COMPLEX PATTERNS. Abstract: Authors suggested earlier hierarchical method for definition of class description at pattern recognition problems solution. In this paper development and use of such hierarchical descriptions for parallel representation of complex patterns on the base of multi-core computers or neural networks is proposed.
- S. Fahlman. 2008. Working Paper 57 a Hypothesis-frame System for Recognition Problems. Abstract: This paper proposes a new approach to a broad class of recognition problems ranging from medical diagnosis to vision. The features of this approach include a top-down hypothesize-and-test style and the use of a great deal of high-level knowledge about the subject. This knowledge is packaged into small groups of related facts and procedures called frames. Work reported herein was conducted at the Artificial Intelligence Laboratory, a Massachusetts Institute of Technology research program supported in part by the Advanced Research Projects Agency of the Department of Defense and monitored by the Office of Naval Research under Contract Number N00014-70-A-0362-0005. Working Papers are informal papers intended for internal use. A Hypothesis-Frame System for Recognition Problems Ph.D. Thesis Proposal Scott Fahlman <<The ideas expressed in this paper are still in their formative stages. I would welcome any thoughts readers might have about them, about the proposed research, or about this presentation.>> A pattern of light and darkness strikes a person's retina and he sees a familiar face, a cow, or a cloud shaped like Texas; vibrations strike his eardrum and he hears words and sentences, a Russian accent, or the call of the Arctic Loon; a chess master looks at pieces on a board and sees a vulnerable king, an impenetrable queen-side, a likely pawn for promotion; a doctor listens to symptoms, reads lab reports, thumps the patient, and arrives at his diagnosis. These examples differ in the extent to which they are conscious acts, but they all are acts of recognition the process of fitting some specific set of observable data (called the sample) into some loosely defined conceptual category, chosen from a large number of such categories. Because it lies at the heart of so many of our mental processes, recognition has fascinated philosophers and psychologists for centuries. Gestalt psychology, in particular, owes its existence to the cloud of mystery that surrounds the seemingly instantaneous nature of the recognition act. This thesis will be an attempt to dispel some of that mystery. Most current computer recognition programs employ a bottom-up
- Engin Cinar Sahin, S. Fahlman, Eric Nyberg, Stephen F. Smith. 2008. Episodic Memory Representation in a Knowledge Base , with Application to Event Monitoring and Event Detection. Abstract: The thesis explores the use of a knowledge-based AI system to assist people in executing procedures and detecting events in an observed world. We extend the Scone knowledge-base system with open-ended facilities for representing time and events. Then we use this episodic knowledge representation as the foundation for our event monitoring and event detection algorithms. This approach lets us represent and reason about three fundamental aspects of the observed events: 1. their ontological character and what entities take part in these events (e.g. buying is a kind of transaction that involves an agent, a seller, money and goods) 2. how events change the world over time (e.g. after a buy event the agent has the goods rather than the money) 3. how events may be composed of other subevents (i.e. a buy event may be composed of giving money and receiving goods) We illustrate knowledge-based solutions to the event monitoring problem in the conference organization domain and to the event detection problem in the national security domain.
- B. Lambert, S. Fahlman. 2007. Knowledge-Driven Learning and Discovery. Abstract: The goal of our current research is machine learning with the help and guidance of a knowledge base (KB). Rather than learning numerical models, our approach generates explicit symbolic hypotheses. These hypotheses are subject to the constraints of the KB and are easily human-readable and verifiable. Toward this end, we have implemented algorithms that hypothesize new relations and new types of entities in a KB by examining structural regularities in the KB that represent implicit knowledge. We evaluate these algorithms on a publications KB and a zoology KB.
- A. Tribble, S. Fahlman. 2007. CMU-AT: Semantic Distance and Background Knowledge for Identifying Semantic Relations. Abstract: This system uses a background knowledge base to identify semantic relations between base noun phrases in English text, as evaluated in SemEval 2007, Task 4. Training data for each relation is converted to statements in the Scone Knowledge Representation Language. At testing time a new Scone statement is created for the sentence under scrutiny, and presence or absence of a relation is calculated by comparing the total semantic distance between the new statement and all positive examples to the total distance between the new statement and all negative examples.
- A. Tribble, S. Fahlman. 2006. Resolving Noun Compounds with Multi-Use Domain Knowledge. Abstract: In this paper we describe a system for semantic interpretation of noun compounds that relies on world and domain knowledge from a knowledge base. This architecture combines domain-independent compounding rules with a task-independent knowledge representation, allowing both components to be flexibly reused. We present examples from Scientific American text, on which the system was developed, and then describe an exercise that tests the portability of the architecture to a new domain: email text on the topic of conference planning.
- A. Tribble, B. Lambert, S. Fahlman. 2006. SconeEdit: A Text-guided Domain Knowledge Editor. Abstract: We will demonstrate SconeEdit, a new tool for exploring and editing knowledge bases (KBs) that leverages interaction with domain texts. The tool provides an annotated view of user-selected text, allowing a user to see which concepts from the text are in the KB and to edit the KB directly from this Text View. Alongside the Text View, SconeEdit provides a navigable KB View of the knowledge base, centered on concepts that appear in the text. This unified tool gives the user a text-driven way to explore a KB and add new knowledge.
- S. Fahlman. 2003. Table of Node Types, Link Types, and Modifier Flags. Abstract: "Consider for a moment the layers of structure and meaning that are attached to concepts like lawsuit, birthday party, fire, mother, walrus, cabbage, or king.... If I tell you that a house burned down, and that the fire started at a child's birthday party, you will think immediately of the candles on the cake and perhaps of the many paper decorations. You will not, In all probability, find yourself thinking about playing pin-the- tall-on-the-donkey or about the color of the cake's icing or about the fact that birthdays come once a year. These concepts are there when you need them, but they do not seem to slow down the search for a link between fires and birthday parties."The human mind can do many remarkable things. One of the most remarkable Is its ability to store an enormous quantity and variety of knowledge and to locate and retrieve whatever part of it is relevant in a particular context quickly and in most cases almost without effort. "If we are ever to create an artificial intelligence with human-like abilities," Fahlman writes, "we will have to endow it with a comparable knowledge-handling facility; current knowledge-base systems fall far short of this goal. This report describes an approach to the problem of representing and using realworld knowledge in a computer."The system developed by Fahlman and presented in this book consists of two more-or-less independent parts. The first is the system's parallel network memory scheme: "Knowledge Is stored as a pattern of interconnections of very simple parallel processing elements: node units that can store a dozen or so distinct marker-bits, and link units that can propagate those markers from node to node, in parallel through the network. Using these marker-bit movements, the parallel network system can p erform searches and many common deductions very quickly."The second (and more traditional) part of the knowledge-base system presented here is NETL, "a vocabulary of conventions and processing algorithms--in some sense, a language--for representing various kinds of knowledge as nodes and links in the network.... NETL incorporates a number of representational techniques--new ideas and new combinations of old ideas-which allow it to represent certain real-world concepts more precisely and more efficiently than earlier systems.... NETL has been designed to operate efficiently on the parallel network machine described above, and to exploit this machine's special abilities. Most of the ideas in NETL are applicable to knowledge-base systems on serial machines as well."
- S. Fahlman. 2002. Selling interrupt rights: A way to control unwanted e-mail and telephone calls. Abstract: Among the great irritations of modern life are un-wanted e-mail (often referred to as " spam " 1) and unwanted telephone calls. In this article I present an approach to controlling these intrusions. The key idea is simple: My attention is a valuable commodity. If you (the sender) want to interrupt me by putting a message in my e-mailbox or by making my telephone ring, you must pay me for the privilege of doing so. More precisely, you must make a binding offer to pay me. If I am happy to hear from you, I will decline the payment; otherwise, I will collect it. This payment compensates me for suffering an unwanted interruption and—more important-ly—it has cost you something to bother me. Since interrupting me is no longer free, advertisers and fund-raisers will no longer choose to send me repetitive , poorly targeted, low-yield messages. Each recipient can set his or her own price. For example , I might set the potential cost of sending an e-mail message to me at $1.00. If you want my phone to ring, the potential cost would be $5.00, or perhaps more if you call at dinnertime or early in the morning. Of course, my friends and business associates would never actually pay these fees. I would only collect the fee from callers who have annoyed me. But once I have been interrupted, it's my decision whether to collect the fee, not the sender's. People in the public eye may have to set their price much higher to avoid constant interruptions. People who are not bothered much by these messages might charge only a few cents—just enough to discourage the truly indiscriminate mass marketers. Here's the catch: Such a system will only be accepted if we can make it relatively painless and hassle-free, both for the owners of phones and e-mail accounts and for their nonspamming friends and associates. In the rest of this article, I suggest some ways in which we might accomplish that. There have been a number of proposals to combat spam through the use of a delivery fee, to be optionally collected by the message recipient. The idea of an " e-stamp " fee for e-mail is generally attributed to Esther Dyson (see Reference 2, for example). Brad Templeton's proposal is a version of e-stamps.
- S. Fahlman. 2000. Computino Facilities A Survey of Present and Near-Future Options. Abstract: At the recent AAAI conference at Stanford, it became apparent that many new AI research centers are being established around the country in industrial and governmental settings and in universities that have not paid much attention to Al in the past. At the same time, many of the established AI centers are in the process of converting from older facilities, primarily based on Decsystem-IO and Decsystem-20 machines, to a variety of newer options. At present, unfortunately, there is no simple answer to the question of what machines, operating systems, and languages a new or upgrading AI facility should use, and this situation has led to a great deal of confusion and anxiety on the part of those researchers and administrators who are faced with making this choice. In this article I will survey the major alternatives available at present and those that are clearly visible on the horizon, and I will try to indicate the advantages and disadvantages of each for AI work. This is mostly information that we have gathered at CMU in the course of planning for our own future computing needs, but the opinions expressed are my own.
- J. Boyan, A. Moore, S. Fahlman. 1998. Learning evaluation functions for global optimization. Abstract: In complex sequential decision problems such as scheduling factory production, planning medical treatments, and playing backgammon, optimal decision policies are in general unknown, and it is often difficult, even for human domain experts, to manually encode good decision policies in software. The reinforcement-learning methodology of “value function approximation” (VFA) offers an alternative: systems can learn effective decision policies autonomously, simply by simulating the task and keeping statistics on which decisions lead to good ultimate performance and which do not. This thesis advances the state of the art in VFA in two ways. 
First, it presents three new VFA algorithms, which apply to three different restricted classes of sequential decision problems: Grow-Support for deterministic problems, ROUT for acyclic stochastic problems, and Least-Squares TD(λ) for fixed-policy prediction problems. Each is designed to gain robustness and efficiency over current approaches by exploiting the restricted problem structure to which it applies. 
Second, it introduces STAGE, a new search algorithm for general combinatorial optimization tasks. STAGE learns a problem-specific heuristic evaluation function as it searches. The heuristic is trained by supervised linear regression or Least-Squares TD(λ) to predict, from features of states along the search trajectory, how well a fast local search method such as hillclimbing will perform starting from each state. Search proceeds by alternating between two stages: performing the fast search to gather new training data, and following the learned heuristic to identify a promising new start state. 
STAGE has produced good results (in some cases, the best results known) on a variety of combinatorial optimization domains, including VLSI channel routing, Bayes net structure-finding, bin-packing, Boolean satisfiability, radiotherapy treatment planning, and geographic cartogram design. This thesis describes the results in detail, analyzes the reasons for and conditions of STAGE's success, and places STAGE in the context of four decades of research in local search and evaluation function learning. It provides strong evidence that reinforcement learning methods can be efficient and effective on large-scale decision problems.
- J. Boyan, A. Moore, S. Fahlman, Tom M. Mitchell, Thomas G. Dietterich. 1996. Learning Evaluation. Abstract: Evaluation functions are an essential component of practical search algorithms for optimization, planning and control. Examples of such algorithms include hillclimb-ing, simulated annealing, best-rst search, A*, and alpha-beta. In all of these, the evaluation functions are typically built manually by domain experts, and may require considerable tweaking to work well. I will investigate the thesis that statistical machine learning can be used to automatically generate high-quality evaluation functions for practical combinatorial problems. The data for such learning is gathered by running trajectories through the search space. The learned evaluation function may be applied either to guide further exploration of the same space, or to improve performance in new problem spaces which share similar features. Two general families of learning algorithms apply here: reinforcement learning and meta-optimization. The reinforcement learning approach, dating back to Samuel's checkers player 1959] but with more recent successes on backgammon Tesauro, 1992] and job-shop scheduling Zhang and Dietterich, 1995], is based on asynchronous dynamic programming with value function approximation. The currently-popular algorithms , Q-learning and TD() with neural networks, run slowly and may even be unstable. I will evaluate several original value-function-approximation algorithms tailored for combinatorial optimization domains. The meta-optimization approach, which has also been applied to game-playing Pol-lack et al., 1996] and combinatorial optimization Ochotta, 1994], is conceptually simpler: we assume a xed parametric form for the evaluation function and optimize it directly. These methods, lacking the theoretical advantages of dynamic programming, have been ignored by the reinforcement-learning community; however, recent advances 1 in local optimization Moore and Schneider, 1996] may help make them superior to reinforcement learning in practice. My research will develop both methods and evaluate them empirically. I will apply these techniques to all or most of the following large-scale combinatorial domains: VLSI channel routing; treatment planning for radiation therapy; scheduling a factory production line; connguring the subsystems of the NASA Outer Planet Or-biter; and move selection in the game of backgammon. I will also validate my new algorithms on standard problems from the optimization and control literatures. Finally , a byproduct of this research will be a software package for public use.
- D. L. Taylor, Lowell D. Harris, R. Debiasio, S. Fahlman, D. Farkas, F. Lanni, M. Nederlof, A. Gough. 1996. Automated interactive microscopy: measuring and manipulating the chemical and molecular dynamics of cells and tissues. Abstract: The Automated Interactive Microscope is a robotic light microscope workstation that combines high performance light microscopy and computing to explore the chemical and molecular dynamics of cells and tissues.
- S. Baluja, S. Fahlman. 1994. Reducing Network Depth in the Cascade-Correlation Learning Architecture,. Abstract: Abstract : The Cascade-Correlation learning algorithm constructs a multi-layer artificial neural network as it learns to perform a given task. The resulting network's size and topology are chosen specifically for this task. In the resulting 'cascade' networks, each new hidden unit receives incoming connections from all input and pre-existing hidden units. In effect, each new unit adds a new layer to the network. This allows Cascade-Correlation to create complex feature detectors, but it typically results in a network that is deeper, in terms of the longest path from input to output, than is necessary to solve the problem efficiently. In this paper we investigate a simple variation of Cascade-Correlation that will build deep nets if necessary, but that is biased toward minimizing network depth. We demonstrate empirically, across a range of problems, that this simple technique can reduce network depth, often dramatically. However, we show that this technique does not, in general, reduce the total number of weights or improve the generalization ability of the resulting networks.
- S. Fahlman. 1994. Roundtable discussion: supercomputing support for advanced biomedical imaging. Abstract: Biomedical imaging takes many forms. The familiar Xrays and CAT scans arc now being joined by such technologies as magnetic resonance imaging (MRI) and advanced forms of light microscopy that can observe living cells and tissues as they grow and change. These new technologies place unusual demands upon the computers that have ~come an integral part of the imaging system, and they present some exciting challenges. We want to enhance, analyze, and display the images in something approaching real-time, which requires computational power at the s u p e ~ p u t e r level and beyond. In addition to raw compuling cycles, these applications stress the acquisition and display hardware, communication channels, storage systems, operating systems (with the need for real-time response), memory capacity, and our ability to build the necessary software. Ultimately, these computing facilities must be packaged into a stand-alone instrument that can be used in a clinical or laboratory setring by people not trained in computer science. This panel will present three well-known experts in different areas of biomedical image processing.-Each will describe the nature of the problems he works on and the computational demands of this work, both present and future. Our goal will be to familiarize the audience with the challenges posed by this exciting fiekl and to identify which computational problems and approaches cut across all of these applications.
- B. Wah, Thomas S. Huang, A. Joshi, D. Moldovan, Y. Aloimonos, R. Bajcsy, D. Ballard, D. DeGroot, K. DeJong, C. Dyer, S. Fahlman, R. Grishman, L. Hirschman, R. Korf, S. Levinson, Daniel P. Miranker, N. H. Morgan, S. Nirenburg, T. Poggio, E. Riseman, Craig Stanfil, S. Stolfo, S. Tanimoto, C. Weems. 1993. Report on Workshop on High Performance Computing and Communications for Grand Challenge Applications: Computer Vision, Speech and Natural Language Processing, and Artificial Intelligence. Abstract: The findings of a workshop, the goals of which were to identify applications, research problems, and designs of high performance computing and communications (HPCC) systems for supporting applications are discussed. In computer vision, the main scientific issues are machine learning, surface reconstruction, inverse optics and integration, model acquisition, and perception and action. In speech and natural language processing (SNLP), issues were identified statistical analysis in corpus-based speech and language understanding, search strategies for language analysis, auditory and vocal-tract modeling, integration of multiple levels of speech and language analyses, and connectionist systems. In AI, important issues that need immediate attention include the development of efficient machine learning and heuristic search methods that can adapt to different architectural configurations, and the design and construction of scalable and verifiable knowledge bases, active memories, and artificial neural networks. >
- S. Fahlman. 1993. Some Thoughts on NETL, 15 Years Later. Abstract: 1. Overview NETL [Fahlman 79] is a knowledge-representation system combining two key ideas: first, the use of a semantic network representation, with built-in capabilities for inheritance, inference, and simple search; second, the use of massively parallel hardware to perform most of these built-in operations in near-constant time, without the need for complex, hand-crafted indexes or application-specific search procedures. NETL was developed as my Ph.D. thesis project in the period from 1974 to 1977, and was published in book form in 1979. In the years since then, the NETL ideas have been influential in a number of ways, though NETL has never really become a part of the mainstream in AI. In this short paper I will present my own personal view of the evolution of NETL, its strengths and weaknesses, and the lessons it might still hold for AI.
- A. Newell, S. Fahlman, Dales A. James, C. R. Taylor. 1992. Information Processing Research. Abstract: This report documents a broad program of basic and applied information processing research conducted by Carnegie Mellon''s School of Computer Science during the period 15 July 1987 through 14 July 1990, and extended through 31 December 1990. We present in detail our seven major research areas: Artificial Intelligence, Image Understanding, Reliable Distributed Systems, Programming Environments, Reasoning About Programs, Uniform Workstation Interfaces, and Very Large Scale Integration. Sections in each chapter present the area''s general research context, the specific problems we addressed, our contributions and their significance, and a bibliography for each chapter.
- Markus Höhfeld, S. Fahlman. 1992. Learning with limited numerical precision using the cascade-correlation algorithm. Abstract: A key question in the design of specialized hardware for simulation of neural networks is whether fixed-point arithmetic of limited numerical precision can be used with existing learning algorithms. An empirical study of the effects of limited precision in cascade-correlation networks on three different learning problems is presented. It is shown that learning can fail abruptly as the precision of network weights or weight-update calculations is reduced below a certain level, typically about 13 bits including the sign. Techniques for dynamic rescaling and probabilistic rounding that allow reliable convergence down to 7 bits of precision or less, with only a small and gradual reduction in the quality of the solutions, are introduced.
- S. Fahlman, Geoffrey E. Hinton. 1990. Connectionist Architectures for Artificial Intelligence. Abstract: A number of researchers have begun exploring the use of massively parallel architectures in an attempt to get around the limitations of conventional symbol processing. Many of these parallel architectures are connectionist: The system's collection of permanent knowledge is stored as a pattern of connections or connection strengths among the processing elements, so the knowledge directly determines how the processing elements interact rather that sitting passively in a memory, waiting to be looked at by the CPU. Some connectionist schemes use formal, symbolic representations, while others use more analog approaches. Some even develop their own internal representations after seeing examples of the patterns they are to recognize or the relationships they are to store. Connectionism is somewhat controversial in the AI community. It is new, still unproven in large-scale practical applications, and very different in style from the traditional AI approach. The authors have only begun to explore the behavior and potential of connectionist networks. In this article, the authors describe some of the central issues and ideas of connectionism, and also some of the unsolved problems facing this approach. Part of the motivation for connectionist research is the possible similarity in function between connectionist networks and the neutral networksmore » of the human cortex, but they concentrate here on connectionism's potential as a practical technology for building intelligent systems.« less
- S. Fahlman. 1990. The Recurrent Cascade-Correlation Architecture. Abstract: Recurrent Cascade-Correlation (RCC) is a recurrent version of the Cascade-Correlation learning architecture of Fahlman and Lebiere [Fahlman, 1990]. RCC can learn from examples to map a sequence of inputs into a desired sequence of outputs. New hidden units with recurrent connections are added to the network as needed during training. In effect, the network builds up a finite-state machine tailored specifically for the current problem. RCC retains the advantages of Cascade-Correlation: fast learning, good generalization, automatic construction of a near-minimal multi-layered network, and incremental training.
- S. Fahlman, C. Lebiere. 1989. The Cascade-Correlation Learning Architecture. Abstract: Cascade-Correlation is a new architecture and supervised learning algorithm for artificial neural networks. Instead of just adjusting the weights in a network of fixed topology. Cascade-Correlation begins with a minimal network, then automatically trains and adds new hidden units one by one, creating a multi-layer structure. Once a new hidden unit has been added to the network, its input-side weights are frozen. This unit then becomes a permanent feature-detector in the network, available for producing outputs or for creating other, more complex feature detectors. The Cascade-Correlation architecture has several advantages over existing algorithms: it learns very quickly, the network determines its own size and topology, it retains the structures it has built even if the training set changes, and it requires no back-propagation of error signals through the connections of the network.
- S. Fahlman. 1988. An empirical study of learning speed in back-propagation networks. Abstract: Most connectionist or "neural network" learning systems use some form of the back-propagation algorithm. However, back-propagation learning is too slow for many applications, and it scales up poorly as tasks become larger and more complex. The factors governing learning speed are poorly understood. I have begun a systematic, empirical study of learning speed in backprop-like algorithms, measured against a variety of benchmark problems. The goal is twofold: to develop faster learning algorithms and to contribute to the development of a methodology that will be of value in future studies of this kind. This paper is a progress report describing the results obtained during the first six months of this study. To date I have looked only at a limited set of benchmark problems, but the results on these are encouraging: I have developed a new learning algorithm that is faster than standard backprop by an order of magnitude or more and that appears to scale up very well as the problem size increases. This research was sponsored in part by the National Science Foundation under Contract Number EET-8716324 and by the Defense Advanced Research Projects Agency (DOD), ARPA Order No. 4976 under Contract F33615-87C-1499 and monitored by the Avionics Laboratory, Air Force Wright Aeronautical Laboratories, Aeronautical Systems Division (AFSC), Wright-Patterson AFB, OH 45433-6543. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of these agencies or of the U.S. Government.
- David B. McDonald, S. Fahlman, Skef Wholey. 1987. Internal design of CMU common Lisp on the IBM RT PC. Abstract: CMU Common Lisp is an implementation of Common Lisp that currently runs on the IBM RT PC under Mach, a Berkeley Unix 4.3 binary compatible operating system. This document describes low level details of the implementation. In particular, it describes the data formats used for all Lisp objects, the assembler language routines (miscops) used to support compiled code, the function call and return mechanism, and other design information necessary to understand the underlying structure of the CMU Common Lisp implementation on the IBM RT PC under the Mach operating system. This research was sponsored by the Defense Advanced Research Projects Agency (DOD) monitored bv the Space and Naval Warfare Systems Command under proposed contract N00039-87.C-0251 m ° m t ° r e d b y The views and conclusions contained in this document are those of the authors and should not be interpreted as STOSJS^^ d t h e r 6 X p r e S S e d 0 r i m p l i e d ' o f * e D e f e n s e Advanced Research Projects Agency or Table of
- S. Fahlman. 1985. TECHNICAL FORUM. Abstract: Among the great irritations of modern life are unwanted e-mail (often referred to as “spam”
 1
) and unwanted telephone calls. In this article I present an approach to controlling these intrusions.
- Skef Wholey, S. Fahlman. 1984. The design of an instruction set for common LISP. Abstract: The design of a microcoded instruction set for executing Common Lisp is presented. The influence that the language design, the machine, and the operating system had on this design is described. A statistical analysis of object code for an earlier instruction set was used to assign specific instruction lengths that led to a significant compression of the object code.
- S. Fahlman, Geoffrey E. Hinton, T. Sejnowski. 1983. Massively Parallel Architectures for AI: NETL, Thistle, and Boltzmann Machines. Abstract: It is becoming increasingly apparent that some aspects of intelligent behavior require enormous computational power and that some sort of massively parallel computing architecture is the most plausible way to deliver such power. Parallelism, rather than raw speed of the computing elements, seems to be the way that the brain gets such jobs done. But even if die need for massive parallelism is admitted, there is still the question of what kind of parallel architecture best fits the needs of various AI tasks. 
 
In this paper we will attempt to isolate a number of basic computational tasks that an intelligent system must perform. We will describe several families of massively parallel computing architectures, and we will see which of diese computational tasks can be handled by each of these families. In particular, we will describe a new architecture, which we call the Boltzmann machine, whose abilities appear to include a number of tasks that are inefficient or impossible on the other architectures.
- S. Fahlman, D. Touretzky, W. Roggen. 1981. Cancellation in a Parallel Semantic Network. Abstract: Handling exceptions to general rules is a persistent and difficult problem in systems for representing knowledge. In semantic networks, this often takes the form of cancelling some item of information, such as membership in a class, that would otherwise be inherited from a higher level description in the type hierarchy. Some conceptually clean approaches to cancellation lead to great inefficiency in accessing the information in the network, and can negate much of the speed advantage that would otherwise be possible in a parallel network system such as NETL. In this paper we explore some of the interactions between cancellation and parallelism in semantic networks, and we propose a cancellation scheme that appears to be workable for NETLIike systems.
- S. Fahlman. 1981. Computing Facilities for AI: A Survey of Present and Near-Future Options. Abstract: At the recent AAAI conference at Stanford, it became apparent that many new AI research centers are being established around the country in industrial and governmental settings and in universities that have not paid much attention to AI in the past. At the same time, many of the established AI centers are in the process of converting from older facilities, primarily based on Decsystem-10 and Decsystem-20 machines, to a variety of newer options. At present, unfortunately, there is no simple answer to the question of what machines, operating systems, and languages a new or upgrading AI facility should use, and this situation has led to a great deal of confusion and anxiety on the part of those researchers and administrators who are faced with making this choice. In this article I will survey the major alternatives available at present and those that are clearly visible on the horizon, and I will try to indicate the advantages and disadvantages of each for AI work. This is mostly information that we have gathered at CMU in the course of planning for our own future computing needs, but the opinions expressed are my own.
- S. Fahlman. 1980. Design Sketch for a Million-Element NETL Machine. Abstract: This paper describes (very briefly) a parallel hardware implementation for NETL-type semantic network memories. A million-element system can be built with about 7000 IC chips, including 4000 64K RAM chips. This compares favorably with the hardware cost of holding the same body of knowledge in a standard computer memory, and offers significant advantages in flexibility of access and the speed of performing certain searches and deductions.
- S. Fahlman. 1979. NETL: A System for Representing and Using Real-World Knowledge. Abstract: Abstract : This report describes a knowledge-base system in which the information is stored in a network of small parallel processing elements--node and link units--which are controlled by an external serial computer. Discussed is NETL, a language for storing real-world information in such a network. A simulator for the parallel network system has been implemented in MACLISP, and an experimental version of NETL is running on this simulator. A number of test-case results and simulated timings will be presented. (Author)
- S. Fahlman. 1975. The Intersection Problem. Abstract: Abstract : This paper is intended as a supplement to AI MEMO 331, "A System for Representing and Using Real-World Knowledge". It is an attempt to redefine and clarify what I now believe the central theme of the research to be. Briefly, I will present the following points: 1. The operation of set-intersection, performed upon large pre-existing sets, plays a pivotal role in the processes of intelligence. 2. Von Neumann machines intersect large sets very. slowly. Attempts to avoid or speed up these intersections have obscured and distorted the other, non-intersection AI problems. 3. The parallel hardware system described in the earlier memo can be viewed as a conceptual tool for thinking about a world in which set-intersection of this sort is cheap. It thus divides many AI problems by factoring out all elements that arise solely due to set intersection.
