Teruko Mitamura
Paper count: 198
- Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg. 2023. Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA. Abstract: The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.
- Zhi-Qi Cheng, Qianwen Dai, Siyao Li, Jingdong Sun, T. Mitamura, A. Hauptmann. 2023. ChartReader: A Unified Framework for Chart Derendering and Comprehension without Heuristic Rules. Abstract: Charts are a powerful tool for visually conveying complex data, but their comprehension poses a challenge due to the diverse chart types and intricate components. Existing chart comprehension methods suffer from either heuristic rules or an over-reliance on OCR systems, resulting in suboptimal performance. To address these issues, we present ChartReader, a unified framework that seamlessly integrates chart derendering and comprehension tasks. Our approach includes a transformer-based chart component detection module and an extended pre-trained vision-language model for chart-to-X tasks. By learning the rules of charts automatically from annotated datasets, our approach eliminates the need for manual rule-making, reducing effort and enhancing accuracy. We also introduce a data variable replacement technique and extend the input and position embeddings of the pre-trained model for cross-task training. We evaluate ChartReader on Chart-to-Table, ChartQA, and Chart-to-Text tasks, demonstrating its superiority over existing methods. Our proposed framework can significantly reduce the manual effort involved in chart analysis, providing a step towards a universal chart understanding model. Moreover, our approach offers opportunities for plug-and-play integration with mainstream LLMs such as T5 and TaPas, extending their capability to chart comprehension tasks.1
- Jiefu Ou, Adithya Pratapa, Rishubh Gupta, T. Mitamura. 2023. Hierarchical Event Grounding. Abstract: Event grounding aims at linking mention references in text corpora to events from a knowledge base (KB). Previous work on this task focused primarily on linking to a single KB event, thereby overlooking the hierarchical aspects of events. Events in documents are typically described at various levels of spatio-temporal granularity. These hierarchical relations are utilized in downstream tasks of narrative understanding and schema construction. In this work, we present an extension to the event grounding task that requires tackling hierarchical event structures from the KB. Our proposed task involves linking a mention reference to a set of event labels from a subevent hierarchy in the KB. We propose a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss. On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events. Code is available at https://github.com/JefferyO/Hierarchical-Event-Grounding
- Sumit Agarwal, Suraj Tripathi, T. Mitamura, C. Rosé. 2022. Zero-shot cross-lingual open domain question answering. Abstract: People speaking different kinds of languages search for information in a cross-lingual manner. They tend to ask questions in their language and expect the answer to be in the same language, despite the evidence lying in another language. In this paper, we present our approach for this task of cross-lingual open-domain question-answering. Our proposed method employs a passage reranker, the fusion-in-decoder technique for generation, and a wiki data entity-based post-processing system to tackle the inability to generate entities across all languages. Our end-2-end pipeline shows an improvement of 3 and 4.6 points on F1 and EM metrics respectively, when compared with the baseline CORA model on the XOR-TyDi dataset. We also evaluate the effectiveness of our proposed techniques in the zero-shot setting using the MKQA dataset and show an improvement of 5 points in F1 for high-resource and 3 points improvement for low-resource zero-shot languages. Our team, CMUmQA’s submission in the MIA-Shared task ranked 1st in the constrained setup for the dev and 2nd in the test setting.
- Srijan Bansal, Suraj Tripathi, Sumit Agarwal, T. Mitamura, Eric Nyberg. 2022. PRO-CS : An Instance-Based Prompt Composition Technique for Code-Switched Tasks. Abstract: Code-switched (CS) data is ubiquitous in today’s globalized world, but the dearth of annotated datasets in code-switching poses a significant challenge for learning diverse tasks across different language pairs. Parameter-efficient prompt-tuning approaches conditioned on frozen language models have shown promise for transfer learning in limited-resource setups. In this paper, we propose a novel instance-based prompt composition technique, PRO-CS, for CS tasks that combine language and task knowledge. We compare our approach with prompt-tuning and fine-tuning for code-switched tasks on 10 datasets across 4 language pairs. Our model outperforms the prompt-tuning approach by significant margins across all datasets and outperforms or remains at par with fine-tuning by using just 0.18% of total parameters. We also achieve competitive results when compared with the fine-tuned model in the low-resource cross-lingual and cross-task setting, indicating the effectiveness of our approach to incorporate new code-switched tasks.
- Zhi-Qi Cheng, Qianwen Dai, Siyao Li, T. Mitamura, A. Hauptmann. 2022. GSRFormer: Grounded Situation Recognition Transformer with Alternate Semantic Attention Refinement. Abstract: Grounded Situation Recognition (GSR) aims to generate structured semantic summaries of images for "human-like'' event understanding. Specifically, GSR task not only detects the salient activity verb (e.g. buying), but also predicts all corresponding semantic roles (e.g. agent and goods). Inspired by object detection and image captioning tasks, existing methods typically employ a two-stage framework: 1) detect the activity verb, and then 2) predict semantic roles based on the detected verb. Obviously, this illogical framework constitutes a huge obstacle to semantic understanding. First, pre-detecting verbs solely without semantic roles inevitably fails to distinguish many similar daily activities (e.g., offering and giving, buying and selling). Second, predicting semantic roles in a closed auto-regressive manner can hardly exploit the semantic relations among the verb and roles. To this end, in this paper we propose a novel two-stage framework that focuses on utilizing such bidirectional relations within verbs and roles. In the first stage, instead of pre-detecting the verb, we postpone the detection step and assume a pseudo label, where an intermediate representation for each corresponding semantic role is learned from images. In the second stage, we exploit transformer layers to unearth the potential semantic relations within both verbs and semantic roles. With the help of a set of support images, an alternate learning scheme is designed to simultaneously optimize the results: update the verb using nouns corresponding to the image, and update nouns using verbs from support images. Extensive experimental results on challenging SWiG benchmarks show that our renovated framework outperforms other state-of-the-art methods under various metrics.
- Srijan Bansal, Suraj Tripathi, Sumit Agarwal, Sireesh Gururaja, Aditya Srikanth Veerubhotla, Ritam Dutt, T. Mitamura, Eric Nyberg. 2022. R3 : Refined Retriever-Reader pipeline for Multidoc2dial. Abstract: In this paper, we present our submission to the DialDoc shared task based on the MultiDoc2Dial dataset. MultiDoc2Dial is a conversational question answering dataset that grounds dialogues in multiple documents. The task involves grounding a user’s query in a document followed by generating an appropriate response. We propose several improvements over the baseline’s retriever-reader architecture to aid in modeling goal-oriented dialogues grounded in multiple documents. Our proposed approach employs sparse representations for passage retrieval, a passage re-ranker, the fusion-in-decoder architecture for generation, and a curriculum learning training paradigm. Our approach shows a 12 point improvement in BLEU score compared to the baseline RAG model.
- Adithya Pratapa, Rishubh Gupta, T. Mitamura. 2022. Multilingual Event Linking to Wikidata. Abstract: We present a task of multilingual linking of events to a knowledge base. We automatically compile a large-scale dataset for this task, comprising of 1.8M mentions across 44 languages referring to over 10.9K events from Wikidata. We propose two variants of the event linking task: 1) multilingual, where event descriptions are from the same language as the mention, and 2) crosslingual, where all event descriptions are in English. On the two proposed tasks, we compare multiple event linking systems including BM25+ (Lv and Zhai, 2011) and multilingual adaptations of the biencoder and crossencoder architectures from BLINK (Wu et al., 2020). In our experiments on the two task variants, we find both biencoder and crossencoder models significantly outperform the BM25+ baseline. Our results also indicate that the crosslingual task is in general more challenging than the multilingual task. To test the out-of-domain generalization of the proposed linking systems, we additionally create a Wikinews-based evaluation set. We present qualitative analysis highlighting various aspects captured by the proposed dataset, including the need for temporal reasoning over context and tackling diverse event descriptions across languages.
- Adithya Pratapa, Zhengzhong Liu, Kimihiro Hasegawa, Linwei Li, Yukari Yamakawa, Shikun Zhang, T. Mitamura. 2021. Cross-document Event Identity via Dense Annotation. Abstract: In this paper, we study the identity of textual events from different documents. While the complex nature of event identity is previously studied (Hovy et al., 2013), the case of events across documents is unclear. Prior work on cross-document event coreference has two main drawbacks. First, they restrict the annotations to a limited set of event types. Second, they insufficiently tackle the concept of event identity. Such annotation setup reduces the pool of event mentions and prevents one from considering the possibility of quasi-identity relations. We propose a dense annotation approach for cross-document event coreference, comprising a rich source of event mentions and a dense annotation effort between related document pairs. To this end, we design a new annotation workflow with careful quality control and an easy-to-use annotation interface. In addition to the links, we further collect overlapping event contexts, including time, location, and participants, to shed some light on the relation between identity decisions and context. We present an open-access dataset for cross-document event coreference, CDEC-WN, collected from English Wikinews and open-source our annotation toolkit to encourage further research on cross-document tasks.
- Steven Y. Feng, Kevin Lu, Zhuofu Tao, Malihe Alikhani, T. Mitamura, E. Hovy, Varun Gangal. 2021. Retrieve, Caption, Generate: Visual Grounding for Enhancing Commonsense in Text Generation Models. Abstract: We investigate the use of multimodal information contained in images as an effective method for enhancing the commonsense of Transformer models for text generation. We perform experiments using BART and T5 on concept-to-text generation, specifically the task of generative commonsense reasoning, or CommonGen. We call our approach VisCTG: Visually Grounded Concept-to-Text Generation. VisCTG involves captioning images representing appropriate everyday scenarios, and using these captions to enrich and steer the generation process. Comprehensive evaluation and analysis demonstrate that VisCTG noticeably improves model performance while successfully addressing several issues of the baseline generations, including poor commonsense, fluency, and specificity.
- Varun Gangal, Steven Y. Feng, E. Hovy, T. Mitamura. 2021. NAREOR: The Narrative Reordering Problem. Abstract: Many implicit inferences exist in text depending on how it is structured that can critically impact the text's interpretation and meaning. One such structural aspect present in text with chronology is the order of its presentation. For narratives or stories, this is known as the narrative order. Reordering a narrative can impact the temporal, causal, event-based, and other inferences readers draw from it, which in turn can have strong effects both on its interpretation and interestingness. In this paper, we propose and investigate the task of Narrative Reordering (NAREOR) which involves rewriting a given story in a different narrative order while preserving its plot. We present a dataset, NAREORC, with human rewritings of stories within ROCStories in non-linear orders, and conduct a detailed analysis of it. Further, we propose novel task-specific training methods with suitable evaluation metrics. We perform experiments on NAREORC using state-of-the-art models such as BART and T5 and conduct extensive automatic and human evaluations. We demonstrate that although our models can perform decently, NAREOR is a challenging task with potential for further exploration. We also investigate two applications of NAREOR: generation of more interesting variations of stories and serving as adversarial sets for temporal/event-related tasks, besides discussing other prospective ones, such as for pedagogical setups related to language skills like essay writing and applications to medicine involving clinical narratives.
- Steven Y. Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush Vosoughi, T. Mitamura, E. Hovy. 2021. A Survey of Data Augmentation Approaches for NLP. Abstract: Data augmentation has recently seen increased interest in NLP due to more work in low-resource domains, new tasks, and the popularity of large-scale neural networks that require large amounts of training data. Despite this recent upsurge, this area is still relatively underexplored, perhaps due to the challenges posed by the discrete nature of language data. In this paper, we present a comprehensive and unifying survey of data augmentation for NLP by summarizing the literature in a structured manner. We first introduce and motivate data augmentation for NLP, and then discuss major methodologically representative approaches. Next, we highlight techniques that are used for popular NLP applications and tasks. We conclude by outlining current challenges and directions for future research. Overall, our paper aims to clarify the landscape of existing literature in data augmentation for NLP and motivate additional work in this area. We also present a GitHub repository with a paper list that will be continuously updated at https://github.com/styfeng/DataAug4NLP
- Vinay Damodaran, Sharanya Chakravarthy, Akshay Kumar, Anjana Umapathy, T. Mitamura, Yuta Nakashima, Noa García, Chenhui Chu. 2021. Understanding the Role of Scene Graphs in Visual Question Answering. Abstract: Visual Question Answering (VQA) is of tremendous interest to the research community with important applications such as aiding visually impaired users and image-based search. In this work, we explore the use of scene graphs for solving the VQA task. We conduct experiments on the GQA dataset which presents a challenging set of questions requiring counting, compositionality and advanced reasoning capability, and provides scene graphs for a large number of images. We adopt image + question architectures for use with scene graphs, evaluate various scene graph generation techniques for unseen images, propose a training curriculum to leverage human-annotated and auto-generated scene graphs, and build late fusion architectures to learn from multiple image representations. We present a multi-faceted study into the use of scene graphs for VQA, making this work the first of its kind.
- Kimihiro Hasegawa, Takaaki Matsumoto, R. Takashima, T. Takiguchi, Y. Ariki, T. Mitamura. 2020. Transfer Learning to Generate Multiple Sentence Question with Leveraging Difference between Datasets. Abstract: Recently, question generation (QG) is getting more attention as the dual task of question answering (QA), improving the performance of QA models. The common setting of the text-based QG task is to output a question by taking a context and an answer as input. In this work, we focus on a semantic aspect of generated questions, specifically reasoning, aiming to generate multi-sentence questions (MSQs): questions that require reasoning over multiple sentences (Khashabi et al., 2018), which is more difficult to answer than single-sentence questions (SSQs). In Figure 1, we show the example of MSQ and SSQ. When one answers to the MSQ, one needs to look at the first and second sentences to figure out “Imelda Staunton” is “the English stage and screen actress born in 1956”, who was starred in “The Awakening”, a 2011 British horror film.” Then, one can answer the question by finding the director of “The Awakening.” Contrary to the MSQ which contains several reasoning steps, the SSQ in Figure 1 can be answered by finding the name, looking at only the first sentence. Due to the current success of neural sequence-tosequence approaches, the performances of QG models have been significantly improved on traditional metrics, such as BLEU or ROUGE (Du and Cardie, 2018; Dong et al., 2019). However, considering an application of QG to measure the reading comprehension ability of humans, semantic quality of generated questions is an important issue. One of the semantic-quality problems which existing models fall into is a semantic drift problem, i.e., the semantics of the model-generated question drifts away from the given context and answer. (Zhang and Bansal, 2019) Furthermore, in order to work on reasoning quality of QG, we do not have a parallel dataset that consists of both MSQ and SSQ for the same context and answer. Therefore, in this paper, we propose a transfer-learning QG approach and a method to create a parallel dataset to address the semantic quality, especially reasoning. Then, on the created parallel dataset, we fine-tune a transformer-based pre-trained language model and train a binary classifier context: (1)The Awakening is a 2011 British horror film directed and co-written by Nick Murphy, starring Rebecca Hall, Dominic West, Isaac HempsteadWright and Imelda Staunton. (2)Imelda Mary Philomena Bernadette Staunton, CBE (born 9 January 1956) is an English stage and screen actress. (3)After training at the Royal Academy of Dramatic Art, ... answer: Nick Murphy
- Keiichi Takamaru, Yasutomo Kimura, Hideyuki Shibuki, Hokuto Ototake, Yuzu Uchida, Kotaro Sakamoto, Madoka Ishioroshi, T. Mitamura, N. Kando. 2020. Extraction of the Argument Structure of Tokyo Metropolitan Assembly Minutes: Segmentation of Question-and-Answer Sets. Abstract: In this study, we construct a corpus of Japanese local assembly minutes. All speeches in an assembly were transcribed into a local assembly minutes based on the local autonomy law. Therefore, the local assembly minutes form an extremely large amount of text data. Our ultimate objectives were to summarize and present the arguments in the assemblies, and to use the minutes as primary information for arguments in local politics. To achieve this, we structured all statements in assembly minutes. We focused on the structure of the discussion, i.e., the extraction of question and answer pairs. We organized the shared task “QA Lab-PoliInfo” in NTCIR 14. We conducted a “segmentation task” to identify the scope of one question and answer in the minutes as a sub task of the shared task. For the segmentation task, 24 runs from five teams were submitted. Based on the obtained results, the best recall was 1.000, best precision was 0.940, and best F-measure was 0.895.
- Zhengzhong Liu, Guanxiong Ding, Avinash Bukkittu, Mansi Gupta, Pengzhi Gao, Atif Ahmed, Shikun Zhang, Xin Gao, Swapnil Singhavi, Linwei Li, Wei Wei, Zecong Hu, Haoran Shi, Xiaodan Liang, T. Mitamura, E. Xing, Zhiting Hu. 2020. A Data-Centric Framework for Composable NLP Workflows. Abstract: Empirical natural language processing (NLP) systems in application domains (e.g., healthcare, finance, education) involve interoperation among multiple components, ranging from data ingestion, human annotation, to text retrieval, analysis, generation, and visualization. We establish a unified open-source framework to support fast development of such sophisticated NLP workflows in a composable manner. The framework introduces a uniform data representation to encode heterogeneous results by a wide range of NLP tasks. It offers a large repository of processors for NLP tasks, visualization, and annotation, which can be easily assembled with full interoperability under the unified representation. The highly extensible framework allows plugging in custom processors from external off-the-shelf NLP and deep learning libraries. The whole framework is delivered through two modularized yet integratable open-source projects, namely Forte (for workflow infrastructure and NLP function processors) and Stave (for user interaction, visualization, and annotation).
- Steven Y. Feng, Varun Gangal, Dongyeop Kang, T. Mitamura, E. Hovy. 2020. GenAug: Data Augmentation for Finetuning Text Generators. Abstract: In this paper, we investigate data augmentation for text generation, which we call GenAug. Text generation and language modeling are important tasks within natural language processing, and are especially challenging for low-data regimes. We propose and evaluate various augmentation methods, including some that incorporate external knowledge, for finetuning GPT-2 on a subset of Yelp Reviews. We also examine the relationship between the amount of augmentation and the quality of the generated text. We utilize several metrics that evaluate important aspects of the generated text including its diversity and fluency. Our experiments demonstrate that insertion of character-level synthetic noise and keyword replacement with hypernyms are effective augmentation methods, and that the quality of generations improves to a peak at approximately three times the amount of original data.
- E. Hovy, J. Carbonell, Hans Chalupsky, A. Gershman, Alexander Hauptmann, Florian Metze, T. Mitamura, Zaid A. W. Sheikh, Ankit Dangi, Aditi Chaudhary, Xianyang Chen, Xiang Kong, Bernie Huang, Salvador Medina, H. Liu, Xuezhe Ma, Maria Ryskina, Ramon Sanabria, Varun Gangal. 2019. OPERA: Operations-oriented Probabilistic Extraction, Reasoning, and Analysis. Abstract: The OPERA system of CMU and USC/ISI performs end-to-end information extraction from multiple media and languages (English, Russian, Ukrainian), integrates the results, builds Knowledge Bases about the domain, and does hypothesis creation and reasoning to answer questions. 
- Kimihiro Hasegawa, Takaaki Matsumoto, T. Mitamura. 2019. Anaphora Reasoning Question Generation Using Entity Coreference. Abstract: We propose an approach for Anaphora Reasoning Question Generation from a plain text: generating a question which needs anaphora resolution to answer. This is one type of Multiple Sentence Reasoning Question, a paragraph-level question which needs more than one sentence in a context to answer. We apply our system to Wikipedia articles and, based on our evaluation, our system generates more Anaphora Reasoning Question compared to the current state-of-the-art neural question generation model which intends to generate a paragraph-level question by around 30%.
- Hemant Pugaliya, Karan Saxena, Shefali Garg, S. Shalini, Prashant Gupta, Eric Nyberg, T. Mitamura. 2019. Pentagon at MEDIQA 2019: Multi-task Learning for Filtering and Re-ranking Answers using Language Inference and Question Entailment. Abstract: Parallel deep learning architectures like fine-tuned BERT and MT-DNN, have quickly become the state of the art, bypassing previous deep and shallow learning methods by a large margin. More recently, pre-trained models from large related datasets have been able to perform well on many downstream tasks by just fine-tuning on domain-specific datasets (similar to transfer learning). However, using powerful models on non-trivial tasks, such as ranking and large document classification, still remains a challenge due to input size limitations of parallel architecture and extremely small datasets (insufficient for fine-tuning). In this work, we introduce an end-to-end system, trained in a multi-task setting, to filter and re-rank answers in the medical domain. We use task-specific pre-trained models as deep feature extractors. Our model achieves the highest Spearman’s Rho and Mean Reciprocal Rank of 0.338 and 0.9622 respectively, on the ACL-BioNLP workshop MediQA Question Answering shared-task.
- Yasutomo Kimura, Hideyuki Shibuki, Hokuto Ototake, Yuzu Uchida, Keiichi Takamaru, Kotaro Sakamoto, Madoka Ishioroshi, T. Mitamura, N. Kando. 2019. Influence of Classifiers and Encoders on Argument Classification in Japanese Assembly Minutes. Abstract: We performed a comparative study of the influence of seven different types of classifiers and four types of encoders on argument classification in Japanese assembly minutes using 45 sets of results from the Question Answering Lab for Political Information task at the NTCIR-14 workshop. The more accurate value obtained from a classification of argumentative relations between a speech sentence and a political topic was 0.942 using the support vector machines classifier and one-hot encoding, while the most accurate classification value obtained with the long short-term memory classifier and word embedding was estimated to be 0.934.
- Sai Abishek Bhaskar, Rashi Rungta, James Route, Eric Nyberg, T. Mitamura. 2019. Sieg at MEDIQA 2019: Multi-task Neural Ensemble for Biomedical Inference and Entailment. Abstract: This paper presents a multi-task learning approach to natural language inference (NLI) and question entailment (RQE) in the biomedical domain. Recognizing textual inference relations and question similarity can address the issue of answering new consumer health questions by mapping them to Frequently Asked Questions on reputed websites like the NIH. We show that leveraging information from parallel tasks across domains along with medical knowledge integration allows our model to learn better biomedical feature representations. Our final models for the NLI and RQE tasks achieve the 4th and 2nd rank on the shared-task leaderboard respectively.
- Aditi Chaudhary, Siddharth Dalmia, Junjie Hu, Xinjian Li, Austin Matthews, Aldrian Obaja Muis, Naoki Otani, Shruti Rijhwani, Zaid A. W. Sheikh, Nidhi Vyas, Xinyi Wang, Jiateng Xie, Ruochen Xu, Chunting Zhou, Peter J. Jansen, Yiming Yang, Lori S. Levin, Florian Metze, T. Mitamura, David R. Mortensen, Graham Neubig, E. Hovy, A. Black, J. Carbonell, Graham Horwood, Shabnam Tafreshi, Mona T. Diab, Efsun Sarioglu Kayi, N. Farra, K. McKeown. 2019. The ARIEL-CMU Systems for LoReHLT18. Abstract: This paper describes the ARIEL-CMU submissions to the Low Resource Human Language Technologies (LoReHLT) 2018 evaluations for the tasks Machine Translation (MT), Entity Discovery and Linking (EDL), and detection of Situation Frames in Text and Speech (SF Text and Speech).
- Vinayshekhar Bannihatti Kumar, A. Srinivasan, Aditi Chaudhary, James Route, T. Mitamura, Eric Nyberg. 2019. Dr.Quad at MEDIQA 2019: Towards Textual Inference and Question Entailment using contextualized representations. Abstract: This paper presents the submissions by TeamDr.Quad to the ACL-BioNLP 2019 shared task on Textual Inference and Question Entailment in the Medical Domain. Our system is based on the prior work Liu et al. (2019) which uses a multi-task objective function for textual entailment. In this work, we explore different strategies for generalizing state-of-the-art language understanding models to the specialized medical domain. Our results on the shared task demonstrate that incorporating domain knowledge through data augmentation is a powerful strategy for addressing challenges posed specialized domains such as medicine.
- Zhengzhong Liu, T. Mitamura, E. Hovy. 2018. Graph Based Decoding for Event Sequencing and Coreference Resolution. Abstract: Events in text documents are interrelated in complex ways. In this paper, we study two types of relation: Event Coreference and Event Sequencing. We show that the popular tree-like decoding structure for automated Event Coreference is not suitable for Event Sequencing. To this end, we propose a graph-based decoding algorithm that is applicable to both tasks. The new decoding algorithm supports flexible feature sets for both tasks. Empirically, our event coreference system has achieved state-of-the-art performance on the TAC-KBP 2015 event coreference task and our event sequencing system beats a strong temporal-based, oracle-informed baseline. We discuss the challenges of studying these event relations.
- J. Araki, T. Mitamura. 2018. Open-Domain Event Detection using Distant Supervision. Abstract: This paper introduces open-domain event detection, a new event detection paradigm to address issues of prior work on restricted domains and event annotation. The goal is to detect all kinds of events regardless of domains. Given the absence of training data, we propose a distant supervision method that is able to generate high-quality training data. Using a manually annotated event corpus as gold standard, our experiments show that despite no direct supervision, the model outperforms supervised models. This result indicates that the distant supervision enables robust event detection in various domains, while obviating the need for human annotation of events.
- Patrick Littell, R. Thomas McCoy, Na-Rae Han, Shruti Rijhwani, Zaid A. W. Sheikh, David R. Mortensen, T. Mitamura, Lori S. Levin. 2018. Parser combinators for Tigrinya and Oromo morphology. Abstract: We present rule-based morphological parsers in the Tigrinya and Oromo languages, based on a parser-combinator rather than finite-state paradigm. This paradigm allows rapid development and ease of integration with other systems, although at the cost of non-optimal theoretical efficiency. These parsers produce multiple output representations simultaneously, including lemmatization, morphological segmentation, and an English word-for-word gloss, and we evaluate these representations as input for entity detection and linking and humanitarian need detection.
- Zhengzhong Liu, T. Mitamura, E. Hovy. 2018. Graph-Based Decoding for Event Sequencing and Coreference Resolution. Abstract: Events in text documents are interrelated in complex ways. In this paper, we study two types of relation: Event Coreference and Event Sequencing. We show that the popular tree-like decoding structure for automated Event Coreference is not suitable for Event Sequencing. To this end, we propose a graph-based decoding algorithm that is applicable to both tasks. The new decoding algorithm supports flexible feature sets for both tasks. Empirically, our event coreference system has achieved state-of-the-art performance on the TAC-KBP 2015 event coreference task and our event sequencing system beats a strong temporal-based, oracle-informed baseline. We discuss the challenges of studying these event relations.
- Ashwin Naresh Kumar, Harini Kesavamoorthy, Madhura Das, Pramati Kalwad, Khyathi Raghavi Chandu, T. Mitamura, Eric Nyberg. 2018. Ontology-Based Retrieval & Neural Approaches for BioASQ Ideal Answer Generation. Abstract: The ever-increasing magnitude of biomedical information sources makes it difficult and time-consuming for a human researcher to find the most relevant documents and pinpointed answers for a specific question or topic when using only a traditional search engine. Biomedical Question Answering systems automatically identify the most relevant documents and pinpointed answers, given an information need expressed as a natural language question. Generating a non-redundant, human-readable summary that satisfies the information need of a given biomedical question is the focus of the Ideal Answer Generation task, part of the BioASQ challenge. This paper presents a system for ideal answer generation (using ontology-based retrieval and a neural learning-to-rank approach, combined with extractive and abstractive summarization techniques) which achieved the highest ROUGE score of 0.659 on the BioASQ 5b batch 2 test.
- Aldrian Obaja Muis, Naoki Otani, Nidhi Vyas, Ruochen Xu, Yiming Yang, T. Mitamura, E. Hovy. 2018. Low-resource Cross-lingual Event Type Detection via Distant Supervision with Minimal Effort. Abstract: The use of machine learning for NLP generally requires resources for training. Tasks performed in a low-resource language usually rely on labeled data in another, typically resource-rich, language. However, there might not be enough labeled data even in a resource-rich language such as English. In such cases, one approach is to use a hand-crafted approach that utilizes only a small bilingual dictionary with minimal manual verification to create distantly supervised data. Another is to explore typical machine learning techniques, for example adversarial training of bilingual word representations. We find that in event-type detection task—the task to classify [parts of] documents into a fixed set of labels—they give about the same performance. We explore ways in which the two methods can be complementary and also see how to best utilize a limited budget for manual annotation to maximize performance gain.
- Takaaki Matsumoto, Kimihiro Hasegawa, Yukari Yamakawa, T. Mitamura. 2018. Textual Entailment based Question Generation. Abstract: This paper proposes a novel question generation (QG) approach based on textual entailment. Many previous QG studies transform a single sentence into a question directly. They need hand-crafted templates or generate simple questions similar to the source texts. As a novel approach to QG, this research employs two-step QG: 1) generating new texts entailed by source documents, and 2) transforming the entailed sentences into questions. This process can generate questions that need the understanding of textual entailment to solve. Our system collected 1,367 English Wikipedia sentences as QG source, retrieved 647 entailed sentences from the web, and transformed them into questions. The evaluation result showed that our system successfully generated non-trivial questions based on textual entailment with 53% accuracy.
- Zhengzhong Liu, Chenyan Xiong, T. Mitamura, E. Hovy. 2018. Automatic Event Salience Identification. Abstract: Identifying the salience (i.e. importance) of discourse units is an important task in language understanding. While events play important roles in text documents, little research exists on analyzing their saliency status. This paper empirically studies Event Salience and proposes two salience detection models based on discourse relations. The first is a feature based salience model that incorporates cohesion among discourse units. The second is a neural model that captures more complex interactions between discourse units. In our new large-scale event salience corpus, both methods significantly outperform the strong frequency baseline, while our neural model further improves the feature based one by a large margin. Our analyses demonstrate that our neural model captures interesting connections between salience and discourse unit relations (e.g., scripts and frame structures).
- Vasu Sharma, Nitish Kulkarni, S. Pranavi, Gabriel Bayomi, Eric Nyberg, T. Mitamura. 2018. BioAMA: Towards an End to End BioMedical Question Answering System. Abstract: In this paper, we present a novel Biomedical Question Answering system, BioAMA: “Biomedical Ask Me Anything” on task 5b of the annual BioASQ challenge. In this work, we focus on a wide variety of question types including factoid, list based, summary and yes/no type questions that generate both exact and well-formed ‘ideal’ answers. For summary-type questions, we combine effective IR-based techniques for retrieval and diversification of relevant snippets for a question to create an end-to-end system which achieves a ROUGE-2 score of 0.72 and a ROUGE-SU4 score of 0.71 on ideal answer questions (7% improvement over the previous best model). Additionally, we propose a novel NLI-based framework to answer the yes/no questions. To train the NLI model, we also devise a transfer-learning technique by cross-domain projection of word embeddings. Finally, we present a two-stage approach to address the factoid and list type questions by first generating a candidate set using NER taggers and ranking them using both supervised or unsupervised techniques.
- J. Araki, Lamana Mulaffer, A. Pandian, Yukari Yamakawa, Kemal Oflazer, T. Mitamura. 2018. Interoperable Annotation of Events and Event Relations across Domains. Abstract: This paper presents methodologies for interoperable annotation of events and event relations across different domains, based on notions proposed in prior work. In addition to the interoperability, our annotation scheme supports a wide coverage of events and event relations. We employ the methodologies to annotate events and event relations on Simple Wikipedia articles in 10 different domains. Our analysis demonstrates that the methodologies can allow us to annotate events and event relations in a principled manner against the wide variety of domains. Despite our relatively wide and flexible annotation of events, we achieve high inter-annotator agreement on event annotation. As for event relations, we obtain reasonable inter-annotator agreement. We also provide an analysis of issues on annotation of events and event relations that could lead to annotators’ disagreement.
- E. Hovy, Taylor Berg-Kirkpatrick, J. Carbonell, Hans Chalupsky, A. Gershman, Alexander Hauptmann, Florian Metze, T. Mitamura, Aditi Chaudhary, Xianyang Chen, Bernie Huang, H. Liu, Xuezhe Ma, Shruti Palaskar, Dheeraj Rajagopal, Maria Ryskina, Ramon Sanabria. 2018. OPERA: Operations-oriented Probabilistic Extraction, Reasoning, and Analysis. Abstract: This paper describes CMU and USC/ISI’s OPERA system that performs endto-end information extraction from multiple media, integrates results across English, Russian, and Ukrainian, produces Knowledge Bases containing the extracted information, and performs hypothesis reasoning over the results.
- Takaaki Matsumoto, T. Mitamura. 2017. MTMT in QALab-3: World History Essay Question Answering System that Utilizes Textbooks and Open Knowledge Bases. Abstract: This paper introduces the system and its evaluation for answering world history essay questions by utilizing linked open data which assists machine translation. Since the target questions are the world history subject of the entrance examination of the University of Tokyo, most answers can be found in the Japanese world history textbooks. However, an equivalent content of high-quality English translation of the Japanese world history textbooks is not available. Therefore, we try to translate those textbooks utilizing linked open data, and using source language knowledge resource of which content is not equivalent with the target knowledge resource. The evaluation result indicates that the proposed system shows the best ROUGE-1 scores of all the end-to-end submissions [13]. The result of this paper concludes followings. 1) Simple neural translation of knowledge resource does not work for domain-specific cross-lingual question answering. 2) Linked open data is effective to find correct translation for difficult terms in machine translation process. 3) Adding source language open knowledge resource would help even if its content is not equivalent to the target knowledge resources.
- Kotaro Sakamoto, Hideyuki Shibuki, Madoka Ishioroshi, Akira Fujita, Yoshinobu Kano, T. Mitamura, Tatsunori Mori, N. Kando. 2017. Automatic Evaluation of World History Essay Using Chronological and Geographical Measures. Abstract: We propose a method for measuring chronological and geographical consistency of the world history essays in Japanese university entrance exams. e experimental result shows a weak positive correlation between the scores measured by the proposed method and the scores estimated by a human expert in world history.
- Hideyuki Shibuki, Kotaro Sakamoto, Madoka Ishioroshi, Yoshinobu Kano, T. Mitamura, Tatsunori Mori, N. Kando. 2017. Overview of the NTCIR-13 QA Lab-3 Task. Abstract: The NTCIR-13 QA Lab-3 task aims at the real-world complex Question Answering (QA) technologies using Japanese university entrance exams and their English translation on the subject of “World history”. QA Lab-3 has three end-toend tasks for multiple-choice, term and essay questions. The essay task has three subtasks of extraction, summarization and evaluation-method. There were 85 submissions from 13 teams in total. We describe the used data, formal run results, and comparison between human marks and automatic evaluation scores for essay questions. Categories and Subject Descriptions H.3.4 [INFORMATION STORAGE AND RETRIEVAL]: Systems and Software Performance evaluation (efficiency and effectiveness), Question-answering (fact retrieval) systems.
- T. Mitamura, Zhengzhong Liu, E. Hovy. 2017. Events Detection, Coreference and Sequencing: What's next? Overview of the TAC KBP 2017 Event Track. Abstract: After two successful years of Event Nugget evaluation in the TAC KBP workshop, the third Event Nugget evaluation track for Knowledge Base Population(KBP) still attracts a lot of attention from the ﬁeld. In addition to the traditional event nugget and coreference tasks, we introduce a new event sequencing task in English. The new task has brought more complex event relation reasoning to the current evaluations. In this paper we try to provide an overview on the task deﬁnition, data annotation, evaluation and trending research methods. We further discuss our efforts in creating the new event sequencing task and interesting research problems related to it.
- Key-Sun Choi, T. Mitamura, P. Vossen, Jin-Dong Kim, A. N. Ngomo. 2017. SIGIR 2017 Workshop on Open Knowledge Base and Question Answering (OKBQA2017). Abstract: Over the past years, several challenges and calls for research projects have pointed out the dire need for pushing natural language interfaces. In this context, the importance of Semantic Web data as a premier knowledge source is rapidly increasing. But we are still far from having accurate natural language interfaces that allow handling complex information needs in a user-centric and highly performant manner. The development of such interfaces requires collaboration of a range of different fields, including natural language processing, information extraction, knowledge base construction and population, reasoning, and question answering. With the goal to join forces in the collaborative development of natural language QA systems, the second OKBQA workshop is organized within the 40th SIGIR conference.
- Evangelia Spiliopoulou, E. Hovy, T. Mitamura. 2017. Event Detection Using Frame-Semantic Parser. Abstract: Recent methods for Event Detection focus on Deep Learning for automatic feature generation and feature ranking. However, most of those approaches fail to exploit rich semantic information, which results in relatively poor recall. This paper is a small & focused contribution, where we introduce an Event Detection and classification system, based on deep semantic information retrieved from a frame-semantic parser. Our experiments show that our system achieves higher recall than state-of-the-art systems. Further, we claim that enhancing our system with deep learning techniques like feature ranking can achieve even better results, as it can benefit from both approaches.
- Dheeru Dua, Bhawna Juneja, Sanchit Agarwal, Kotaro Sakamoto, Di Wang, T. Mitamura. 2016. CMUQA: Multiple-Choice Question Answering at NTCIR-12 QA Lab-2 Task. Abstract: The ﬁrst version of the UIMA-based modular automatic question answering (QA) system was developed for NTCIR-11 QA Lab task[5]. The system answers multiple-choice English questions for the Japanese university entrance examinations on the subject of world history. We made improvements in the current system by adding components focused towards Source Expansion and better Semantic Understanding of the question in terms of events and their time-lines
- Dheeraj Rajagopal, E. Hovy, T. Mitamura. 2016. Unsupervised Event Coreference for Abstract Words. Abstract: We introduce a novel approach for resolving coreference when the trigger word refers to multiple (sometimes non-contiguous) clauses. Our approach is completely unsupervised, and our experiments show that Neural Network models perform much better (about 20% more accurate) than traditional feature-rich baseline models. We also present a new dataset for Biomedical Language Processing which, with only about 25% of the original corpus vocabulary, still captures the essential distributional semantics of the corpus.
- Zhiyi Song, Ann Bies, S. Strassel, Joe Ellis, T. Mitamura, H. Dang, Yukari Yamakawa, Susan Holm. 2016. Event Nugget and Event Coreference Annotation. Abstract: In this paper, we describe the event nugget annotation created in support of the pilot Event Nugget Detection evaluation in 2014 and in support of the Event Nugget Detection and Coreference open evaluation in 2015, which was one of the Knowledge Base Population tracks within the NIST Text Analysis Conference. We present the data volume annotated for both training and evaluation data for the 2015 evaluation as well as changes to annotation in 2015 as compared to that of 2014. We also analyze the annotation for the 2015 evaluation as an example to show the annotation challenges and consistency, and identify the event types and subtypes that are most difficult for human annotators. Finally, we discuss annotation issues that we need to take into consideration in the future.
- J. Araki, Dheeraj Rajagopal, Sreecharan Sankaranarayanan, Susan Holm, Yukari Yamakawa, T. Mitamura. 2016. Generating Questions and Multiple-Choice Answers using Semantic Analysis of Texts. Abstract: We present a novel approach to automated question generation that improves upon prior work both from a technology perspective and from an assessment perspective. Our system is aimed at engaging language learners by generating multiple-choice questions which utilize specific inference steps over multiple sentences, namely coreference resolution and paraphrase detection. The system also generates correct answers and semantically-motivated phrase-level distractors as answer choices. Evaluation by human annotators indicates that our approach requires a larger number of inference steps, which necessitate deeper semantic understanding of texts than a traditional single-sentence approach.
- Ann Bies, Zhiyi Song, Jeremy Getman, Joe Ellis, Justin Mott, S. Strassel, Martha Palmer, T. Mitamura, Marjorie Freedman, Heng Ji, Timothy J. O'Gorman. 2016. A Comparison of Event Representations in DEFT. Abstract: This paper will discuss and compare event representations across a variety of types of event annotation: Rich Entities, Relations, and Events (Rich ERE), Light Entities, Relations, and Events (Light ERE), Event Nugget (EN), Event Argument Extraction (EAE), Richer Event Descriptions (RED), and Event-Event Relations (EER). Comparisons of event representations are presented, along with a comparison of data annotated according to each event representation. An event annotation ex-periment is also discussed, including annotation for all of these representations on the same set of sample data, with the purpose of being able to compare actual annotation across all of these approaches as directly as possible. We walk through a brief example to illustrate the various annotation approaches, and to show the intersections among the various annotated data sets.
- Hideyuki Shibuki, Kotaro Sakamoto, Madoka Ishioroshi, Akira Fujita, Yoshinobu Kano, T. Mitamura, Tatsunori Mori, N. Kando. 2016. Overview of the NTCIR-12 QA Lab-2 Task. Abstract: The NTCIR-12 QA Lab-2 task aims at the real-world complex Question Answering (QA) technologies using Japanese university entrance exams and their English translation on the subject of “World history”. The exam questions are roughly divided into multiple-choice and free-description styles, and have various question formats, which are essay, factoid, slot-filling, true-or-false and so on. We conducted three phases of formal runs, and collaborated on Phase-2 Japanese subtask with the Todai Robot Project. Twelve teams submitted 148 runs in total. We describe the used data, the hierarchy of question formats, formal run results, and comparison between human marks and automatic evaluation scores for essay questions. Categories and Subject Descriptions H.3.4 [INFORMATION STORAGE AND RETRIEVAL]: Systems and Software Performance evaluation (efficiency and effectiveness), Question-answering (fact retrieval) systems.
- Zhengzhong Liu, J. Araki, T. Mitamura, E. Hovy. 2016. CMU-LTI at KBP 2016 Event Nugget Track. Abstract: In this paper, we describe the CMU LTI team’s participation in TAC KBP 2016 event nugget track. This year, we extend our feature based event detection and coreference systems to process also Chinese documents. We also conduct experiments using Neural Network based models for English event nugget detection, which can enable us building models that can be easily transfer to different languages. Our feature based English Nugget Detection and Coreference systems both rank number 2 among all the participants. The Chinese counterpart ranks first in English Nugget Detection and second in English Coreference.
- Lu Jiang, Shoou-I Yu, Deyu Meng, T. Mitamura, Alexander Hauptmann. 2015. Bridging the Ultimate Semantic Gap: A Semantic Search Engine for Internet Videos. Abstract: Semantic search in video is a novel and challenging problem in information and multimedia retrieval. Existing solutions are mainly limited to text matching, in which the query words are matched against the textual metadata generated by users. This paper presents a state-of-the-art system for event search without any textual metadata or example videos. The system relies on substantial video content understanding and allows for semantic search over a large collection of videos. The novelty and practicality is demonstrated by the evaluation in NIST TRECVID 2014, where the proposed system achieves the best performance. We share our observations and lessons in building such a state-of-the-art system, which may be instrumental in guiding the design of the future system for semantic search in video.
- T. Mitamura, Zhengzhong Liu, E. Hovy. 2015. Overview of TAC KBP 2015 Event Nugget Track. Abstract: This paper describes three TAC KBP Event Nugget tasks: (1) Event Nugget Detection, (2) Event Nugget Detection and Coreference, and (3) Event Nuggest Coreference. The evaluation corpus, prepared by LDC, consists of 202 documents from newswire and discussion forum. Participating systems detect event nuggets, event types and subtypes, and Realis values. For task 1, 38 runs were submitted by 14 teams; for task 2, 19 runs were submitted by 8 teams; for task 3, 16 runs were submitted by 6 teams. After the scoring algorithms and their results, we provide some analyses of these tasks.
- Lu Jiang, Shoou-I Yu, Deyu Meng, Yi Yang, T. Mitamura, Alexander Hauptmann. 2015. Fast and Accurate Content-based Semantic Search in 100 M Internet Videos. Abstract: Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. MM ’15 Brisbane, Australia Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$15.00. and thus the solution of the original problem is
- Lu Jiang, Shoou-I Yu, Deyu Meng, Yi Yang, T. Mitamura, Alexander Hauptmann. 2015. Fast and Accurate Content-based Semantic Search in 100M Internet Videos. Abstract: Large-scale content-based semantic search in video is an interesting and fundamental problem in multimedia analysis and retrieval. Existing methods index a video by the raw concept detection score that is dense and inconsistent, and thus cannot scale to "big data" that are readily available on the Internet. This paper proposes a scalable solution. The key is a novel step called concept adjustment that represents a video by a few salient and consistent concepts that can be efficiently indexed by the modified inverted index. The proposed adjustment model relies on a concise optimization framework with interpretations. The proposed index leverages the text-based inverted index for video retrieval. Experimental results validate the efficacy and the efficiency of the proposed method. The results show that our method can scale up the semantic search while maintaining state-of-the-art search performance. Specifically, the proposed method (with reranking) achieves the best result on the challenging TRECVID Multimedia Event Detection (MED) zero-example task. It only takes 0.2 second on a single CPU core to search a collection of 100 million Internet videos.
- T. Mitamura, Yukari Yamakawa, Susan Holm, Zhiyi Song, Ann Bies, S. Kulick, S. Strassel. 2015. Event Nugget Annotation: Processes and Issues. Abstract: This paper describes the processes and issues of annotating event nuggets based on DEFT ERE Annotation Guidelines v1.3 and TAC KBP Event Detection Annotation Guidelines 1.7. Using Brat Rapid Annotation Tool (brat), newswire and discussion forum documents were annotated. One of the challenges arising from human annotation of documents is annotators’ disagreement about the way of tagging events. We propose using Event Nuggets to help meet the definitions of the specific type/subtypes which are part of this project. We present case studies of several examples of event annotation issues, including discontinuous multi-word events representing single events. Annotation statistics and consistency analysis is provided to characterize the interannotator agreement, considering single term events and multi-word events which are both continuous and discontinuous. Consistency analysis is conducted using a scorer to compare first pass annotated files against adjudicated files.
- J. Araki, T. Mitamura. 2015. Joint Event Trigger Identification and Event Coreference Resolution with Structured Perceptron. Abstract: Events and their coreference offer useful semantic and discourse resources. We show that the semantic and discourse aspects of events interact with each other. However, traditional approaches addressed event extraction and event coreference resolution either separately or sequentially, which limits their interactions. This paper proposes a document-level structured learning model that simultaneously identifies event triggers and resolves event coreference. We demonstrate that the joint model outperforms a pipelined model by 6.9 BLANC F1 and 1.8 CoNLL F1 points in event coreference resolution using a corpus in the biology domain.
- Zhengzhong Liu, J. Araki, Dheeru Dua, T. Mitamura, E. Hovy. 2015. CMU-LTI at KBP 2015 Event Track. Abstract: We describe CMU LTI’s participation in the KBP 2015 Event Track. We officially participated in Task 1: Event Nugget Detection track and Task 3: Event Coreference track. Our system rank high in both tracks. We found that our combined system is competitive but have room to improve. In addition, we have conducted follow up experiments by creating a simple piplined system, and We found it competitive comparing to the official submissions.
- Zhengzhong Liu, T. Mitamura, E. Hovy. 2015. Evaluation Algorithms for Event Nugget Detection : A Pilot Study. Abstract: Event Mention detection is the first step in textual event understanding. Proper evaluation is important for modern natural language processing tasks. In this paper, we present our evaluation algorithm and results during the Event Mention Evaluation pilot study. We analyze the problems of evaluating multiple event mention attributes and discontinuous event mention spans. In addition, we identify a few limitations in the evaluation algorithm used for the pilot task and propose some potential improvements.
- J. Araki, E. Hovy, T. Mitamura. 2014. Evaluation for Partial Event Coreference. Abstract: This paper proposes an evaluation scheme to measure the performance of a system that detects hierarchical event structure for event coreference resolution. We show that each system output is represented as a forest of unordered trees, and introduce the notion of conceptual event hierarchy to simplify the evaluation process. We enumerate the desiderata for a similarity metric to measure the system performance. We examine three metrics along with the desiderata, and show that metrics extended from MUC and BLANC are more adequate than a metric based on Simple Tree Matching.
- Lori S. Levin, T. Mitamura, B. MacWhinney, Davida Fromm, J. Carbonell, Wes Feely, R. Frederking, A. Gershman, Carlos Ramírez. 2014. Resources for the Detection of Conventionalized Metaphors in Four Languages. Abstract: This paper describes a suite of tools for extracting conventionalized metaphors in English, Spanish, Farsi, and Russian. The method depends on three significant resources for each language: a corpus of conventionalized metaphors, a table of conventionalized conceptual metaphors (CCM table), and a set of extraction rules. Conventionalized metaphors are things like “escape from poverty” and “burden of taxation”. For each metaphor, the CCM table contains the metaphorical source domain word (such as “escape”) the target domain word (such as “poverty”) and the grammatical construction in which they can be found. The extraction rules operate on the output of a dependency parser and identify the grammatical configurations (such as a verb with a prepositional phrase complement) that are likely to contain conventional metaphors. We present results on detection rates for conventional metaphors and analysis of the similarity and differences of source domains for conventional metaphors in the four languages.
- Zhengzhong Liu, J. Araki, E. Hovy, T. Mitamura. 2014. Supervised Within-Document Event Coreference using Information Propagation. Abstract: Event coreference is an important task for full text analysis. However, previous work uses a variety of approaches, sources and evaluation, making the literature confusing and the results incommensurate. We provide a description of the differences to facilitate future research. Second, we present a supervised method for event coreference resolution that uses a rich feature set and propagates information alternatively between events and their arguments, adapting appropriately for each type of argument.
- J. Araki, Zhengzhong Liu, E. Hovy, T. Mitamura. 2014. Detecting Subevent Structure for Event Coreference Resolution. Abstract: In the task of event coreference resolution, recent work has shown the need to perform not only full coreference but also partial coreference of events. We show that subevents can form a particular hierarchical event structure. This paper examines a novel two-stage approach to finding and improving subevent structures. First, we introduce a multiclass logistic regression model that can detect subevent relations in addition to full coreference. Second, we propose a method to improve subevent structure based on subevent clusters detected by the model. Using a corpus in the Intelligence Community domain, we show that the method achieves over 3.2 BLANC F1 gain in detecting subevent relations against the logistic regression model.
- Di Wang, Leonid Boytsov, J. Araki, Alkesh Patel, Jeffrey G. Gee, Zhengzhong Liu, Eric Nyberg, T. Mitamura. 2014. CMU Multiple-choice Question Answering System at NTCIR-11 QA-Lab. Abstract: We describe CMU’s UIMA-based modular automatic question answering (QA) system. This system answers multiplechoice English questions for the world history entrance exam. Questions are preceded by short descriptions providing a historical context. Given the context and question-specic instructions, we generate veriable assertions for each answer choice. These assertions are evaluated using several evidencing modules, which assign a plausibility score to each assertion. These scores are then aggregated to produce the most plausible answer choice. In the NTCIR-11 QALab evaluations, our system achieved 51.6% accuracy on the training set, 47.2% on Phase 1 testing set, and 34.1% on Phase 2 testing set.
- Shoou-I Yu, Lu Jiang, Zhongwen Xu, Zhenzhong Lan, Shicheng Xu, Xiaojun Chang, Xuanchong Li, Zexi Mao, Chuang Gan, Yajie Miao, Xingzhong Du, Yang Cai, Lara J. Martin, Nikolas Wolfe, Anurag Kumar, Huan Li, Ming Lin, Zhigang Ma, Yi Yang, Deyu Meng, S. Shan, P. D. Sahin, Susanne Burger, Florian Metze, Rita Singh, B. Raj, T. Mitamura, R. Stern, Alexander Hauptmann. 2014. Informedia@TrecVID 2014: MED and MER. Abstract: We report on our system used in the TRECVID 2014 Multimedia Event Detection (MED) and Multimedia Event Recounting (MER) tasks. On the MED task, the CMU team achieved leading performance in the Semantic Query (SQ), 000Ex, 010Ex and 100Ex settings. Furthermore, SQ and 000Ex runs are significantly better than the submissions from the other teams. We attribute the good performance to 4 main components: 1) our large-scale semantic concept detectors trained on video shots for SQ/000Ex systems, 2) better features such as improved trajectories and deep learning features for 010Ex/100Ex systems, 3) a novel Multistage Hybrid Late Fusion method for 010Ex/100Ex systems and 4) our developed reranking methods for Pseudo Relevance Feedback for 000Ex/010Ex systems. On the MER task, our system utilizes a subset of features and detection results from the MED system from which the recounting is then generated. Recounting evidence is presented by selecting the most likely concepts detected in the salient shots of a video. Salient shots are detected by searching for shots which have high response when predicted by the video level event detector.
- Lu Jiang, Deyu Meng, T. Mitamura, Alexander Hauptmann. 2014. Easy Samples First: Self-paced Reranking for Zero-Example Multimedia Search. Abstract: Reranking has been a focal technique in multimedia retrieval due to its efficacy in improving initial retrieval results. Current reranking methods, however, mainly rely on the heuristic weighting. In this paper, we propose a novel reranking approach called Self-Paced Reranking (SPaR) for multimodal data. As its name suggests, SPaR utilizes samples from easy to more complex ones in a self-paced fashion. SPaR is special in that it has a concise mathematical objective to optimize and useful properties that can be theoretically verified. It on one hand offers a unified framework providing theoretical justifications for current reranking methods, and on the other hand generates a spectrum of new reranking schemes. This paper also advances the state-of-the-art self-paced learning research which potentially benefits applications in other fields. Experimental results validate the efficacy and the efficiency of the proposed method on both image and video search tasks. Notably, SPaR achieves by far the best result on the challenging TRECVID multimedia event search task.
- Hideyuki Shibuki, Kotaro Sakamoto, Yoshinobu Kano, T. Mitamura, Madoka Ishioroshi, Kelly Y. Itakura, Di Wang, Tatsunori Mori, N. Kando. 2014. Overview of the NTCIR-11 QA-Lab Task. Abstract: This paper describes an overview of the first QA Lab (Question Answering Lab for Entrance Exam) task at NTCIR 11. The goal of the QA lab is to provide a module-based platform for advanced question answering systems and comparative evaluation for solving real-world university entrance exam questions. In this task, “world history” questions are selected from The National Center Test for University Admissions and from the secondary exams at 5 universities in Japan. This paper also describes the used data, baseline systems, formal run results, the characteristic aspects of the participating groups’ systems and their contribution.
- Suguru Matsuyoshi, Yusuke Miyao, Tomohide Shibata, Chuan-Jie Lin, Cheng-Wei Shih, Yotaro Watanabe, T. Mitamura. 2014. Overview of the NTCIR-11 Recognizing Inference in TExt and Validation (RITE-VAL) Task. Abstract: System Valida5on Subtask Language Task Description Acronym Test Data Size Submissions Top Macro-F1 Top Accuracy Top Team (Run Num.) Fact Validation Simplified Chinese Multi-Classification CS-FV 613 12 38.93 44.05 III&CYUT (05) Traditional Chinese Multi-Classification CT-FV 613 15 39.51 44.70 III&CYUT (02) Japanese Binary Classification JA-FV 514 30 61.93 63.23 NUL (03) Passage Search -514 3 ---English Binary Classification EN-FV 188 9 53.17 55.85 BnO (01) System Validation Simplified Chinese Binary Classification CS-SVBC 1,200 23 61.51 62.33 BUPTTeam (05) Multi-Classification CS-SVMC 1,200 18 44.39 51.83 WUST (01) Traditional Chinese Binary Classification CT-SVBC 1,200 17 56.24 56.25 III&CYUT (04) Multi-Classification CT-SVMC 1,200 17 40.54 43.33 III&CYUT (05) Japanese Binary Classification JA-SV 1,379 26 69.59 77.81 NUL (04) Total 170 Active participating team: 23 teams • 11 from Japan • 7 from Taiwan • 4 from China • 1 from Norway • 1 from Vietnam (One team consists of people from Japan and Vietnam.)
- Lu Jiang, T. Mitamura, Shoou-I Yu, Alexander Hauptmann. 2014. Zero-Example Event Search using MultiModal Pseudo Relevance Feedback. Abstract: We propose a novel method MultiModal Pseudo Relevance Feedback (MMPRF) for event search in video, which requires no search examples from the user. Pseudo Relevance Feedback has shown great potential in retrieval tasks, but previous works are limited to unimodal tasks with only a single ranked list. To tackle the event search task which is inherently multimodal, our proposed MMPRF takes advantage of multiple modalities and multiple ranked lists to enhance event search performance in a principled way. The approach is unique in that it leverages not only semantic features, but also non-semantic low-level features for event search in the absence of training data. Evaluated on the TRECVID MEDTest dataset, the approach improves the baseline by up to 158% in terms of the mean average precision. It also significantly contributes to CMU Team's final submission in TRECVID-13 Multimedia Event Detection.
- Ehsan Younessian, Michael Quinn, T. Mitamura, Alexander Hauptmann. 2013. Multimedia event detection using visual concept signatures. Abstract: Multimedia Event Detection (MED) is a multimedia retrieval task with the goal of finding videos of a particular event in a large-scale Internet video archive, given example videos and text descriptions. In this paper, we mainly focus on an 'ad-hoc' scenario in MED where we do not use any example video. We aim to retrieve test videos based on their visual semantics using a Visual Concept Signature (VCS) generated for each event only derived from the event description provided as the query. Visual semantics are described using the Semantic INdexing (SIN) feature which represents the likelihood of predefined visual concepts in a video. To generate a VCS for an event, we project the given event description to a visual concept list using the proposed textual semantic similarity. Exploring SIN feature properties, we harmonize the generated visual concept signature and the SIN feature to improve retrieval performance. We conduct different experiments to assess the quality of generated visual concept signatures with respect to human expectation, and in the context of the MED task to retrieve the SIN feature of videos in the test dataset when we have no or only very few training videos.
- Yotaro Watanabe, Yusuke Miyao, Junta Mizuno, Tomohide Shibata, H. Kanayama, Cheng-Wei Lee, Chuan-Jie Lin, Shuming Shi, T. Mitamura, N. Kando, Hideki Shima, Koichi Takeda. 2013. Overview of the Recognizing Inference in Text (RITE-2) at NTCIR-10. Abstract: This paper describes an overview of RITE-2 (Recognizing Inference in TExt) task in NTCIR-10. We evaluated systems that automatically recognize semantic relations between sentences such as paraphrase, entailment, contradiction in Japanese, Simplified Chinese and Traditional Chinese. The tasks in RITE-2 are Binary Classification of entailment (BC Subtask), Multi-Class Classification including paraphrase and contradiction (MC Subtask), Entrance Exam Subtasks (Exam BC and Exam Search), Unit Test, and RITE4QA Subtask. We had 28 active participants, and received 215 formal runs (110 Japanese runs, 53 Traditional Chinese runs, 52 Simplified Chinese runs). This paper also describes how the datasets for RITE-2 had been developed, how the systems were evaluated, and reports RITE-2 formal run results.
- E. Hovy, T. Mitamura, M. Verdejo, J. Araki, A. Philpot. 2013. Events are Not Simple: Identity, Non-Identity, and Quasi-Identity. Abstract: Despite considerable theoretical and computational work on coreference, deciding when two entities or events are identical is very difficult. In a project to build corpora containing coreference links between events, we have identified three levels of event identity (full, partial, and none). Event coreference annotation on two corpora was performed to validate the findings.
- Zhenzhong Lan, Lu Jiang, Shoou-I Yu, Chenqiang Gao, Shourabh Rawat, Yang Cai, Shicheng Xu, Haoquan Shen, Xuanchong Li, Yipei Wang, Waito Sze, Yan Yan, Zhigang Ma, Nicolas Ballas, Deyu Meng, Wei Tong, Yi Yang, Susanne Burger, Florian Metze, Rita Singh, B. Raj, R. Stern, T. Mitamura, Eric Nyberg, Alexander Hauptmann, A. Hauptmann. 2013. Informedia@TRECVID 2013. Abstract: In the first part of this three-part report we describe our system and novel approaches used in the TRECVID 2013 Multimedia Event Detection (MED) and Multimedia Event Recounting (MER) tasks. A separate section of the report (SIN) details methods and results for the Semantic Indexing task. The final section (SED) describes our approaches and results on the Surveillance Event Detection task.
- Alkesh Patel, Zi Yang, Eric Nyberg, T. Mitamura. 2013. Building Optimal Question Answering System Automatically using Configuration Space Exploration (CSE) for QA4MRE 2013 Tasks. Abstract: Different software systems for automatic question answering have been developed in recent years. Some systems perform well on specific domains, but may not be appropriate for other domains. As the complexity and scaling of such information systems become ever greater, it is much more challenging to effectively and efficiently determine which toolkits, algorithms, knowledge bases or other resources should be integrated into a system so that one can achieve a desired or optimal level of performance on a given task. In this working notepaper, we present a generic framework that can be used for any machinereading task and automatically find the best configuration of algorithmic components as well as values of their corresponding parameters. Although we have designed the framework for all QA4MRE-2013 tasks (i.e. Main task, Biomedical about Alzheimer’s and Entrance Exam), our analysis will mostly focus on Biomedical about Alzheimer’s task. We introduce the Configuration Space Exploration (CSE) framework, an extension to the Unstructured Information Management Architecture (UIMA) which provides a general distributed solution for building and exploring possible configurations for any intelligent information system. For the Biomedial about Alzheimer’s task, CSE was used to generate more than 1000 different configurations from existing components; we selected the 3 best runs for submission. We achieved an average c@1 of 0.27; our highest score was 0.60 for reading-test-1, and our lowest was 0.0 for reading-test3. We further enhanced the system by introducing point-wise mutual information (PMI) scoring for answer ranking, which produced an average c@1 of 0.4025, with a highest score of 0.77 for reading test-1 and a lowest score of 0.2 for reading test-2.
- Mahmoud Azab, Ahmed S. Salama, Kemal Oflazer, Hideki Shima, J. Araki, T. Mitamura. 2013. An NLP-based Reading Tool for Aiding Non-native English Readers. Abstract: This paper describes a text-reading tool that makes extensive use of widelyavailable NLP tools and resources to aid non-native English speakers overcome language related hindrances while reading a text. It is a web-based tool, that can be accessed from browsers running on PCs or tablets, and provides the reader with an intelligent e-book functionality.
- Mahmoud Azab, Ahmed S. Salama, Kemal Oflazer, Hideki Shima, J. Araki, T. Mitamura. 2013. An English Reading Tool as a NLP Showcase. Abstract: We introduce -SmartReaderan English reading tool for non-native English readers to overcome language related hindrances while reading a text. It makes extensive use of widely-available NLP tools and resources. SmartReader is a web-based application that can be accessed from standard browsers running on PCs or tablets. A user can choose a text document from the system’s library they want to read or can upload a new document of their own and the system will display an interactive version of such text, that provides the reader with an intelligent e-book functionality.
- T. Mitamura, N. Kando, Koichi Takeda. 2012. Introduction to the Special Issue on RITE. Abstract: INTRODUCTION The NTCIR1 Workshop is a series of evaluation workshops designed to enhance research in information access technologies, such as information retrieval, question answering, summarization, and text mining. The main goal of the NTCIR project is to provide infrastructure for large-scale evaluations of information access technologies, and then to speed up the research and the technology transfer. The major components of the infrastructure are reusable test collections, evaluation metrics, and a forum for researchers. As the fundamental text processing in information access technologies, such as indexing, which includes language-dependent procedures, the NTCIR workshop has placed emphasis on, but has not limited it to, East Asian languages, such as Japanese, Chinese, and Korean, (and English documents published in Asia), and its series of workshops has attracted international participation. An NTCIR workshop is held once every year and a half. In NTCIR, which is different from ordinary scientific conferences, the organizers and participating research groups have worked together in the process before the final meeting. The task organizers propose the tasks, the data sets used for experiments, and the evaluation metrics and methods and each of the participating research groups can participate for their own purposes and targets, and conduct research and experiments using the same data set provided by NTCIR. The experimental results are collected, and analyses and crosssystem comparisons are reported on at the final meeting. After the meeting, most of the test collections constructed through the NTCIR workshop are made available to non-participating research groups for research purposes. NTCIR-9, the ninth verion of the NTCIR, started its call for task participation from September 2010 and concluded the activities by the workshop held on 6th–9th December 2011, in Tokyo, Japan [Sakai and Joho 2011].
- Yusuke Miyao, Hideki Shima, H. Kanayama, T. Mitamura. 2012. Evaluating Textual Entailment Recognition for University Entrance Examinations. Abstract: The present article addresses an attempt to apply questions in university entrance examinations to the evaluation of textual entailment recognition. Questions in several fields, such as history and politics, primarily test the examinee’s knowledge in the form of choosing true statements from multiple choices. Answering such questions can be regarded as equivalent to finding evidential texts from a textbase such as textbooks and Wikipedia. Therefore, this task can be recast as recognizing textual entailment between a description in a textbase and a statement given in a question. We focused on the National Center Test for University Admission in Japan and converted questions into the evaluation data for textual entailment recognition by using Wikipedia as a textbase. Consequently, it is revealed that nearly half of the questions can be mapped into textual entailment recognition; 941 text pairs were created from 404 questions from six subjects. This data set is provided for a subtask of NTCIR RITE (Recognizing Inference in Text), and 16 systems from six teams used the data set for evaluation. The evaluation results revealed that the best system achieved a correct answer ratio of 56%, which is significantly better than a random choice baseline.
- Ehsan Younessian, T. Mitamura, Alexander Hauptmann. 2012. Multimodal knowledge-based analysis in multimedia event detection. Abstract: Multimedia Event Detection (MED) is a multimedia retrieval task with the goal of finding videos of a particular event in a large-scale Internet video archive, given example videos and text descriptions. We focus on the multimodal knowledge-based analysis in MED where we utilize meaningful and semantic features such as Automatic Speech Recognition (ASR) transcripts, acoustic concept indexing (i.e. 42 acoustic concepts) and visual semantic indexing (i.e. 346 visual concepts) to characterize videos in archive. We study two scenarios where we either do or do not use the provided example videos. In the former, we propose a novel Adaptive Semantic Similarity (ASS) to measure textual similarity between ASR transcripts of videos. We also incorporate acoustic concept indexing and classification to retrieve test videos, specially with too few spoken words. In the latter 'ad-hoc' scenario where we do not have any example video, we use only the event kit description to retrieve test videos ASR transcripts and visual semantics. We also propose an event-specific fusion scheme to combine textual and visual retrieval outputs. Our results show the effectiveness of the proposed ASS and acoustic concept indexing methods and their complimentary role. We also conduct a set of experiments to assess the proposed framework for the 'ad-hoc' scenario.
- Hideki Shima, T. Mitamura. 2012. Diversifiable Bootstrapping for Acquiring High-Coverage Paraphrase Resource. Abstract: Recognizing similar or close meaning on different surface form is a common challenge in various Natural Language Processing and Information Access applications. However, we identified multiple limitations in existing resources that can be used for solving the vocabulary mismatch problem. To this end, we will propose the Diversifiable Bootstrapping algorithm that can learn paraphrase patterns with a high lexical coverage. The algorithm works in a lightly-supervised iterative fashion, where instance and pattern acquisition are interleaved, each using information provided by the other. By tweaking a parameter in the algorithm, resulting patterns can be diversifiable with a specific degree one can control.
- Sixie Yu, Zhongwen Xu, Duo Ding, Waito Sze, F. Vicente, Zhenzhong Lan, Yang Cai, Shourabh Rawat, Peter F. Schulam, N. Markandaiah, S. Bahmani, A. Juárez, Wei Tong, Yi Yang, Susanne Burger, Florian Metze, Rita Singh, B. Raj, R. Stern, T. Mitamura, Eric Nyberg, A. Hauptmann. 2012. Informedia @TRECVID 2012. Abstract: We report on our system used in the TRECVID 2012 Multimedia Event Detection (MED) and Multimedia Event Recounting (MER) tasks. For MED, it consists of three main steps: extracting features, training detectors and fusion. In the feature extraction part, we extract many low-level, high-level, and text features. Those features are then represented in three different ways which are spatial bag-of words with standard tiling, spatial bag-of-words with feature and event specific tiling and the Gaussian Mixture Model Super Vector. In the detector training and fusion, two classifiers and three fusion methods are employed. The results from both the official sources and our internal evaluations show good performance of our system. Our MER system utilizes a subset of features and detection results from the MED system from which the recounting is generated. 1. MED System 1.1 Features In order to encompass all aspects of a video, we extracted a wide variety of low-level and highlevel features. Table 1 summarizes the features used in our system. Among those features, most of them are widely used features in the community, for example, SIFT, STIP and MFCC. We extracted those features using standard code available from the authors with default parameters. Table 1: Features used for MED’12 system Visual Features Audio Features Low-level features 1. SIFT (Sande, Gevers, & Snoek, 2010) 2. Color SIFT (CSIFT) (Sande, Gevers, & Snoek, 2010) 3. Motion SIFT (MoSIFT) (Chen & Hauptmann, 2009) 4. Transformed Color Histogram (TCH) (Sande, Gevers, & Snoek, 2010) 5. STIP (Wang, Ullah, Klaser, Laptev, & Schmid, 2009) 6. Dense Trajectory (Wang, Klaser, Schmid, & Liu, 2011) 1. MFCC 2. Acoustic Unit Descriptors (AUDs) (Chaudhuri, Harvilla, & Raj, 2011) High-level features 1. Semantic Indexing Concepts (SIN) (Over, et al., 2012) 2. Object Bank (Li, Su, Xing, & Fei-Fei, 2010) 1. Acoustic Scene Analysis Text Features 1. Optical Character Recognition 1. Automatic Speech Recognition Besides those common features, we have two home-grown features which are Motion SIFT (MoSIFT) and Acoustic Unit Descriptors (AUDs). We will introduce these two features in the following subsections. 1.1 .1 Motion SIFT (MoSIFT) Feature The goal of developing the MoSIFT feature is to combine the features from the spatial domain and the temporal domain. Local spatio-temporal features around interest points provide compact and descriptive representations for video analysis and motion recognition. Current approaches tend to extend spatial descriptions by adding a temporal component to the appearance descriptor, which only implicitly captures motion information. MoSIFT detects interest points and encodes not only their local appearance but also explicitly models local motion. The idea is to detect distinctive local features through local appearance and motion. Figure 1 demonstrates the MoSIFT algorithm. Figure 1: System flow chart of the MoSIFT algorithm. The algorithm takes a pair of video frames to find spatio-temporal interest points at multiple scales. Two major computations are applied: SIFT point detection and optical flow computation according to the scale of the SIFT points. For the descriptor, MoSIFT adapts the idea of grid aggregation in SIFT to describe motions. Optical flow detects the magnitude and direction of a movement. Thus, optical flow has the same properties as appearance gradients. The same aggregation can be applied to optical flow in the neighborhood of interest points to increase robustness to occlusion and deformation. The two aggregated histograms (appearance and optical flow) are combined into the MoSIFT descriptor, which now has 256 dimensions. 1.1 .2 Acoustic Unit Descriptors (AUDs) We have developed an unsupervised lexicon learning algorithm that automatically learns units of sound. Each unit is such that it spans a set of audio frames, thereby taking local acoustic context into account. Using a maximum-likelihood estimation process, we can learn a set of such acoustic units unsupervised from audio data. Each of these units can be thought of as low-level fundamental units of sound, and each audio frame is generated by these units. We refer to these units as Acoustic Unit Descriptors (AUDs) and we expect that the distribution of these units will carry information about the semantic content of the audio stream. Each AUD is represented by a 5-state Hidden Markov Model (HMM) with a 4-gaussian mixture output density function. Ideally, with a perfect learning process, we would like to learn semantically interpretable lowerlevel units, such as a clap, a thud sound, a bang, etc. Naturally, it is hard to enforce semantic interpretability on the audio learning process at that level of detail. Further, because the space of all possible sounds is so large, many different sounds will be mapped into single sounds at learning time, since we can only learn a finite set of units. 1.2 Feature Representat ions In the previous section, we briefly describe the features we used in the system. In this section, we will describe the representations we used for the raw features extracted in Section 1. Three representations were used in our system. They were K-means based spatial bag-ofwords model with standard tiling (Lazebnik, Schmid, & Ponce, 2006), K-means based spatial bag-of-words with feature and event specific tiling (Viitaniemil & Laaksonen, 2009) and Gaussian Mixture Model Super Vector (Campbell & Sturim, 2006). Since the K-means based spatial bag-of-words model with standard tiling and Gaussian Mixture Model Super Vector are standard technology, we will focus on the K-means based spatial bag-of-words model with feature and event specific tiling. For simplicity, we will refer to it as tiling. Spatial bag-of-words model is a widely used representation of the low-level image/video features. The central idea of the spatial bag-of-words model is to divide the image into some small tiles and compute bag-of-words for each tile. Figure 2 shows a couple of tiling examples. Figure 2: Examples of tiling In general, the standard spatial bag-of-words tiling uses the 1x1, 2x2 and 4x4 tiling. However the use of those tilings is ad-hoc and some preliminary works have shown that other tilings might produce better performance (Viitaniemil & Laaksonen, 2009). In our system, we systematically tested 80 different tilings to select the best one for each feature and each event. Table 2 shows the performance of feature specific tiling v.s. the standard tiling. The scores are computed from our internal experiments and are the average over 20 MED12 pre-specified events. The PMiss @ TER=12.5 metric is an official evaluation metric specified in the MED 2012 Evaluation Plan. A smaller PMiss score signifies better performance. From the table, we can see clearly that for all of the five features, the feature specific tiling performs consistently at least 1% better than the standard tiling. Table 2: The performance of feature specific tiling and standard tiling Feature SIFT CSIFT TCH STIP MOSIFT Feature Specific Tiling 0.4209 0.4496 0.4914 0.5178 0.4330 Standard Tiling 0.4325 0.4618 0.5052 0.5234 0.4456 Figure 3 shows an example of the performance of event specific tiling v.s. standard tiling on Event 25 (marriage proposal), which is a difficult event identified in our experiments. It can be seen clearly that the event specific tiling can noticeably improve the performance over standard tiling. Figure 3: The comparison of event specific tiling and standard tiling on Event 25 1.3 Training and Fusion We used the standard MED’12 training dataset for our internal evaluation and the training of the models for our submission. For our internal evaluation, the MED’12 training dataset was further divided into the training set and testing set by randomly selecting half of the positive examples into the training set and the other half into the testing set. The negative examples consisted of only NULL videos which do not have label information. The two classifiers used in the system were kernel SVM and kernelized rigid regression. For simplicity, we will refer to it as kernel regression. For the K-means based feature representations, we used the Chi-squared kernel. For the GMM based representation RBF kernel was used. The parameters of the model were tuned by 5-fold cross validation and the PMiss @ TER = 12.5 metric was used as the evaluation metric. For combining features from multiple modalities and the outputs of different classifiers, we used fusion and ensemble methods. More specifically, for the same classifier, we used three fusion methods to fuse different features. The fusion methods were early fusion, late fusion and double fusion (Lan, Bao, Yu, Liu, & Hauptmann, 2012). In early fusion, the kernel matrices from different features were normalized first and then combined together. In late fusion, the prediction scores from the models trained using different features were combined. In our system, we also used a fusion method called double fusion, which combines early fusion and late fusion together. Finally, the results from different classifiers were ensembled together. Figure 4 shows the diagram of our system. Figure 4: The diagram of the system 0.55 0.57 0.59 0.61 0.63 0.65 0.67 0.69 0.71 0.73 0.75 CSIFT SIFT MOSIFT STIP TCH PM is s@ 12 .5 E025 Marriage_proposal baseline 1.4 Submiss ion In the following section we describe in detail the runs we submitted to NIST. Table 3 shows the official performance of each submission. 1.4 .1 Pre-Specified Submission 1.4.1.1 Submission 1: CMU_MED12_MED12TEST_PS_MEDFull_EKFull_AutoEAG_p_ensembleKRSVM_1 In this submission, using the features described in the previous section, we did the following to generate this run: 1. For each feature, train a SVM classifier and a kernel regression model. 2. Late fusion of all the results from SVM classifiers and kernel regression respectively. 3. Early fusion of all features except ASR. 4. Train a SVM classifier and a kernel
- M. Tomita, Marion Kee, Hiroaki Saito, T. Mitamura, H. Tomabechi. 2011. TOWARDS A SPEECH-TO-SPEECH TRANSLATION SYSTEM ( 1 ). Abstract: We describe our Universal Parser Architecture and its use in a speech translation system, based on the Machine Translation system under development at the Center for Machine Translation at Carnegie Mellon. To "understand" natural language, a system must have syntactic knowledge of the language and semantic knowledge of the domain. The Universal Parser Architecture allows grammar writers to develop these kinds of knowledge separately in a declarative manner, and the compiler/interpreter integrates these two knowledge bases dynamically in order to parse input sentences. We recently integrated our system with a speech recognition system to accept spoken sentences (rather than typed sentences) by extending our runtime parser component to handle "noisy" phoneme sequences (of spoken utterances) that possibly include recognition errors. The nature of this modification is explained and examples are presented. We find our architecture very suitable for speech translation, as it combines the use of domain semantic knowledge with a highly efficient runtime parsing algorithm, thus accommodating the increased search space necessary for parsing speech input.
- Kemal Oflazer, T. Mitamura, Tomas By, Hideki Shima, E. Riebling. 2011. A Natural Language Processing-Based Active and Interactive Platform for Accessing English Language Content and Advanced Language Learning. Abstract: Abstract SmartReader is a general-purpose “reading appliance” being implemented at Carnegie Mellon University (Qatar and Pittsburgh) - building upon an earlier prototype version. It is an artificial intelligence system that employs advanced language processing technologies and can interact with the reader and respond to queries about the content, words and sentences in a text. We expect it to be used by students in Qatar and elsewhere to help improve their comprehension of English text. SmartReader is motivated by the observation that text is still the predominant medium for learning especially at the advanced level and that text, being ``bland’’, is hardly a conducive and motivating medium for learning, especially when one does not have access to tools that enable one get over language roadblocks, ranging from unknown words to unrecognized and forgotten names, to hard-to-understand sentences. SmartReader strives to make reading (English) textual material, an “active” and an “interactive” process with the user interacting with the text using anytime-anywhere contextually-guided query mechanism based-on contextual user intent recognition. With SmartReader, a user can -inquire about the contextually correct meaning or synonyms of a word or idiomatic and multi-word constructions, -select a person's name, and then get an immediate ``flashback’’ to the first (or the last) time the person was encountered in text to remind herself the details of the person, -extract a summary of a section to remember important aspects of the content at the point she left off, and continue reading with a significantly refreshed context, -select a sentence that she may not be able to understand fully and ask SmartReader to break it down, simplify or paraphrase to comprehend it better. -test her comprehension of the text in a page or a chapter, by asking SmartReader to dynamically generate quizzes and answering them. -ask questions about the content of the text and get answers in addition to many other functions. SmartReader is being implemented as a multi-platform (tablet/PC) client-server system using HTML5 technology, with Unstructured Information Management Architecture -UIMA technology (used recently in IBM's Watson Q/A system in the Jeopardy Challenge) as the underlying language processing framework.
- K. Koedinger, T. Mitamura, Ruth Wylie. 2011. Examining the Generality of Self-Explanation. Abstract: Prompting students to self-explain during problem solving has proven to be an effective instructional strategy across many domains. However, despite being called "domain general", very little work has been done in areas outside of math and science. In this dissertation, I investigate whether the self-explanation effect holds when applied in an inherently different type of domain, second language grammar learning. 
Through a series of in vivo experiments, I tested the effects of using prompted self-explanation to help adult English language learners acquire the English article system (e.g., teaching students the difference between "I saw a dog" versus "I was the dog"). In the pilot study, I explored different modalities of self-explanation (free-form versus menu-based), and in Study 1, 1 looked at transfer effects between practice and self-explanation. In the studies that followed, I added an additional deep processing manipulation (Study 2: analogical comparisons) and a strategy designed to increase the rate of practice and information processing (Study 3: worked example study). Finally, in Study 4, I built and evaluated an adaptive self-explanation tutor that prompted students to self-explain only when estimates of prior knowledge were low. Across all studies, results show that self-explanation is an effective instructional strategy in that it leads to significant pre to posttest learning gains, but it is inefficient compared to tutored practice. In addition to learning gains, I compared learning process data and found that both self-explanation and practice lead to similar patterns of learning and there was no evidence in support of individual differences. 
This work makes contributions to learning sciences, second language acquisition (SLA), and tutoring system communities. It contributes to learning sciences by demonstrating boundary conditions of the self-explanation effect and cautioning against broad generalizations for instructional strategies, suggesting instead that strategies should be aligned to target knowledge. This work contributes to second language acquisition theory by demonstrating the effectiveness of computer-based tutoring systems for second language grammar learning and providing data that supports the benefits of explicit instruction. Furthermore, this work demonstrates the relative effectiveness of a broad spectrum of explicit learning conditions. Finally, this work makes contributions to tutoring systems research by demonstrating a process for data-driven and experiment-driven tutor design that has lead to significant learning gains and consistent adoption in real classrooms.
- Hideki Shima, Yuanpeng Li, Naoki Orii, T. Mitamura. 2011. LTI's Textual Entailment Recognizer System at NTCIR-9 RITE. Abstract: paper describes the LTI's system participated in NTCIR-9 RITE. The system is based on multiple linguistically-motivated features and an adaptable framework for different datasets. The formal run scores are 54.6% (accuracy in BC), 66.7% (accuracy in Entrance Exam), and 29.8% (MRR in RITE4QA) which outperformed strong baselines, and are relatively good among participants. We also describe in-house experimental results (e.g. ablation study for measuring feature contribution).
- Hideki Shima, T. Mitamura. 2011. Diversity-aware Evaluation for Paraphrase Patterns. Abstract: Common evaluation metrics for paraphrase patterns do not necessarily correlate with extrinsic recognition task performance. We propose a metric which gives weight to lexical variety in paraphrase patterns; our proposed metric has a positive correlation with paraphrase recognition task performance, with a Pearson correlation of 0.5~0.7 (k=10, with "strict" judgment) in a statistically significant level (p-value<0.01).
- Hideki Shima, H. Kanayama, Cheng-Wei Lee, Chuan-Jie Lin, T. Mitamura, Yusuke Miyao, Shuming Shi, Koichi Takeda. 2011. Overview of NTCIR-9 RITE: Recognizing Inference in TExt. Abstract: This paper introduces an overview of the RITE (Recognizing Inference in TExt) task in NTCIR-9. We evaluate systems that automatically recognize entailment, paraphrase, and contradiction between two texts written in Japanese, Simplified Chinese, or Traditional Chinese. The task consists of four subtasks: Binary classification of entailment (BC); Multi-class classification including paraphrase and contradiction (MC); and two extrinsic application-oriented datasets: Entrance Exam and RITE4QA. This paper also describes how we built the test collection, evaluation metrics, and evaluation results of the submitted runs.
- Ruth Wylie, K. Koedinger, T. Mitamura. 2010. Extending the self-explanation effect to second language grammar learning. Abstract: Self-explanation is an instructional strategy that has shown to be beneficial for math and science learning. However, it remains an open question whether these benefits will extend to other domains like second language grammar learning. Within the domain of the English article system (teaching students when to use a, an, the, or no article at all), we compare two computer-based tutoring conditions in an in vivo classroom study. In the article choice condition, students select the correct article to complete the sentence. In the explanation choice condition, students are given a sentence with the correct article highlighted and choose the rule or feature that best explains the article use. Students (N=101) in both conditions show significant learning on both procedural (article choice) and declarative (explanation choice) tasks. Not surprisingly, we found that declarative instruction (explanation choice) led to significant learning of explanations, while procedural practice (article choice) led to significant learning of the procedures. More interestingly, we also found evidence of cross-type transfer such that declarative practice led to procedural gains and procedural practice led to better understanding of the declarative rules. In general the effects of prompted self-explanation appeared somewhat stronger than those of procedural practice.
- Jeongwoo Ko, Luo Si, Eric Nyberg, T. Mitamura. 2010. Probabilistic models for answer-ranking in multilingual question-answering. Abstract: This article presents two probabilistic models for answering ranking in the multilingual question-answering (QA) task, which finds exact answers to a natural language question written in different languages. Although some probabilistic methods have been utilized in traditional monolingual answer-ranking, limited prior research has been conducted for answer-ranking in multilingual question-answering with formal methods. This article first describes a probabilistic model that predicts the probabilities of correctness for individual answers in an independent way. It then proposes a novel probabilistic method to jointly predict the correctness of answers by considering both the correctness of individual answers as well as their correlations. As far as we know, this is the first probabilistic framework that proposes to model the correctness and correlation of answer candidates in multilingual question-answering and provide a novel approach to design a flexible and extensible system architecture for answer selection in multilingual QA. An extensive set of experiments were conducted to show the effectiveness of the proposed probabilistic methods in English-to-Chinese and English-to-Japanese cross-lingual QA, as well as English, Chinese, and Japanese monolingual QA using TREC and NTCIR questions.
- T. Sakai, T. Mitamura. 2010. Boiling down information retrieval test collections. Abstract: Constructing large-scale test collections is costly and time-consuming, and a few relevance assessment methods have been proposed for constructing "minimal" information retrieval test collections that may still provide reliable experimental results. In contrast to building up such test collections, we take existing test collections constructed through the traditional pooling approach and empirically investigate whether they can be "boiled down." More specifically, we report on experiments with test collections from both NT-CIR and TREC to investigate the effect of reducing both the topic set size and the pool depth on the outcome of a statistical significance test between two systems, starting with (approximately) 100 topics and depth-100 pools. We define cost (of manual relevance assessment) as the pool depth multiplied by the topic set size, and error as a system pair whose outcome of statistical significance testing differs from the original result based on the full test collection. Our main findings are: (a) Cost and the number of errors are negatively correlated, and any attempt at substantially reducing cost introduces some errors; (b) The NTCIR-7 IR4QA and the TREC 2004 robust track test collections all yield a comparable and considerable number of errors in response to cost reduction, and this is true despite the fact that the TREC relevance assessments relied on more than twice as many runs as the NTCIR ones; (c) Using 100 topics with depth-30 pools generally yields fewer errors than using 30 topics with depth-100 pools; and (d) Even with depth-100 pools, using fewer than 100 topics results in false alarms, i.e. two systems are declared significantly different even though the full topic set would declare otherwise.
- Hideki Shima, T. Mitamura. 2010. Bootstrap Pattern Learning for Open-Domain CLQA*. Abstract: We describe Javelin, a Cross-lingual Question Answering system which participated in the NTCIR-8 ACLIA evaluation and which is designed to work on any type of question, including factoid and complex questions. The key technical contribution of this paper is a minimally supervised bootstrapping approach to generating lexicosyntactic patterns used for answer extraction. The preliminary evaluation result (measured by nugget F3 score) shows that the proposed pattern learning approach outperformed two baselines, a supervised learning approach used in NTCIR-7 ACLIA and a simple key-term based approach, for both monolingual and crosslingual tracks. The proposed approach is general and thus it has potential applicability to a wide variety of information access applications which require deeper semantic processing.
- Jian-Cheng Wu, Yu-Chia Chang, T. Mitamura, Jason J. S. Chang. 2010. Automatic Collocation Suggestion in Academic Writing. Abstract: In recent years, collocation has been widely acknowledged as an essential characteristic to distinguish native speakers from non-native speakers. Research on academic writing has also shown that collocations are not only common but serve a particularly important discourse function within the academic community. In our study, we propose a machine learning approach to implementing an online collocation writing assistant. We use a data-driven classifier to provide collocation suggestions to improve word choices, based on the result of classification. The system generates and ranks suggestions to assist learners' collocation usages in their academic writing with satisfactory results.
- Lu Jiang, Zhongwen Xu, Zhenzhong Lan, Shicheng Xu, Xiaojun Chang, Xuanchong Li, Zexi, Mao, Chuang Gan, Yajie Miao, Xingzhong Du, Yang Cai, Lara Martin, Nikolas Wolfe, Anurag Kumar, Huan Li, Ming Lin, Yezhou Yang, Deyu Meng, S. Shan, P. D. Sahin, Susanne, Burger, Florian Metze, Rita Singh, B. Raj, T. Mitamura, R. Stern, Alexander, Hauptmann, Pinar Duygulu-Sahin, Alexander Hauptmann, Yicheng Zhao. 2010. MMM-TJU at TRECVID 2010. Abstract: Surveillance Event Detection Semantic event detection in the huge amount of surveillance video in both retrospective and real-time styles is essential to a variety of higher-level applications in the public security. In TRECVID 2010, to overcome the limitations of the traditional human action analysis method with human detection/tracking and domain knowledge, we evaluate the general framework for multiple human behaviors modeling with the philosophy of bag of spatiotemporal feature (BoSTF). The brief
- K. Koedinger, T. Mitamura, Ruth Wylie. 2009. Is Self-Explanation Always Better? The Effects of Adding Self-Explanation Prompts to an English Grammar Tutor. Abstract: Is Self-Explanation Always Better? The Effects of Adding Self-Explanation Prompts to an English Grammar Tutor Ruth Wylie (rwylie@cs.cmu.edu) Human-Computer Interaction Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh, PA 15217 USA Kenneth R. Koedinger (koedinger@cmu.edu) Human-Computer Interaction Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh, PA 15217 USA Teruko Mitamura (teruko@cs.cmu.edu) Language Technologies Institute, Carnegie Mellon University 5000 Forbes Avenue, Pittsburgh, PA 15217 USA Abstract Several studies have demonstrated the benefits of self- explanation on learning well-defined domains like math, biology, and physics. However, these findings have yet to be replicated in probabilistic domains like second language acquisition. Working with adult English as a Second Language students (n=61) within the domain of the English article system (i.e. teaching students the difference between a dog vs. the dog) we conduct the first experimental study of the effects of prompting self-explanation on second language grammar acquisition. We compare two different modes of self-explanations (free-response and menu-based), each implemented in an intelligent tutoring system, to a control tutor with no explicit self-explanation prompts. Students in all conditions show significant learning gains but contrary to theoretical predictions, the self-explanation tutors did not lead to better learning over the no self-explanation condition. We discuss why and under what specific conditions target- specific practice without self-explanation may be a more effective instructional strategy. Keywords: Self-Explanation Effect; Computer Assisted Language Learning; ESL Grammar Learning Introduction Self-explanation has been shown to be a successful learning strategy for multiple domains, contexts, and learners. One limitation of the existing work is the domains in which it has been tested have all been math and science domains like biology (Chi, et al., 1994), physics (Chi, 1989; Conati & VanLehn, 2000), and geometry (Aleven & Koedinger, 2002), and, to the best of our knowledge, there have never been any experimental studies on the effects of self- explanation on second language grammar acquisition. Thus, an open question exists: is self-explanation truly domain independent (Roy & Chi, 2005) or are there constraints to its applicability? In the original self-explanation studies, Chi et al. (1989) examined students’ spontaneous self-explanations of a physics text. This work revealed a positive correlation between the number and type of self-explanations and student learning. In subsequent experimental studies, Chi et al. (1994) showed that students who were prompted to self- explain demonstrated greater learning gains than those who were not. Furthermore, Aleven and Koedinger (2002) demonstrated that prompting self-explanations can be an effective learning strategy even when students only select a general problem-solving principle. Within the second language acquisition community, there is a large body of research that looks at implicit versus explicit instruction. A meta-analysis of the relative effectiveness of different types of second language instruction revealed that treatments involving explicit focus on rules were more effective than those that did not (Norris & Ortega, 2000). Thus, self- explanations, which highlight explicit rules, may be beneficial for the second language learner. Our goal was to see if the success of self-explanation could be replicated within second language acquisition. To this end, we developed two tutoring systems with different types of self-explanation prompts and compared student learning gains and learning efficiency scores to a control tutor that had no explicit self-explanation prompts. Results show that while students in all three conditions demonstrate significant pre-post learning gains, students in the self- explanation conditions did no better than those in the control group. In fact, a significant learning efficiency by tutor condition interaction reveals that there may be limits to the benefits of self-explanation. Adding Self-Explanation to an Existing Tutor Self-explanation prompts were added to an existing tutoring system designed to teach the English article system (teaching students the difference between “a dog” and “the dog”). In the existing system (Figure 1), developed using the Cognitive Tutoring Authoring Tools (Koedinger, et al., 2004), students select an article (a, an, the, or no article) from a drop-down menu to complete the sentence. They receive immediate feedback on their selections (the answer
- T. Sakai, N. Kando, Hideki Shima, Chuan-Jie Lin, Ruihua Song, Miho Sugimoto, T. Mitamura. 2009. Ranking the NTCIR ACLIA IR4QA Systems without Relevance Assessments. Abstract: We consider the problem of ranking information retrieval systems without relevance assessments in the context of collaborative evaluation forums such as NTCIR and TREC. Our short-term goal is to provide the NTCIR participants with a “system ranking forecast” prior to conducting manual relevance assessments, thereby reducing researchers’ “idle time” and accelarating research. The long term goal is to semi-automate repeated evaluation of search engines. Our experiments using the NTCIR-7 ACLIA IR4QA test collections show that pseudo-systemrankings based on a simple method are highly correlated with the “true” rankings. Encouraged by this positive finding, we plan to release system ranking forecasts to participants of the next round of IR4QA at NTCIR-8.
- Mona T. Diab, Lori S. Levin, T. Mitamura, Owen Rambow, Vinodkumar Prabhakaran, Weiwei Guo. 2009. Committed Belief Annotation and Tagging. Abstract: We present a preliminary pilot study of belief annotation and automatic tagging. Our objective is to explore semantic meaning beyond surface propositions. We aim to model people's cognitive states, namely their beliefs as expressed through linguistic means. We model the strength of their beliefs and their (the human) degree of commitment to their utterance. We explore only the perspective of the author of a text. We classify predicates into one of three possibilities: committed belief, non committed belief, or not applicable. We proceed to manually annotate data to that end, then we build a supervised framework to test the feasibility of automatically predicting these belief states. Even though the data is relatively small, we show that automatic prediction of a belief class is a feasible task. Using syntactic features, we are able to obtain significant improvements over a simple baseline of 23% F-measure absolute points. The best performing automatic tagging condition is where we use POS tag, word type feature AlphaNumeric, and shallow syntactic chunk information CHUNK. Our best overall performance is 53.97% F-measure.
- T. Mitamura, Hideki Shima, T. Sakai, N. Kando, Tatsunori Mori, Koichi Takeda, Chin-Yew Lin, Ruihua Song, Chuan-Jie Lin, Cheng-Wei Lee. 2008. Overview of the NTCIR-7 ACLIA Tasks: Advanced Cross-Lingual Information Access. Abstract: This paper presents an overview of the ACLIA (Advanced Cross-Lingual Information Access) task cluster. The task overview includes: a definition of and motivation for the evaluation; a description of the complex question types evaluated; the document sources and exchange formats selected and/or defined; the official metrics used in evaluating participant runs; the tools and process used to develop the official evaluation topics; summary data regarding the runs submitted; and the results of evaluating the submitted runs with the official metrics.
- T. Sakai, N. Kando, Chuan-Jie Lin, Ruihua Song, Hideki Shima, T. Mitamura. 2008. NTCIR-7 ACLIA IR4QA Results based on Qrels Version 2. Abstract: This document is a postscript to the Overview of the NTCIR-7 ACLIA IR4QA Task [2]. At the NTCIR7 Workshop Meeting (December 2008), participating systems of IR4QA were evaluated based on “qrels version 1,” which covered the depth-30 pool for every topic and went further down the pool for a limited number of topics. Here, we report on revised results based on “qrels version 2” which covers the depth-100 pool for every topic. While the version 1 and version 2 results are generally in agreement, some differences in system rankings and significance test results suggest that the additional effort was worthwhile.
- Hideki Shima, N. Lao, Eric Nyberg, T. Mitamura. 2008. Complex Cross-lingual Question Answering as a Sequential Classification and Multi-Document Summarization Task. Abstract: In this paper, we describe the JAVELIN IV system, which treats complex question answering as a sequential classification and multi-document summarization task. Our research and development effort is based on various forms of linguistic annotation, and a comparison of various answer extraction and summarization algorithms. We discuss the use of different units of extraction, the effect of different syntactic features for classification, and the effect of different summarization strategies. We also analyze how the performance of machine translation and information retrieval affect the performance of question answering. In the NTCIR-7 CCLQA main track official evaluation, our system achieved 16.3% and 19.2% accuracy in the English-toJapanese and English-to-Chinese subtasks, respectively.
- N. Lao, Hideki Shima, T. Mitamura, Eric Nyberg. 2008. Query Expansion and Machine Translation for Robust Cross-Lingual Information Retrieval. Abstract: In this paper, we describe the Information Retrieval subsystem of JAVELIN IV, a question-answering system that answers complex questions from multilingual sources. Our research focus is on different strategies for query term extraction, translation, filtering, expansion and weighting, including a novel alias expansion technique using lexico-syntactic patterns learned with weakly-supervised algorithm. In the NTCIR7 IR4QA evaluation, our retrieval system achieved 59% and 59% MAP in the Chinese-to-Chinese and Japanese-toJapanese subtasks, respectively. We provide a rationale for the retrieval system design, and present a detailed error analysis for our formal run results.
- T. Sakai, N. Kando, Chuan-Jie Lin, T. Mitamura, Hideki Shima, D. Ji, Kuang-hua Chen, Eric Nyberg. 2008. Overview of the NTCIR-7 ACLIA IR4QA Task. Abstract: This paper presents an overview of the IR4QA (Information Retrieval for Question Answering) Task of the NTCIR-7 ACLIA (Advanced Cross-lingual Information Access) Task Cluster. IR4QA evaluates traditional ranked retrieval of documents using wellstudied metrics such as Average Precision, but the retrieval task is embedded in the context of cross-lingual question answering. That is, document retrieval is treated as a component of the entire question answering system. This paper concentrates on how relevance assessments for the Simpified Chinese, Traditional Chinese and Japanese IR4QA test collections were obtained, and the outcome of the formal IR4QA evaluation using the three collections. For the relationship between IR4QA and the entire ACLIA task cluster, we refer the reader to the overview paper of ACLIA [17]. For details of the individual IR4QA systems, we refer the reader to the participants’ reports.
- Jeongwoo Ko, T. Mitamura, Eric Nyberg. 2007. Language-independent Probabilistic Answer Ranking for Question Answering. Abstract: This paper presents a language-independent probabilistic answer ranking framework for question answering. The framework estimates the probability of an individual answer candidate given the degree of answer relevance and the amount of supporting evidence provided in the set of answer candidates for the question. Our approach was evaluated by comparing the candidate answer sets generated by Chinese and Japanese answer extractors with the re-ranked answer sets produced by the answer ranking framework. Empirical results from testing on NTCIR factoid questions show a 40% performance improvement in Chinese answer selection and a 45% improvement in Japanese answer selection.
- Mengqiu Wang, Noah A. Smith, T. Mitamura. 2007. What is the Jeopardy Model? A Quasi-Synchronous Grammar for QA. Abstract: This paper presents a syntax-driven approach to question answering, specifically the answer-sentence selection problem for short-answer questions. Rather than using syntactic features to augment existing statistical classifiers (as in previous work), we build on the idea that questions and their (correct) answers relate to each other via loose but predictable syntactic transformations. We propose a probabilistic quasi-synchronous grammar, inspired by one proposed for machine translation (D. Smith and Eisner, 2006), and parameterized by mixtures of a robust nonlexical syntax/alignment model with a(n optional) lexical-semantics-driven log-linear model. Our model learns soft alignments as a hidden variable in discriminative training. Experimentalresultsusing theTRECdataset are shown to significantly outperform strong state-of-the-art baselines.
- T. Mitamura, Frank Lin, Hideki Shima, Mengqiu Wang, Jeongwoo Ko, J. Betteridge, M. Bilotti, A. Schlaikjer, Eric Nyberg. 2007. JAVELIN III: Cross-Lingual Question Answering from Japanese and Chinese Documents. Abstract: In this paper, we describe the JAVELIN Cross Language Question Answering system, which includes modules for question analysis, keyword translation, document retrieval, information extraction and answer generation. In the NTCIR6 CLQA2 evaluation, our system achieved 19% and 13% accuracy in the English-to-Chinese and English-to-Japanese subtasks, respectively. An overall analysis and a detailed module-by-module analysis are presented.
- A. Lavie, David Yarowsky, Kevin Knight, Chris Callison-Burch, Nizar Habash, T. Mitamura. 2007. Machine Translation Working Group Final Report. Abstract: This report is one of five reports that were based on the MINDS workshops, led by Donna Harman (NIST) and sponsored by Heather McCallum-Bayliss of the Disruptive Technology Office of the Office of the Director of National Intelligence's Office of Science and Technology (ODNI/ADDNI/S&T/DTO). To find the rest of the reports, and an executive overview, please see http://www.itl.nist.gov/iaui/894.02/minds.html.
- Hideki Shima, T. Mitamura. 2007. JAVELIN III: Answering Non-Factoid Questions in Japanese. Abstract: In this paper, we describe our adaptation of the JAVELIN system to Japanese question answering for the NTCIR-6 QAC track. To establish a baseline Japaneseto-Japanese non-factoid question answering system, we performed the minimum extensions to our factoid question answering system. The answer boundary recognition task was simplified by introducing a “One Sentence Assumption” so that answer extraction task only deals with ranking of answer candidates in one sentence level. In the end, the performance of our machine learning-based sub-modules was affected by a scarcity of training data; nevertheless, our system performed close to the average accuracy in the number of questions correctly answered.
- Hideki Shima, Mengqiu Wang, Frank Lin, T. Mitamura. 2006. Modular Approach to Error Analysis and Evaluation for Multilingual Question Answering. Abstract: Multilingual Question Answering systems are generally very complex, integrating several sub-modules to achieve their result. Global metrics (such as average precision and recall) are insufficient when evaluating the performance of individual sub-modules and their influence on each other. In this paper, we present a modular approach to error analysis and evaluation; we use manually-constructed, gold-standard input for each module to obtain an upper-bound for the (local) performance of that module. This approach enables us to identify existing problem areas quickly, and to target improvements accordingly.
- Jeongwoo Ko, Fumihiko Murase, T. Mitamura, Eric Nyberg, Masahiko Tateishi, Ichiro Akahori. 2006. Context-aware Dialog Strategies for Multimodal Mobile Dialog Systems. Abstract: Multimodal mobile dialog systems face new challenges which do not exist in traditional spoken dialog systems. A mobile dialog system should provide robust task management during network loss, and intelligent assistance in new environments. To provide these capabilities, a system must sense changes in the user environment, and communicate them effectively to the user. In the field of human-computer interaction, such systems are referred to as context-aware systems. Two possible approaches have been explored: in one, the user requests information when needed (information pull), and in the other, the system automatically offers relevant information (information push). In this paper, we present our dialog management strategy for context-awareness using an information push model. A preliminary evaluation conducted in both labaratory and driving environments shows that context-awareness significantly improved user performance.
- Owen Rambow, B. Dorr, D. Farwell, R. Green, Nizar Habash, Stephen Helmreich, E. Hovy, Lori S. Levin, Keith J. Miller, T. Mitamura, F. Reeder, Advaith Siddharthan. 2006. Parallel Syntactic Annotation of Multiple Languages. Abstract: This paper describes an effort to investigate the incrementally deepening development of an interlingua notation, validated by human annotation of texts in English plus six languages. We begin with deep syntactic annotation, and in this paper present a series of annotation manuals for six different languages at the deep-syntactic level of representation. Many syntactic differences between languages are removed in the proposed syntactic annotation, making them useful resources for multilingual NLP projects with semantic components.
- Jeongwoo Ko, Fumihiko Murase, T. Mitamura, Eric Nyberg, Masahiko Tateishi, Ichiro Akahori. 2006. Analyzing the Effects of Spoken Dialog Systems on Driving Behavior. Abstract: This paper presents an evaluation of a spoken dialog system for automotive environments. Our overall goal was to measure the impact of user-system interaction on the user’s driving performance, and to determine whether adding context-awareness to the dialog system might reduce the degree of user distraction during driving. To address this issue, we incorporated context-awareness into a spoken dialog system, and implemented three system features using user context, network context and dialog context. A series of experiments were conducted under three different configurations: driving without a dialog system, driving while using a context-aware dialog system, and driving while using a context-unaware dialog system. We measured the differences between the three configurations by comparing the average car speed, the frequency of speed changes and the angle between the car’s direction and the centerline on the road. These results indicate that context-awareness could reduce the degree of user distraction when using a dialog system during
- Mengqiu Wang, Kenji Sagae, T. Mitamura. 2006. A Fast, Accurate Deterministic Parser for Chinese. Abstract: We present a novel classifier-based deterministic parser for Chinese constituency parsing. Our parser computes parse trees from bottom up in one pass, and uses classifiers to make shift-reduce decisions. Trained and evaluated on the standard training and test sets, our best model (using stacked classifiers) runs in linear time and has labeled precision and recall above 88% using gold-standard part-of-speech tags, surpassing the best published results. Our SVM parser is 2-13 times faster than state-of-the-art parsers, while producing more accurate results. Our Maxent and DTree parsers run at speeds 40-270 times faster than state-of-the-art parsers, but with 5-6% losses in accuracy.
- Eric Nyberg, R. Frederking, T. Mitamura, M. Bilotti, K. Hannan, L. Hiyakumoto, Jeongwoo Ko, Frank Lin, L. Lita, V. Pedro, A. Schlaikjer. 2005. JAVELIN I and II Systems at TREC 2005. Abstract: The JAVELIN team at Carnegie Mellon University submitted three question-answering runs for the TREC 2005 evaluation. The JAVELIN I system was used to generate a single submission to the main track, and the JAVELIN II system was used to generate two submissions to the relationship track. In the sections that follow, we separately describe each system and the submission(s) it produced, and conclude with a brief summary.
- Eric Nyberg, T. Mitamura, R. Frederking, V. Pedro, M. Bilotti, A. Schlaikjer, K. Hannan. 2005. Extending the JAVELIN QA System with Domain Semantics ∗. Abstract: This paper presents the current status of work to extend the JAVELIN QA system with domain semantics for question answering in restricted domains. We discuss how the original architecture was extended, and how the system modules must be adjusted to incorporate knowledge from existing ontologies and information provided by third-party annotation tools.
- Frank Lin, Hideki Shima, Mengqiu Wang, T. Mitamura. 2005. CMU JAVELIN System for NTCIR5 CLQA1. Abstract: In this paper, we describe the JAVELIN Cross Language Question Answering system, which includes modules for question analysis, keyword translation, document retrieval, information extraction and answer generation. In the NTCIR5 CLQA1 evaluation, our system achieved 7.5% and 10.0% accuracy in the English-to-Chinese and English-to-Japanese subtasks, respectively. An overall analysis and a detailed module-by-module analysis are presented.
- Eric Nyberg, T. Mitamura, J. Betteridge. 2005. Capturing knowledge from domain text with controlled language. Abstract: This paper describes a prototype system which captures semantic knowledge from domain text using controlled language. The KANTOO system is used to analyze input sentences from college-level science textbooks, producing sentence-level meaning representations (interlingua). The interlingua expressions are mapped into F-logic statements, which are be stored in a separate knowledge base to support reasoning in the domain.
- B. Dorr, D. Farwell, R. Green, Nizar Habash, Stephen Helmreich, E. Hovy, Lori S. Levin, Keith J. Miller, T. Mitamura, Owen Rambow, F. Reeder, Advaith Siddharthan. 2004. Interlingua Development and Testing through Semantic Annotation of Multilingual Text Corpora. Abstract: This paper describes a multi-site project to annotate the interlingual content of six sizable bilingual parallel corpora. The project addresses several principal problems in parallel: specification of interlingua content and notation, development of reliable annotation methods, and evaluation of annotated corpora. As a by-product, a growing corpus of annotated texts is being produced, which may eventually be useful for machine learning of semantics-based processing.
- Anna Kupsc, T. Mitamura, Benjamin Van Durme, Eric Nyberg. 2004. Pronominal Anaphora Resolution for Unrestricted Text. Abstract: The paper presents an anaphora resolution algorithm for unrestricted text. In particular, we examine portability of a knowledge-based approach of (Mitamura et al., 2002), proposed for a domain-specific task. We obtain up to 70% accuracy on unrestricted text, which is a significant improvement (almost 20%) over a baseline we set for general text. As the overall results leave much room for improvement, we provide a detailed error analysis and investigate possible enhancements.
- Stephen Helmreich, D. Farwell, B. Dorr, Nizar Habash, Lori S. Levin, T. Mitamura, F. Reeder, Keith J. Miller, E. Hovy, Owen Rambow, Advaith Siddharthan. 2004. Interlingual Annotation of Multilingual Text Corpora. Abstract: This paper describes a multi-site project to annotate six sizable bilingual parallel corpora for interlingual content. After presenting the background and objectives of the effort, we will go on to describe the data set that is being annotated, the interlingua representation language used, an interface environment that supports the annotation task and the annotation process itself. We will then present a preliminary version of our evaluation methodology and conclude with a summary of the current status of the project along with a number of issues which have arisen.
- N. Hataoka, Y. Buchi, T. Mitamura, Eric Nyberg. 2004. Robust speech dialog interface for car telematics service. Abstract: We describe new consumer services based on speech processing technologies to support a new digital/mobile era of ubiquitous communication. First, we propose, a compact and noise robust embedded speech recognition middleware implemented on microprocessors focused on sophisticated HMIs (human machine interfaces) for car information systems (i.e. car telematics). Second, we report on a novel and sophisticated dialog management/manager (DM) system, based on VoiceXML (voice extensible markup language), called CAMMIA (conversational agent for multimedia mobile information access). The proposed DM handles two important issues: an automatic generation scheme for lexicons and grammars, and an effective combination/merger between automatic speech recognition (ASR) and natural language processing (NLP). The new DM scheme has been evaluated for an application of the car telematics service task after integration with ASR and a VoiceXML interpreter (VXI).
- H. Sagawa, T. Mitamura, Eric Nyberg. 2004. A comparison of confirmation styles for error handling in a speech dialog system. Abstract: Speech recognition errors are inevitable in a speech dialog system. It is important to provide a dialog flow that allows the user to correct system errors and quickly return to the original dialog. This paper describes explicit, final and implicit confirmation styles that are implemented in the CAMMIA speech dialog system, and compares them from the viewpoint of usability. Our results show that a final confirmation with fewer confirmation turns is preferred by the user when there is no error in the dialog. On the other hand, an explicit confirmation is preferred when an error occurs.
- H. Sagawa, T. Mitamura, Eric Nyberg. 2004. Correction Grammars for Error Handling in a Speech Dialog System. Abstract: Speech recognition errors are inevitable in a speech dialog system. This paper presents an error handling method based on correction grammars which recognize the correction utterances which follow a recognition error. Correction grammars are dynamically created from existing grammars and a set of correction templates. We also describe a prototype dialog system which incorporates this error handling method, and provide empirical evidence that this method can improve dialog success rate and reduce the number of dialog turns required for error recovery.
- V. Pedro, Jeongwoo Ko, Eric Nyberg, T. Mitamura. 2004. An Information Repository Model for Advanced Question Answering Systems. Abstract: This paper presents the design and implementation of the information repository which is the central core of the JAVELIN opendomain question answering system. JAVELIN is comprised of several modules that perform a wide variety of question answering (QA) tasks, such as question analysis, document and passage retrieval, answer candidate extraction, answer selection, answer justification, and planning. The architecture is designed to support comparative component-level evaluation, so that different strategies for each module can be integrated and tested in a straightforward way. Each time a module uses a particular piece of information to produce an output, a dependency is created. To support answer justification and introspective learning, the system can use this longterm memory to trace the origin of each answer it produces for a particular question. The JAVELIN Repository implements a complete, consistent relational model for all of the information associated with a question answering scenario.
- T. Mitamura, Kathryn L. Baker, David Svoboda, Eric Nyberg. 2003. Source language diagnostics for MT. Abstract: This paper presents a source language diagnostic system for controlled translation. Diagnostics were designed and implemented to address the most difficult rewrites for authors, based on an empirical analysis of log files containing over 180,000 sentences. The design and implementation of the diagnostic system are presented, along with experimental results from an empirical evaluation of the completed system. We found that the diagnostic system can correctly identify the problem in 90.2% of the cases. In addition, depending on the type of grammar problem, the diagnostic system may offer a rewritten sentence. We found that 89.4% of the rewritten sentences were correctly rewritten. The results suggest that these methods could be used as the basis for an automatic rewriting system in the future.
- Eric Nyberg, T. Mitamura, Jamie Callan, J. Carbonell, R. Frederking, Kevyn Collins-Thompson, L. Hiyakumoto, Yifen Huang, C. Huttenhower, S. Judy, Jeongwoo Ko, Anna Kupsc, L. Lita, V. Pedro, David Svoboda, Benjamin Van Durme. 2003. The JAVELIN Question-Answering System at TREC 2003: A Multi-Strategh Approach with Dynamic Planning. Abstract: The JAVELIN system evaluated at TREC 2003 is an integrated architecture for open-domain question answering. JAVELIN employs a modular approach that addresses individual aspects of the QA task in an abstract manner. The System implements a planner that controls the execution and information o w, as well as a multiple answer seeking strategies used differently depending on the type of question.
- T. Mitamura, Eric Nyberg, R. Frederking. 2003. Teaching machine translation in a graduate language technologies program. Abstract: This paper describes a graduate-level machine translation (MT) course taught at the Language Technologies Institute at Carnegie Mellon University. Most of the students in the course have a background in computer science. We discuss what we teach (the course syllabus), and how we teach it (lectures, homeworks, and projects). The course has evolved steadily over the past several years to incorporate refinements in the set of course topics, how they are taught, and how students “learn by doing”. The course syllabus has also evolved in response to changes in the field of MT and the role that MT plays in various social contexts.
- Eric Nyberg, T. Mitamura, J. Carbonell, Jamie Callan, Kevyn Collins-Thompson, Krzysztof Czuba, M. Duggan, L. Hiyakumoto, N. Hu, Yifen Huang, Jeongwoo Ko, L. Lita, S. Murtagh, V. Pedro, David Svoboda. 2002. The JAVELIN Question-Answering System at TREC 2002. Abstract: This Conference Proceeding is brought to you for free and open access by the School of Computer Science at Research Showcase. It has been acceptedfor inclusion in Computer Science Department by an authorized administrator of Research Showcase. For more information, please contactkbehrman@andrew.cmu.edu.
- Eric Nyberg, T. Mitamura, N. Hataoka. 2002. DialogXML: extending VoiceXML for dynamic dialog management. Abstract: The characteristics of VoiceXML make it an attractive choice for the implementation of embedded dialog systems on networked hardware. Nevertheless, VoiceXML lacks some important features found in existing proprietary approaches. It is difficult to build a complex, multi-dialog system directly in VoiceXML. This paper describes DialogXML, an extension to VoiceXML that supports a more implicitly declarative language for dialog scenarios, and ScenarioXML, a straightforward combination of DialogXML with the template-filling mechanism of Java Server Pages. The paper describes an initial prototype system, which extends the OpenVXI VoiceXML interpreter for DialogXML, implements a web server for ScenarioXML, and utilizes the KANTOO natural language analyzer for understanding user inputs.
- R. Frederking, Eric Nyberg, T. Mitamura, Jaime G. Carbonnell. 2002. Design and Evolution of a Language Technologies Curriculum. Abstract: The Language Technologies Institute (LTI) of the School of Computer Science at Carnegie Mellon University is one of the largest programs of its kind. We present here the initial design and subsequent evolution of our MS and PhD programs in Language Technologies. The motivations for the design and evolution are also presented.
- Eric Nyberg, T. Mitamura. 2002. Evaluating QA Systems on Multiple Dimensions. Abstract: Question-answering systems are expanding beyond information retrieval and information extraction, to become fullfledged, complex NLP applications. In this paper we discuss the evaluation of question-answering systems as complex NLP systems, and suggest three different dimensions for evaluation: objective or information-based evaluation; subjective evaluation; and architectural evaluation. We also discuss the role of ambiguity resolution in QA systems, and how ambiguity resolution might be evaluated.
- Jamie Callan, T. Mitamura. 2002. Knowledge-based extraction of named entities. Abstract: The usual approach to named-entity detection is to learn extraction rules that rely on linguistic, syntactic, or document format patterns that are consistent across a set of documents. However, when there is no consistency among documents, it may be more effective to learn document-specific extraction rules.This paper presents a knowledge-based approach to learning rules for named-entity extraction. Document-specific extraction rules are created using a generate-and-test paradigm and a database of known named-entities. Experimental results show that this approach is effective on Web documents that are difficult for the usual methods.
- T. Mitamura, Eric Nyberg, Enrique Torrejón, David Svoboda, Ann Brunner, Kathryn L. Baker. 2002. Pronominal anaphora resolution in the KANTOO multilingual machine translation system.. Abstract: We present an approach to pronominal anaphora resolution using KANT Controlled Language and the KANTOO multilingual MT system. Our algorithm is based on a robust, syntax-based approach that applies a set of restrictions and preferences to select the correct antecedent. We report a success rate of 93.3% on a training corpus with 286 anaphors, and 88.8% on held-out data with 144 anaphors. Our approach translates anaphors to Spanish with 97.9% accuracy and to German with 94.4% accuracy on held-out data.
- T. Mitamura, Eric Nyberg, Enrique Torrejón, David Svoboda, Kathryn L. Baker. 2001. Pronominal anaphora resolution in KANTOO English-to-Spanish machine translation system. Abstract: We describe the automatic resolution of pronominal anaphora using KANT Controlled English (KCE) and the KANTOO English-to-Spanish MT system. Our algorithm is based on a robust, syntax-based approach that applies a set of restrictions and preferences to select the correct antecedent. We report a success rate of 89.6% on a training corpus with 289 anaphors, and 87.5% on held-out data containing 145 anaphors. Resolution of anaphors is important in translation, due to gender mismatches among languages; our approach translates anaphors to Spanish with 97.2% accuracy.
- V. Cavalli-Sforza, A. Soudi, T. Mitamura. 2000. Arabic Morphology Generation Using a Concatenative Strategy. Abstract: Arabic inflectional morphology requires infixation, prefixation and suffixation, giving rise to a large space of morphological variation. In this paper we describe an approach to reducing the complexity of Arabic morphology generation using discrimination trees and transformational rules. By decoupling the problem of stem changes from that of prefixes and suffixes, we gain a significant reduction in the number of rules required, as much as a factor of three for certain verb types. We focus on hollow verbs but discuss the wider applicability of the approach.
- T. Mitamura, Eric Nyberg, Enrique Torrejón, Robert Igo. 1999. Multiple strategies for automatic disambiguation in technical translation. Abstract: The use of knowledge-based machine translation with controlled technical text can produce high-quality translations. However, building and maintaining knowledge bases can require significant time and effort, since they typically involve handcoding of semantic preferences. When a system can't disambiguate based on semantic preferences, it can initiate interactive disambiguation with the author to improve the likelihood of an accurate translation, but this decreases the productivity of text authoring. In this paper, we present an experimental evaluation of automatic disambiguation strategies which could eliminate the need for interactive structural disambiguation in the KANT machine translation system.
- T. Mitamura. 1999. Controlled language for multilingual machine translation. Abstract: In this paper, we present an overview of the issues in designing a controlled language, the implementation of a controlled language checker, and the deployment of KANT Controlled English for multilingual machine translation. We also discuss some success criteria for introducing controlled language. Finally, future vision of KANT controlled language development is discussed.
- T. Mitamura. 1999. Controlled Language for Multilingual Machine Translation 1. Abstract: In this paper, we present an overview of the issues in designing a controlled language, the implementation of a controlled language checker, and the deployment of KANT Controlled English for multilingual machine translation. We also discuss some success criteria for introducing controlled language. Finally, future vision of KANT controlled language development is discussed.
- Krzysztof Czuba, T. Mitamura, Eric Nyberg. 1998. Can Practical Interlinguas Be Used for Difficult Analysis Problems. Abstract: A method and apparatus in which a blunt interior needle is positioned within a larger external needle and a sample cavity is formed at the blunt end of the interior needle. An optical fiber extends from the sample cavity up the interior needle and to a light source and light detector. A reflective surface is placed at the end of the sample cavity reflects light back to the optical fiber. A beam splitter separates the incident and reflected light. To make an in-vivo measurement of chemical concentrations in a body, the needle is inserted into the body and fluids are aspirated into the sample cavity. Light is then transmitted to the cavity by the optical fiber and is transmitted from the cavity to a detector by the same fiber. By measuring the amount of light reflected, one can determine the amount of light absorbed in the cavity and may thus determine concentrations of selected chemicals.
- C. Kamprath, E. Adolphson, T. Mitamura, Eric Nyberg. 1998. Controlled Language for Multilingual Document Production: Experience with Caterpillar Technical English 1. Abstract: Caterpillar Inc., a heavy equipment manufacturing company headquartered in Peoria IL, supports world-wide distribution of a large number of products and parts. Each Caterpillar product integrates several complex subsystems (engine, hydraulic system, drive system, implements, electrical, etc.) for which a variety of technical documents must be produced (operations and maintenance, testing and adjusting, disassembly and assembly, specifications, etc.). To support consistent, high-quality authoring and translation of these documents from English into a variety of target languages, Caterpillar uses Caterpillar Technical English (CTE), a controlled English system developed in conjunction with CarnegieMellon University’s Center forMachine Translation (CMT) andCarnegie Group Incorporated (CGI).
- Eric Nyberg, T. Mitamura, J. Carbonell. 1997. The KANT Machine Translation System: From R&D to Initial Deployment. Abstract: The KANT system (Knowledge-based, Accurate Natural-language Translation) is a set of software tools for automatic and interactive analysis of source text and generation of target text ( Mi amura, et al., 1991). It has been primarily targeted towards the translation of technical text in controlled subdomains (Mitamura and Nyberg, 1995). Initially an outgrowth of research ideas following the completion of the KBMT-89 system at CMU ( Goodman and Nirenburg, 1990), KANT has been scaled up for multilingual document production in an industrial setting. In this paper, we discuss the facets of KANT which are of potential interest to the LISA audience: its technical foundation, its intended domain(s) of application, its current performance, and our future plans regarding its application and commercialization.
- R. Frederking, T. Mitamura, Eric Nyberg, J. Carbonell. 1997. Translingual Information Access. Abstract: We present an attempt at a coherent vision of an end-to-end translingual information retrieval system. We begin by presenting a sample of the broad range of possibilities, and the results of some initial work comparing the different approaches. We then present an overall workstation architecture, followed by two possible approaches to the actual translingual IR stage presented in detail. Ranking retrieved documents, query-relevant summarization, assimilation of retrieved information, and system evaluation are all discussed in turn.
- AccessRobert, Frederking, T. Mitamura, Eric Nyberg, Jaime, CarbonellLanguage. 1997. Translingual Information Access Introduction: beyond Traditional Information Retrieval. Abstract: We present an attempt at a coherent vision of an end-to-end translingual information retrieval system. We begin by presenting a sample of the broad range of possibilities, and the results of some initial work comparing the diierent approaches. We then present an overall workstation architecture, followed by two possible approaches to the actual translingual IR stage presented in detail. Ranking retrieved documents, query-relevant summarization, assimilation of retrieved information, and system evaluation are all discussed in turn.
- Eric Nyberg, T. Mitamura. 1997. A Real-Time MT System for Translating Broadcast Captions. Abstract: This presentation demonstrates a new multi-engine machine translation system, which combines knowledge-based and example-based machine translation strategies for real-time translation of business news captions from English to German.
- T. Mitamura, Eric Nyberg. 1995. Controlled English for Knowledge-Based MT: Experience with the KANT System. Abstract: In this paper, we describe the design and deployment of KANT Controlled English (KCE) for knowledge-based machine translation in the KANT system. KCE combines three kinds of constraints: constraints on the lexicon; constraints on the complexity of sentences; and the use of generalized markup language. We describe how each of these types of language control are utilized in the implementation of a typical KANT application. The principles described are not specific to knowledge-based MT, and can be applied in the design of controlled languages for any kind of MT application.
- Eric Nyberg, T. Mitamura, J. Carbonell. 1994. Evaluation Metrics for Knowledge-Based Machine Translation. Abstract: A methodology is presented for component-based machine translation (MT) evaluation through causal error analysis to complement existing global evaluation methods. This methodology is particularly appropriate for knowledge-based machine translation (KBMT) systems. After a discussion of MT evaluation criteria and the particular evaluation metrics proposed for KBMT, we apply this methodology to a large-scale application of the KANT machine translation system, and present some sample results.
- Kathryn L. Baker, A. Franz, Pamela W. Jordan, T. Mitamura, Eric Nyberg. 1994. Coping With Ambiguity in a Large-Scale Machine Translation System. Abstract: In an interlingual knowledge-based machine translation system, ambignuity arises when the source language analyzer produces more than one interlingua expression for a source sentence. This can have a negative impact on translation quality, since a target sentence may be produced from an unintended meaning. In this paper we describe the methods used in the KANT machine translation system to reduce or eliminate ambiguity in a large-scale application domain. We also test these methods on a large corpus of test sentences, in order to illustrate how the different disambiguation methods reduce the average number of parses per sentence.
- T. Mitamura, Eric Nyberg, J. Carbonell. 1994. KANT: Knowledge-Based, Accurate Natural Language Translation. Abstract: KANT is an interlingual MT system for multi-lingual translation of technical documents, written using a controlled vocabulary and grammar. KANT is comprised of a set of software modules (parser, interpreter, mapper, generator) which work together to produce target language translations from controlled source text. These modules are the result of long-term research and development in practical machine translation at the Center for Machine Translation (CMT) at Carnegie Mellon University, located in Pittsburgh, PA. The KANT software grew out of extensions and refinements to earlier systems developed at the CMT, which include the CMT-SEMSYN system, a collaborative effort with the University of Stuttgart in the domain of doctor patient communications (Japanese and English source languages to Japanese, English and German target languages), and the KBMT-89 system, a funded project with IBM's Tokyo Research Laboratory in the domain of PC installation manuals (Japanese and English to Japanese and English; cf. (Goodman and Nirenburg, 1991)).
- T. Mitamura, Eric Nyberg, J. Carbonell. 1993. Automated Corpus Analysis and the Acquisition of Large, Multi-Lingual Knowledge Bases for MT. Abstract: Although knowledge-based MT systems have the potential to achieve high translation accuracy, each successful application system requires a large amount of hand-coded knowledge (lexicons, grammars, mapping rules, etc.). Systems like KBMT-89 and its descendants have demonstrated how knowledge-based translation can produce good results in technical domains with tractable domain semantics. Nevertheless, the cost of developing large-scale applications with tens of thousands of domain concepts precludes a purely hand-crafted approach. The current challenge for the "next generation" of knowledge-based MT systems is to utilize on-line textual resources and corpus analysis software in order to automate the most laborious aspects of the knowledge acquisition process. This partial automation can in turn maximize the productivity of human knowledge engineers and help to make large-scale applications of knowledge-based MT an economic reality. In this paper we discuss the corpus-based knowledge acquisition methodology used in KANT, a knowledge-based translation system for multi-lingual document production. This methodology can be generalized beyond the KANT interlingua approach for use with any system that requires similar kinds of knowledge.
- T. Kitani, T. Mitamura. 1993. A Japanese preprocessor for syntactic and semantic parsing. Abstract: The authors describe a Japanese preprocessor which includes a morphological analyzer called MAJESTY, and a proper noun identification program. The original morphological analyzer was modified to disambiguate its output when multiple possibilities for segmentations and parts of speech are found. Ambiguous segments are packed locally in the output enabling a syntactic and semantic parser to perform efficiently. Then the proper noun identification program groups several segments constructing a proper noun to present a meaningful set of segments to the parser. Tested on financial news articles, the preprocessor successfully segmented text and tagged parts of speech with greater than 98% accuracy. Over 80% of company names and 90% of personal and place names have been identified.<<ETX>>
- P. Jacobs, George B. Krupka, L. Rau, M. Mauldin, T. Mitamura, T. Kitani, I. Sider, L. Childs. 1993. GE-CMU: Description of the SHOGUN System Used for MUC-5. Abstract: This paper describes the GE-CMU TIPSTER/SHOGUN system as configured for the TIP-STER 24-month (MUC-5) benchmark, and gives details of the system's performance on the selected Japanese and English texts. The SHOGUN system is a distillation of some of the key ideas that emerged from previous benchmarks and experiments, emphasizing a simple architecture in which the focus is on detailed corpus-based knowledge. This design allowed the project to meet its goal of achieving advances in coverage and accuracy while showing consistently good performance across languages and domains.
- T. Mitamura, Eric Nyberg. 1992. Hierarchical Lexical Structure and Interpretive Mapping in Machine Translation. Abstract: Large-scale knowledge-based machine translation requires significant amounts of lexical knowledge in order to map syntactic structures to conceptual structures. This paper presents a framework in which lexical knowledge is separated into different levels of representation, which are arranged in a hierarchical model based on principles of knowledge representation and lexical semantics. The proposed methodology is language-independent, and has been used to organize lexical knowledge for both English and Japanese.
- J. Carbonell, T. Mitamura, Eric Nyberg. 1992. The KANT perspective: a critique of pure transfer (and pure interlingua, pure statistics, .. ). Abstract: There is a strong tendency among MT researchers to emphasize paradigmatic differences in MT approaches. This often leads to energetic criticism of competing systems, but obscures the fact that many techniques developed within a particular paradigm can improve the quality of MT systems in general. In this paper we show how practical MT development must move beyond dogmatic dismissal of differing approaches to an integrated, rational approach to MT which combines the best that each paradigm has to offer. We then discuss KANT, a practical MT system which makes use of techniques from the interlingua, statistical, and transfer-based MT paradigms to produce accurate, high-quality translation.
- Eric Nyberg, T. Mitamura. 1992. The KANT System: Fast, Accurate, High-Quality Translation in Practical Domains. Abstract: Knowledge-based interlingual machine translation systems produce semantically accurate translations, but typically require massive knowledge acquisition. Ongoing research and development at the Center for Machine Translation has focussed on reducing this requirement to produce large-scale practical applications of knowledge-based MT. This paper describes KANT, the first system to combine principled source language design, semi-automated knowledge acquisition, and knowledge compilation techniques to produce fast, high-quality translation to multiple languages.
- T. Mitamura, Eric Nyberg, J. Carbonell. 1991. An Efficient Interlingua Translation System for Multi-lingual Document Production. Abstract: Knowledge-based interlingual machine translation systems produce semantically accurate translations, but typically require massive knowledge acquisition. This paper describes KANT, a system that reduces this requirement to produce practical, scalable, and accurate KBMT applications. First, the set of requirements is discussed, then the full KANT architecture is illustrated, and finally results from a fully implemented prototype are presented.
- H. Kitano, H. Tomabechi, T. Mitamura, H. Iida. 1989. A massively parallel model of speech-to-speech dialog translation: a step toward interpreting telephony. Abstract: This paper describes the overall picture of 4iDMDIALOG. 4>DMDIALOG is a real-time Japanese-English speech-to speech dialog translation system that accepts speaker independent continuous speech inputs. The scientific fo cus of the project is to model the cognitive process of simultaneaus . interpreters. As a result, the architecture of the system is very different from machine translation sys tems. Our model assumes hybridized parallelism
- T. Mitamura, Lorraine S. Levin. 1989. The hierarchical organization of predicate frames for interpretive mapping in natural language processing. Abstract: The purpose of this thesis is to develop a methodology for constructing a hierarchical organization of predicate frames for interpretive mapping in knowledge-based machine translation. Interpretive mapping refers to the mapping between predicate conceptual structures and syntactic structures, and it involves two kinds of processes. One is a mapping between grammatical functions, such as subject and object, and semantic roles in the conceptual structures, such as agent and theme. The second is a mapping between words, such as naguru 'hit' and lexical conceptual frames, such as *HIT. 
The thesis shows that the systematic study of lexical semantics contributes to the construction of lexical structures and interpretive mapping rules. Lexical semantics provides insight into systematic correspondences between syntax and semantics. We focus on Japanese verbs and classify them based on their common syntactic behavior, giving special attention to case alternations. Then we utilize knowledge representation techniques and inheritance mechanisms developed by artificial intelligence researchers to organize predicate frames hierarchically for interpretive mapping. The hierarchical organization of predicate frames can be incorporated into a system that does natural language processing, such as parsing a sentence into some meaning representation or generating a sentence from a meaning representation. 
The core set of Japanese predicate frames constructed in this thesis can be further developed by the addition of new words in the hierarchy. We expect that the lexical acquisition process can be done fairly automatically, since the mapping hierarchy has already been developed and can be used in various domains. In addition, the proposed methodology for organizing interpretive mapping rules would be helpful in the construction of predicate frames for other languages. 
In knowledge-based machine translation, syntactic structures and conceptual structures are combined to produce an intermediate semantic representation of the source language text. In order to combine these two structures, we need mapping rules to unite them. The main contribution of this thesis is to give a full-fledged model of interpretive mapping for knowledge-based machine translation, and to offer guidance that makes it easier to develop new translation domains.
- H. Kitano, T. Mitamura, M. Tomita. 1989. Massively Parallel Parsing in \PhiDmDialog: Integrated Architecture for Parsing Speech Inputs. Abstract: This paper describes the parsing scheme in the \PhiDmDialog speech-to-speech dialog translation system, with special emphasis on the integration of speech and natural language processing. We propose an integrated architecture for parsing speech inputs based on a parallel marker-passing scheme and attaining dynamic participation of knowledge from the phonological-level to the discourse-level. At the phonological level, we employ a stochastic model using a transition matrix and a confusion matrix and markers which carry a probability measure. At a higher level, syntactic/semantic and discourse processing, we integrate a case-based and constraint-based scheme in a consistent manner so that a priori probability and constraints, which reflect linguistic and discourse factors, are provided to the phonological level of processing. A probability/cost-based scheme in our model enables ambiguity resolution at various levels using one uniform principle.
- A. Lavie, David Yarowsky, Kevin Knight, Chris Callison-Burch, Nizar Habash, T. Mitamura. None. MINDS Workshops Machine Translation Working Group Final Report. Abstract: This report is one of five reports that were based on the MINDS workshops, led by Donna Harman (NIST) and sponsored by Heather McCallum-Bayliss of the Disruptive Technology Office of the Office of the Director of National Intelligence's Office of Science and Technology (ODNI/ADDNI/S&T/DTO). To find the rest of the reports, and an executive overview, please see http://www.itl.nist.gov/iaui/894.02/minds.html.
